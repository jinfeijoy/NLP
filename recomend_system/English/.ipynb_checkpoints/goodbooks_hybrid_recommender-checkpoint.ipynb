{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd3a146a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from pandasql import sqldf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import coo_matrix\n",
    "root_path = 'C:\\\\Users\\\\luoyan011\\\\Desktop\\\\PersonalLearning\\\\GitHub\\\\NLP_data\\\\goodbooks'\n",
    "sys.path.append('C:\\\\Users\\\\luoyan011\\\\Desktop\\\\PersonalLearning\\\\GitHub\\\\python_functions\\\\jl_nlp_pkg')\n",
    "\n",
    "import nlpbasic.textClean as TextProcessing\n",
    "import nlpbasic.docVectors as DocVector\n",
    "import nlpbasic.dataExploration as dataExploration\n",
    "import nlpbasic.lda as lda\n",
    "import nlpbasic.tfidf as tfidf\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns', 500)\n",
    "print(tf.__version__)\n",
    "pysqldf = lambda q: sqldf(q, globals())\n",
    "# Reference: https://medium.com/codex/tensorflow-deep-learning-recommenders-on-retail-dataset-ce0c50aff5fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a054d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_tags = pd.read_csv(os.path.join(root_path, \"book_tags.csv\"))\n",
    "books = pd.read_csv(os.path.join(root_path, \"books.csv\"))\n",
    "ratings = pd.read_csv(os.path.join(root_path, \"ratings.csv\"))\n",
    "tags = pd.read_csv(os.path.join(root_path, \"tags.csv\"))\n",
    "to_read = pd.read_csv(os.path.join(root_path, \"to_read.csv\"))\n",
    "\n",
    "#load ratings latent variable dataset\n",
    "user_latent = pd.read_csv(os.path.join(root_path, 'user_latent.csv'))\n",
    "item_latent = pd.read_csv(os.path.join(root_path, 'item_latent.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cd2fcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_id_from_0(data, column):\n",
    "    data_copy = data.copy()\n",
    "    for i in column:\n",
    "        data_copy[i] = data_copy[i] - 1\n",
    "    return data_copy\n",
    "\n",
    "book_tags = change_id_from_0(book_tags, ['goodreads_book_id'])\n",
    "books = change_id_from_0(books, ['id'])\n",
    "ratings = change_id_from_0(ratings, ['book_id','user_id'])\n",
    "to_read = change_id_from_0(to_read, ['book_id','user_id'])\n",
    "        \n",
    "user_latent.columns = ['id','u_latent_1','u_latent_2','u_latent_3','u_latent_4',\n",
    "                       'u_latent_5','u_latent_6','u_latent_7','u_latent_8',\n",
    "                       'u_latent_9','u_latent_10','u_latent_11','u_latent_12',\n",
    "                       'u_latent_13','u_latent_14','u_latent_15']\n",
    "item_latent.columns = ['id','i_latent_1','i_latent_2','i_latent_3','i_latent_4',\n",
    "                       'i_latent_5','i_latent_6','i_latent_7','i_latent_8',\n",
    "                       'i_latent_9','i_latent_10','i_latent_11','i_latent_12',\n",
    "                       'i_latent_13','i_latent_14','i_latent_15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49b66fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------book_tags--------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goodreads_book_id</th>\n",
       "      <th>tag_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>30574</td>\n",
       "      <td>167697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>11305</td>\n",
       "      <td>37174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>11557</td>\n",
       "      <td>34173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   goodreads_book_id  tag_id   count\n",
       "0                  0   30574  167697\n",
       "1                  0   11305   37174\n",
       "2                  0   11557   34173"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------books--------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>best_book_id</th>\n",
       "      <th>work_id</th>\n",
       "      <th>books_count</th>\n",
       "      <th>isbn</th>\n",
       "      <th>isbn13</th>\n",
       "      <th>authors</th>\n",
       "      <th>original_publication_year</th>\n",
       "      <th>original_title</th>\n",
       "      <th>title</th>\n",
       "      <th>language_code</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>work_ratings_count</th>\n",
       "      <th>work_text_reviews_count</th>\n",
       "      <th>ratings_1</th>\n",
       "      <th>ratings_2</th>\n",
       "      <th>ratings_3</th>\n",
       "      <th>ratings_4</th>\n",
       "      <th>ratings_5</th>\n",
       "      <th>image_url</th>\n",
       "      <th>small_image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2767052</td>\n",
       "      <td>2767052</td>\n",
       "      <td>2792775</td>\n",
       "      <td>272</td>\n",
       "      <td>439023483</td>\n",
       "      <td>9.780439e+12</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>The Hunger Games (The Hunger Games, #1)</td>\n",
       "      <td>eng</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4780653</td>\n",
       "      <td>4942365</td>\n",
       "      <td>155254</td>\n",
       "      <td>66715</td>\n",
       "      <td>127936</td>\n",
       "      <td>560092</td>\n",
       "      <td>1481305</td>\n",
       "      <td>2706317</td>\n",
       "      <td>https://images.gr-assets.com/books/1447303603m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1447303603s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4640799</td>\n",
       "      <td>491</td>\n",
       "      <td>439554934</td>\n",
       "      <td>9.780440e+12</td>\n",
       "      <td>J.K. Rowling, Mary GrandPré</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Harry Potter and the Sorcerer's Stone (Harry P...</td>\n",
       "      <td>eng</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4602479</td>\n",
       "      <td>4800065</td>\n",
       "      <td>75867</td>\n",
       "      <td>75504</td>\n",
       "      <td>101676</td>\n",
       "      <td>455024</td>\n",
       "      <td>1156318</td>\n",
       "      <td>3011543</td>\n",
       "      <td>https://images.gr-assets.com/books/1474154022m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1474154022s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>41865</td>\n",
       "      <td>41865</td>\n",
       "      <td>3212258</td>\n",
       "      <td>226</td>\n",
       "      <td>316015849</td>\n",
       "      <td>9.780316e+12</td>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>Twilight</td>\n",
       "      <td>Twilight (Twilight, #1)</td>\n",
       "      <td>en-US</td>\n",
       "      <td>3.57</td>\n",
       "      <td>3866839</td>\n",
       "      <td>3916824</td>\n",
       "      <td>95009</td>\n",
       "      <td>456191</td>\n",
       "      <td>436802</td>\n",
       "      <td>793319</td>\n",
       "      <td>875073</td>\n",
       "      <td>1355439</td>\n",
       "      <td>https://images.gr-assets.com/books/1361039443m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1361039443s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  book_id  best_book_id  work_id  books_count       isbn        isbn13  \\\n",
       "0   0  2767052       2767052  2792775          272  439023483  9.780439e+12   \n",
       "1   1        3             3  4640799          491  439554934  9.780440e+12   \n",
       "2   2    41865         41865  3212258          226  316015849  9.780316e+12   \n",
       "\n",
       "                       authors  original_publication_year  \\\n",
       "0              Suzanne Collins                     2008.0   \n",
       "1  J.K. Rowling, Mary GrandPré                     1997.0   \n",
       "2              Stephenie Meyer                     2005.0   \n",
       "\n",
       "                             original_title  \\\n",
       "0                          The Hunger Games   \n",
       "1  Harry Potter and the Philosopher's Stone   \n",
       "2                                  Twilight   \n",
       "\n",
       "                                               title language_code  \\\n",
       "0            The Hunger Games (The Hunger Games, #1)           eng   \n",
       "1  Harry Potter and the Sorcerer's Stone (Harry P...           eng   \n",
       "2                            Twilight (Twilight, #1)         en-US   \n",
       "\n",
       "   average_rating  ratings_count  work_ratings_count  work_text_reviews_count  \\\n",
       "0            4.34        4780653             4942365                   155254   \n",
       "1            4.44        4602479             4800065                    75867   \n",
       "2            3.57        3866839             3916824                    95009   \n",
       "\n",
       "   ratings_1  ratings_2  ratings_3  ratings_4  ratings_5  \\\n",
       "0      66715     127936     560092    1481305    2706317   \n",
       "1      75504     101676     455024    1156318    3011543   \n",
       "2     456191     436802     793319     875073    1355439   \n",
       "\n",
       "                                           image_url  \\\n",
       "0  https://images.gr-assets.com/books/1447303603m...   \n",
       "1  https://images.gr-assets.com/books/1474154022m...   \n",
       "2  https://images.gr-assets.com/books/1361039443m...   \n",
       "\n",
       "                                     small_image_url  \n",
       "0  https://images.gr-assets.com/books/1447303603s...  \n",
       "1  https://images.gr-assets.com/books/1474154022s...  \n",
       "2  https://images.gr-assets.com/books/1361039443s...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------ratings--------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>313</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>438</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>587</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id  user_id  rating\n",
       "0        0      313       5\n",
       "1        0      438       3\n",
       "2        0      587       5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------tags--------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag_id</th>\n",
       "      <th>tag_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>--1-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>--10-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tag_id tag_name\n",
       "0       0        -\n",
       "1       1     --1-\n",
       "2       2    --10-"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------to_read--------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  book_id\n",
       "0        0      111\n",
       "1        0      234\n",
       "2        0      532"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------user_latent--------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>u_latent_1</th>\n",
       "      <th>u_latent_2</th>\n",
       "      <th>u_latent_3</th>\n",
       "      <th>u_latent_4</th>\n",
       "      <th>u_latent_5</th>\n",
       "      <th>u_latent_6</th>\n",
       "      <th>u_latent_7</th>\n",
       "      <th>u_latent_8</th>\n",
       "      <th>u_latent_9</th>\n",
       "      <th>u_latent_10</th>\n",
       "      <th>u_latent_11</th>\n",
       "      <th>u_latent_12</th>\n",
       "      <th>u_latent_13</th>\n",
       "      <th>u_latent_14</th>\n",
       "      <th>u_latent_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.199595</td>\n",
       "      <td>-0.108096</td>\n",
       "      <td>0.247037</td>\n",
       "      <td>0.208254</td>\n",
       "      <td>0.106582</td>\n",
       "      <td>-0.123816</td>\n",
       "      <td>0.125920</td>\n",
       "      <td>0.384342</td>\n",
       "      <td>0.611112</td>\n",
       "      <td>-0.349587</td>\n",
       "      <td>-0.031930</td>\n",
       "      <td>-0.156987</td>\n",
       "      <td>0.041728</td>\n",
       "      <td>0.185200</td>\n",
       "      <td>-0.358743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.212097</td>\n",
       "      <td>-0.068822</td>\n",
       "      <td>0.102718</td>\n",
       "      <td>0.252274</td>\n",
       "      <td>-0.133377</td>\n",
       "      <td>-0.093753</td>\n",
       "      <td>-0.558407</td>\n",
       "      <td>0.492150</td>\n",
       "      <td>-0.254548</td>\n",
       "      <td>-0.076484</td>\n",
       "      <td>-0.131823</td>\n",
       "      <td>-0.259838</td>\n",
       "      <td>-0.156847</td>\n",
       "      <td>0.019408</td>\n",
       "      <td>-0.642446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.057435</td>\n",
       "      <td>-0.006853</td>\n",
       "      <td>0.118266</td>\n",
       "      <td>0.120967</td>\n",
       "      <td>-0.020337</td>\n",
       "      <td>-0.095097</td>\n",
       "      <td>-0.039628</td>\n",
       "      <td>0.067750</td>\n",
       "      <td>0.028180</td>\n",
       "      <td>0.038364</td>\n",
       "      <td>0.013028</td>\n",
       "      <td>-0.054933</td>\n",
       "      <td>-0.047005</td>\n",
       "      <td>0.054901</td>\n",
       "      <td>-0.032876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  u_latent_1  u_latent_2  u_latent_3  u_latent_4  u_latent_5  u_latent_6  \\\n",
       "0   0    0.199595   -0.108096    0.247037    0.208254    0.106582   -0.123816   \n",
       "1   1   -0.212097   -0.068822    0.102718    0.252274   -0.133377   -0.093753   \n",
       "2   2   -0.057435   -0.006853    0.118266    0.120967   -0.020337   -0.095097   \n",
       "\n",
       "   u_latent_7  u_latent_8  u_latent_9  u_latent_10  u_latent_11  u_latent_12  \\\n",
       "0    0.125920    0.384342    0.611112    -0.349587    -0.031930    -0.156987   \n",
       "1   -0.558407    0.492150   -0.254548    -0.076484    -0.131823    -0.259838   \n",
       "2   -0.039628    0.067750    0.028180     0.038364     0.013028    -0.054933   \n",
       "\n",
       "   u_latent_13  u_latent_14  u_latent_15  \n",
       "0     0.041728     0.185200    -0.358743  \n",
       "1    -0.156847     0.019408    -0.642446  \n",
       "2    -0.047005     0.054901    -0.032876  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------item_latent--------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>i_latent_1</th>\n",
       "      <th>i_latent_2</th>\n",
       "      <th>i_latent_3</th>\n",
       "      <th>i_latent_4</th>\n",
       "      <th>i_latent_5</th>\n",
       "      <th>i_latent_6</th>\n",
       "      <th>i_latent_7</th>\n",
       "      <th>i_latent_8</th>\n",
       "      <th>i_latent_9</th>\n",
       "      <th>i_latent_10</th>\n",
       "      <th>i_latent_11</th>\n",
       "      <th>i_latent_12</th>\n",
       "      <th>i_latent_13</th>\n",
       "      <th>i_latent_14</th>\n",
       "      <th>i_latent_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.900808</td>\n",
       "      <td>0.380494</td>\n",
       "      <td>0.661577</td>\n",
       "      <td>-0.665127</td>\n",
       "      <td>-0.355070</td>\n",
       "      <td>0.904718</td>\n",
       "      <td>0.856841</td>\n",
       "      <td>0.359961</td>\n",
       "      <td>-0.945763</td>\n",
       "      <td>-0.005923</td>\n",
       "      <td>0.378899</td>\n",
       "      <td>-0.479288</td>\n",
       "      <td>-0.702245</td>\n",
       "      <td>-0.751551</td>\n",
       "      <td>-0.541900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.694283</td>\n",
       "      <td>0.602090</td>\n",
       "      <td>0.477443</td>\n",
       "      <td>-0.531324</td>\n",
       "      <td>-0.125256</td>\n",
       "      <td>0.900841</td>\n",
       "      <td>1.043496</td>\n",
       "      <td>0.370730</td>\n",
       "      <td>-1.422744</td>\n",
       "      <td>-0.050342</td>\n",
       "      <td>0.366465</td>\n",
       "      <td>-0.751425</td>\n",
       "      <td>-0.551353</td>\n",
       "      <td>-0.573139</td>\n",
       "      <td>-0.660848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.265569</td>\n",
       "      <td>0.245617</td>\n",
       "      <td>0.385378</td>\n",
       "      <td>-0.438928</td>\n",
       "      <td>0.333491</td>\n",
       "      <td>0.216258</td>\n",
       "      <td>-0.090325</td>\n",
       "      <td>0.468572</td>\n",
       "      <td>-0.925843</td>\n",
       "      <td>-0.116226</td>\n",
       "      <td>0.675204</td>\n",
       "      <td>-0.455215</td>\n",
       "      <td>-0.768754</td>\n",
       "      <td>-0.879207</td>\n",
       "      <td>-0.654471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  i_latent_1  i_latent_2  i_latent_3  i_latent_4  i_latent_5  i_latent_6  \\\n",
       "0   0    1.900808    0.380494    0.661577   -0.665127   -0.355070    0.904718   \n",
       "1   1    1.694283    0.602090    0.477443   -0.531324   -0.125256    0.900841   \n",
       "2   2    1.265569    0.245617    0.385378   -0.438928    0.333491    0.216258   \n",
       "\n",
       "   i_latent_7  i_latent_8  i_latent_9  i_latent_10  i_latent_11  i_latent_12  \\\n",
       "0    0.856841    0.359961   -0.945763    -0.005923     0.378899    -0.479288   \n",
       "1    1.043496    0.370730   -1.422744    -0.050342     0.366465    -0.751425   \n",
       "2   -0.090325    0.468572   -0.925843    -0.116226     0.675204    -0.455215   \n",
       "\n",
       "   i_latent_13  i_latent_14  i_latent_15  \n",
       "0    -0.702245    -0.751551    -0.541900  \n",
       "1    -0.551353    -0.573139    -0.660848  \n",
       "2    -0.768754    -0.879207    -0.654471  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('--------------book_tags--------------')\n",
    "display(book_tags.head(3))\n",
    "print('--------------books--------------')\n",
    "display(books.head(3))\n",
    "print('--------------ratings--------------')\n",
    "display(ratings.head(3))\n",
    "print('--------------tags--------------')\n",
    "display(tags.head(3))\n",
    "print('--------------to_read--------------')\n",
    "display(to_read.head(3))\n",
    "print('--------------user_latent--------------')\n",
    "display(user_latent.head(3))\n",
    "print('--------------item_latent--------------')\n",
    "display(item_latent.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49531767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         book_id\n",
       "user_id         \n",
       "0              3\n",
       "1              3\n",
       "2              2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_rating_counts = ratings[['user_id','book_id']].groupby('user_id').agg('count')\n",
    "user_rating_counts.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43197e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>234</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>532</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1197</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1873</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2057</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>3333</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  book_id  rank\n",
       "0        0      111   1.0\n",
       "1        0      234   2.0\n",
       "2        0      532   3.0\n",
       "3        0     1197   4.0\n",
       "4        0     1873   5.0\n",
       "5        0     2057   6.0\n",
       "6        0     3333   7.0\n",
       "7        1        3   1.0\n",
       "8        1       10   2.0\n",
       "9        1       12   3.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_read['rank'] = to_read.groupby('user_id')['book_id'].rank('dense')\n",
    "to_read.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "462d0b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>117889</th>\n",
       "      <td>1179</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488112</th>\n",
       "      <td>4892</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625717</th>\n",
       "      <td>6284</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796318</th>\n",
       "      <td>8033</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875008</th>\n",
       "      <td>8854</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959821</th>\n",
       "      <td>9761</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890007</th>\n",
       "      <td>9013</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893311</th>\n",
       "      <td>9048</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326891</th>\n",
       "      <td>3272</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837459</th>\n",
       "      <td>8463</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        book_id  user_id  rating  rank\n",
       "117889     1179        0       4   1.0\n",
       "488112     4892        0       3   2.0\n",
       "625717     6284        0       4   3.0\n",
       "796318     8033        1       4   1.0\n",
       "875008     8854        1       5   2.0\n",
       "959821     9761        1       4   3.0\n",
       "890007     9013        2       1   1.0\n",
       "893311     9048        2       1   2.0\n",
       "326891     3272        3       2   1.0\n",
       "837459     8463        3       5   3.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings['rank'] = ratings.groupby('user_id')['book_id'].rank('dense')\n",
    "ratings.sort_values(by='user_id').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "033a92ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>original_title</th>\n",
       "      <th>authors</th>\n",
       "      <th>original_publication_year</th>\n",
       "      <th>language_code</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>to_read_book_id</th>\n",
       "      <th>u_latent_1</th>\n",
       "      <th>u_latent_2</th>\n",
       "      <th>u_latent_3</th>\n",
       "      <th>u_latent_4</th>\n",
       "      <th>u_latent_5</th>\n",
       "      <th>u_latent_6</th>\n",
       "      <th>u_latent_7</th>\n",
       "      <th>u_latent_8</th>\n",
       "      <th>u_latent_9</th>\n",
       "      <th>u_latent_10</th>\n",
       "      <th>u_latent_11</th>\n",
       "      <th>u_latent_12</th>\n",
       "      <th>u_latent_13</th>\n",
       "      <th>u_latent_14</th>\n",
       "      <th>u_latent_15</th>\n",
       "      <th>i_latent_1</th>\n",
       "      <th>i_latent_2</th>\n",
       "      <th>i_latent_3</th>\n",
       "      <th>i_latent_4</th>\n",
       "      <th>i_latent_5</th>\n",
       "      <th>i_latent_6</th>\n",
       "      <th>i_latent_7</th>\n",
       "      <th>i_latent_8</th>\n",
       "      <th>i_latent_9</th>\n",
       "      <th>i_latent_10</th>\n",
       "      <th>i_latent_11</th>\n",
       "      <th>i_latent_12</th>\n",
       "      <th>i_latent_13</th>\n",
       "      <th>i_latent_14</th>\n",
       "      <th>i_latent_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>eng</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4780653</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.565416</td>\n",
       "      <td>0.546839</td>\n",
       "      <td>0.256609</td>\n",
       "      <td>-1.007740</td>\n",
       "      <td>-0.473202</td>\n",
       "      <td>0.049479</td>\n",
       "      <td>0.280110</td>\n",
       "      <td>0.210727</td>\n",
       "      <td>-0.532448</td>\n",
       "      <td>-0.860113</td>\n",
       "      <td>0.335041</td>\n",
       "      <td>0.148334</td>\n",
       "      <td>-0.337264</td>\n",
       "      <td>-0.586449</td>\n",
       "      <td>-0.603003</td>\n",
       "      <td>1.900808</td>\n",
       "      <td>0.380494</td>\n",
       "      <td>0.661577</td>\n",
       "      <td>-0.665127</td>\n",
       "      <td>-0.35507</td>\n",
       "      <td>0.904718</td>\n",
       "      <td>0.856841</td>\n",
       "      <td>0.359961</td>\n",
       "      <td>-0.945763</td>\n",
       "      <td>-0.005923</td>\n",
       "      <td>0.378899</td>\n",
       "      <td>-0.479288</td>\n",
       "      <td>-0.702245</td>\n",
       "      <td>-0.751551</td>\n",
       "      <td>-0.5419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>438</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>eng</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4780653</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.811270</td>\n",
       "      <td>0.483355</td>\n",
       "      <td>0.393725</td>\n",
       "      <td>-0.617435</td>\n",
       "      <td>0.300784</td>\n",
       "      <td>0.259413</td>\n",
       "      <td>0.422586</td>\n",
       "      <td>0.058931</td>\n",
       "      <td>-0.734391</td>\n",
       "      <td>-0.499431</td>\n",
       "      <td>-0.014451</td>\n",
       "      <td>0.281844</td>\n",
       "      <td>-0.162854</td>\n",
       "      <td>0.475232</td>\n",
       "      <td>-0.825033</td>\n",
       "      <td>1.900808</td>\n",
       "      <td>0.380494</td>\n",
       "      <td>0.661577</td>\n",
       "      <td>-0.665127</td>\n",
       "      <td>-0.35507</td>\n",
       "      <td>0.904718</td>\n",
       "      <td>0.856841</td>\n",
       "      <td>0.359961</td>\n",
       "      <td>-0.945763</td>\n",
       "      <td>-0.005923</td>\n",
       "      <td>0.378899</td>\n",
       "      <td>-0.479288</td>\n",
       "      <td>-0.702245</td>\n",
       "      <td>-0.751551</td>\n",
       "      <td>-0.5419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>587</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>eng</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4780653</td>\n",
       "      <td>2115.0</td>\n",
       "      <td>0.683785</td>\n",
       "      <td>0.593587</td>\n",
       "      <td>0.700573</td>\n",
       "      <td>-0.508013</td>\n",
       "      <td>-1.182165</td>\n",
       "      <td>-0.424068</td>\n",
       "      <td>0.672739</td>\n",
       "      <td>-0.196326</td>\n",
       "      <td>-0.031572</td>\n",
       "      <td>-0.659620</td>\n",
       "      <td>-0.111626</td>\n",
       "      <td>-0.663243</td>\n",
       "      <td>-0.828182</td>\n",
       "      <td>0.270393</td>\n",
       "      <td>-0.394489</td>\n",
       "      <td>1.900808</td>\n",
       "      <td>0.380494</td>\n",
       "      <td>0.661577</td>\n",
       "      <td>-0.665127</td>\n",
       "      <td>-0.35507</td>\n",
       "      <td>0.904718</td>\n",
       "      <td>0.856841</td>\n",
       "      <td>0.359961</td>\n",
       "      <td>-0.945763</td>\n",
       "      <td>-0.005923</td>\n",
       "      <td>0.378899</td>\n",
       "      <td>-0.479288</td>\n",
       "      <td>-0.702245</td>\n",
       "      <td>-0.751551</td>\n",
       "      <td>-0.5419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id book_id  rating    original_title          authors  \\\n",
       "0     313       0       5  The Hunger Games  Suzanne Collins   \n",
       "1     438       0       3  The Hunger Games  Suzanne Collins   \n",
       "2     587       0       5  The Hunger Games  Suzanne Collins   \n",
       "\n",
       "   original_publication_year language_code  average_rating  ratings_count  \\\n",
       "0                     2008.0           eng            4.34        4780653   \n",
       "1                     2008.0           eng            4.34        4780653   \n",
       "2                     2008.0           eng            4.34        4780653   \n",
       "\n",
       "   to_read_book_id  u_latent_1  u_latent_2  u_latent_3  u_latent_4  \\\n",
       "0             10.0    0.565416    0.546839    0.256609   -1.007740   \n",
       "1            120.0    0.811270    0.483355    0.393725   -0.617435   \n",
       "2           2115.0    0.683785    0.593587    0.700573   -0.508013   \n",
       "\n",
       "   u_latent_5  u_latent_6  u_latent_7  u_latent_8  u_latent_9  u_latent_10  \\\n",
       "0   -0.473202    0.049479    0.280110    0.210727   -0.532448    -0.860113   \n",
       "1    0.300784    0.259413    0.422586    0.058931   -0.734391    -0.499431   \n",
       "2   -1.182165   -0.424068    0.672739   -0.196326   -0.031572    -0.659620   \n",
       "\n",
       "   u_latent_11  u_latent_12  u_latent_13  u_latent_14  u_latent_15  \\\n",
       "0     0.335041     0.148334    -0.337264    -0.586449    -0.603003   \n",
       "1    -0.014451     0.281844    -0.162854     0.475232    -0.825033   \n",
       "2    -0.111626    -0.663243    -0.828182     0.270393    -0.394489   \n",
       "\n",
       "   i_latent_1  i_latent_2  i_latent_3  i_latent_4  i_latent_5  i_latent_6  \\\n",
       "0    1.900808    0.380494    0.661577   -0.665127    -0.35507    0.904718   \n",
       "1    1.900808    0.380494    0.661577   -0.665127    -0.35507    0.904718   \n",
       "2    1.900808    0.380494    0.661577   -0.665127    -0.35507    0.904718   \n",
       "\n",
       "   i_latent_7  i_latent_8  i_latent_9  i_latent_10  i_latent_11  i_latent_12  \\\n",
       "0    0.856841    0.359961   -0.945763    -0.005923     0.378899    -0.479288   \n",
       "1    0.856841    0.359961   -0.945763    -0.005923     0.378899    -0.479288   \n",
       "2    0.856841    0.359961   -0.945763    -0.005923     0.378899    -0.479288   \n",
       "\n",
       "   i_latent_13  i_latent_14  i_latent_15  \n",
       "0    -0.702245    -0.751551      -0.5419  \n",
       "1    -0.702245    -0.751551      -0.5419  \n",
       "2    -0.702245    -0.751551      -0.5419  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "select A.user_id\n",
    "    , A.book_id\n",
    "    , A.rating\n",
    "    , B.original_title\n",
    "    , B.authors\n",
    "    , B.original_publication_year\n",
    "    , B.language_code\n",
    "    , B.average_rating\n",
    "    , B.ratings_count\n",
    "    , C.book_id as to_read_book_id\n",
    "    , D.*\n",
    "    , E.*\n",
    "from ratings A\n",
    "left join books B on A.book_id = B.id\n",
    "left join to_read C on A.user_id = C.user_id and A.rank = C.rank\n",
    "left join user_latent D on A.user_id = D.id\n",
    "left join item_latent E on A.book_id = E.id\n",
    "where B.language_code in ('eng','en-US','en-GB','en-CA')\n",
    "\"\"\"\n",
    "hybrid_data_base = pysqldf(query)\n",
    "hybrid_data_base = hybrid_data_base.drop(columns = ['id'])\n",
    "# hybrid_data_base[['user_id']] = 'u' + hybrid_data_base[['user_id']].astype(str)\n",
    "# hybrid_data_base[['book_id']] = 'b' + hybrid_data_base[['book_id']].astype(str)\n",
    "hybrid_data_base[['book_id','user_id','original_title']] = hybrid_data_base[['book_id','user_id','original_title']].astype(str)\n",
    "hybrid_data_base.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32ee8f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(981756, 42)\n",
      "(981756, 4)\n"
     ]
    }
   ],
   "source": [
    "print(hybrid_data_base.shape)\n",
    "print(ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2a3abee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'book_id', 'rating', 'original_title', 'authors',\n",
       "       'original_publication_year', 'language_code', 'average_rating',\n",
       "       'ratings_count', 'to_read_book_id', 'u_latent_1', 'u_latent_2',\n",
       "       'u_latent_3', 'u_latent_4', 'u_latent_5', 'u_latent_6', 'u_latent_7',\n",
       "       'u_latent_8', 'u_latent_9', 'u_latent_10', 'u_latent_11', 'u_latent_12',\n",
       "       'u_latent_13', 'u_latent_14', 'u_latent_15', 'i_latent_1', 'i_latent_2',\n",
       "       'i_latent_3', 'i_latent_4', 'i_latent_5', 'i_latent_6', 'i_latent_7',\n",
       "       'i_latent_8', 'i_latent_9', 'i_latent_10', 'i_latent_11', 'i_latent_12',\n",
       "       'i_latent_13', 'i_latent_14', 'i_latent_15'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_data_base.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9bc8ae",
   "metadata": {},
   "source": [
    "## Data Embedding Processing (Discontinued)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "051ed10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a1f3b9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_columns = ['u_latent_{}'.format(i for i in range(15))] + ['i_latent_{}'.format(i for i in range(15))]\n",
    "non_factor_columns = ['book_id', 'original_title', 'authors', 'original_publication_year',  \n",
    "                      'rating', 'average_rating', 'ratings_count', 'to_read_book_id']\n",
    "label_columns = 'to_read_book_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "27469352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_book_ids: 10000\n",
      "number_of_authors: 4664\n"
     ]
    }
   ],
   "source": [
    "\n",
    "number_of_book_ids = len(hybrid_data_base.book_id.unique())\n",
    "print('number_of_book_ids:', number_of_book_ids)\n",
    "number_of_authors = len(hybrid_data_base.authors.unique())\n",
    "print('number_of_authors:', number_of_authors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d4657aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_columns(args):\n",
    "    # create book_id feature column\n",
    "    book_id_column = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "        key = 'book_id',\n",
    "        hash_bucket_size = number_of_book_ids\n",
    "    )\n",
    "    # embed book_id into a lower dimensional representation\n",
    "    embedded_book_columns = tf.feature_column.embedding_column(\n",
    "        categorical_column = book_id_column,\n",
    "        dimension = args['book_id_embedding_dimensions']\n",
    "    )\n",
    "    \n",
    "    # create title feature column usng TF Hub\n",
    "    embedded_title_column = hub.text_embedding_column_v2(\n",
    "        key = 'oriinal_title',\n",
    "        module_path = \"https://tfhub.dev/google/nnlm-en-dim50-with-normalization/2\",\n",
    "        trainable = False\n",
    "    )\n",
    "    \n",
    "    #create author feature column\n",
    "    author_column = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "        key = 'authors',\n",
    "        hash_bucket_size = number_of_authors + 1\n",
    "    )\n",
    "    # embed author into a lower dimensional representative\n",
    "    embedded_author_column = tf.feature_column.embedding_column(\n",
    "        categorical_column = author_column,\n",
    "        dimension = args['author_embedding_dimensions']\n",
    "    )\n",
    "    \n",
    "    #create original publication year boundaries list \n",
    "    original_publication_year_boundaries = [-500, 500, 1000, 1500, 1600, 1700, 1800, 1900, 1950, \n",
    "                                            1960, 1970, 1980, 1990, 2000, 2005, 2010, 2015]\n",
    "    \n",
    "    # create original_publication_year feature column using raw data\n",
    "    original_publication_year_column = tf.feature_column.numeric_column(\n",
    "        key = 'original_publication_year'\n",
    "    )\n",
    "    \n",
    "    #create original_publication_year feature column using boundaries list\n",
    "    original_publication_year_bucketized = tf.feature_column.bucketized_column(\n",
    "        source_column = original_publication_year_column,\n",
    "        boundaries = original_publication_year_boundaries\n",
    "    )\n",
    "    \n",
    "    #create user and item factor feature columns from trained WALS model\n",
    "    user_factors = [tf.feature_column.numeric_column(key = 'u_latent_' + str(i)) for i in range(15)]\n",
    "    item_factors = [tf.feature_column.numeric_column(key = 'i_latent_' + str(i)) for i in range(15)]\n",
    "    rating_columns = tf.feature_column.numeric_column(key = 'rating')\n",
    "    average_rating_columns = tf.feature_column.numeric_column(key = 'average_rating')\n",
    "    ratings_count_columns = tf.feature_column.numeric_column(key = 'ratings_count')\n",
    "\n",
    "    feature_columns = [\n",
    "        embedded_book_columns,\n",
    "        embedded_title_column,\n",
    "        embedded_author_column,\n",
    "        original_publication_year_bucketized,\n",
    "        rating_columns,\n",
    "        average_rating_columns,\n",
    "        ratings_count_columns\n",
    "    ] + user_factors + item_factors \n",
    "    return feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1c1958d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[EmbeddingColumn(categorical_column=HashedCategoricalColumn(key='book_id', hash_bucket_size=10000, dtype=tf.string), dimension=1000, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x000002754C110100>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True, use_safe_embedding_lookup=True),\n",
       " _TextEmbeddingColumnV2(key='oriinal_title', module_path='https://tfhub.dev/google/nnlm-en-dim50-with-normalization/2', output_key=None, trainable=False),\n",
       " EmbeddingColumn(categorical_column=HashedCategoricalColumn(key='authors', hash_bucket_size=4665, dtype=tf.string), dimension=500, combiner='mean', initializer=<tensorflow.python.ops.init_ops.TruncatedNormal object at 0x000002754C110970>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True, use_safe_embedding_lookup=True),\n",
       " BucketizedColumn(source_column=NumericColumn(key='original_publication_year', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(-500, 500, 1000, 1500, 1600, 1700, 1800, 1900, 1950, 1960, 1970, 1980, 1990, 2000, 2005, 2010, 2015)),\n",
       " NumericColumn(key='rating', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='average_rating', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='ratings_count', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='u_latent_0', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='u_latent_1', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='u_latent_2', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='u_latent_3', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='u_latent_4', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='u_latent_5', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='u_latent_6', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='u_latent_7', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='u_latent_8', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='u_latent_9', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='u_latent_10', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='u_latent_11', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='u_latent_12', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='u_latent_13', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='u_latent_14', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='i_latent_0', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='i_latent_1', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='i_latent_2', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='i_latent_3', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='i_latent_4', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='i_latent_5', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='i_latent_6', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='i_latent_7', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='i_latent_8', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='i_latent_9', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='i_latent_10', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='i_latent_11', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='i_latent_12', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='i_latent_13', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='i_latent_14', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_para = {\n",
    "    'author_embedding_dimensions' : 500,\n",
    "    'book_id_embedding_dimensions' : 1000\n",
    "}\n",
    "create_feature_columns(feature_para)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c8986c",
   "metadata": {},
   "source": [
    "# Tensorflow-Recommender\n",
    "## **Ranking and Retrieval**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bcabf3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>original_title</th>\n",
       "      <th>authors</th>\n",
       "      <th>original_publication_year</th>\n",
       "      <th>language_code</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>to_read_book_id</th>\n",
       "      <th>u_latent_1</th>\n",
       "      <th>u_latent_2</th>\n",
       "      <th>u_latent_3</th>\n",
       "      <th>u_latent_4</th>\n",
       "      <th>u_latent_5</th>\n",
       "      <th>u_latent_6</th>\n",
       "      <th>u_latent_7</th>\n",
       "      <th>u_latent_8</th>\n",
       "      <th>u_latent_9</th>\n",
       "      <th>u_latent_10</th>\n",
       "      <th>u_latent_11</th>\n",
       "      <th>u_latent_12</th>\n",
       "      <th>u_latent_13</th>\n",
       "      <th>u_latent_14</th>\n",
       "      <th>u_latent_15</th>\n",
       "      <th>i_latent_1</th>\n",
       "      <th>i_latent_2</th>\n",
       "      <th>i_latent_3</th>\n",
       "      <th>i_latent_4</th>\n",
       "      <th>i_latent_5</th>\n",
       "      <th>i_latent_6</th>\n",
       "      <th>i_latent_7</th>\n",
       "      <th>i_latent_8</th>\n",
       "      <th>i_latent_9</th>\n",
       "      <th>i_latent_10</th>\n",
       "      <th>i_latent_11</th>\n",
       "      <th>i_latent_12</th>\n",
       "      <th>i_latent_13</th>\n",
       "      <th>i_latent_14</th>\n",
       "      <th>i_latent_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>eng</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4780653</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.565416</td>\n",
       "      <td>0.546839</td>\n",
       "      <td>0.256609</td>\n",
       "      <td>-1.007740</td>\n",
       "      <td>-0.473202</td>\n",
       "      <td>0.049479</td>\n",
       "      <td>0.280110</td>\n",
       "      <td>0.210727</td>\n",
       "      <td>-0.532448</td>\n",
       "      <td>-0.860113</td>\n",
       "      <td>0.335041</td>\n",
       "      <td>0.148334</td>\n",
       "      <td>-0.337264</td>\n",
       "      <td>-0.586449</td>\n",
       "      <td>-0.603003</td>\n",
       "      <td>1.900808</td>\n",
       "      <td>0.380494</td>\n",
       "      <td>0.661577</td>\n",
       "      <td>-0.665127</td>\n",
       "      <td>-0.35507</td>\n",
       "      <td>0.904718</td>\n",
       "      <td>0.856841</td>\n",
       "      <td>0.359961</td>\n",
       "      <td>-0.945763</td>\n",
       "      <td>-0.005923</td>\n",
       "      <td>0.378899</td>\n",
       "      <td>-0.479288</td>\n",
       "      <td>-0.702245</td>\n",
       "      <td>-0.751551</td>\n",
       "      <td>-0.5419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>438</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>eng</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4780653</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.811270</td>\n",
       "      <td>0.483355</td>\n",
       "      <td>0.393725</td>\n",
       "      <td>-0.617435</td>\n",
       "      <td>0.300784</td>\n",
       "      <td>0.259413</td>\n",
       "      <td>0.422586</td>\n",
       "      <td>0.058931</td>\n",
       "      <td>-0.734391</td>\n",
       "      <td>-0.499431</td>\n",
       "      <td>-0.014451</td>\n",
       "      <td>0.281844</td>\n",
       "      <td>-0.162854</td>\n",
       "      <td>0.475232</td>\n",
       "      <td>-0.825033</td>\n",
       "      <td>1.900808</td>\n",
       "      <td>0.380494</td>\n",
       "      <td>0.661577</td>\n",
       "      <td>-0.665127</td>\n",
       "      <td>-0.35507</td>\n",
       "      <td>0.904718</td>\n",
       "      <td>0.856841</td>\n",
       "      <td>0.359961</td>\n",
       "      <td>-0.945763</td>\n",
       "      <td>-0.005923</td>\n",
       "      <td>0.378899</td>\n",
       "      <td>-0.479288</td>\n",
       "      <td>-0.702245</td>\n",
       "      <td>-0.751551</td>\n",
       "      <td>-0.5419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>587</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>eng</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4780653</td>\n",
       "      <td>2115.0</td>\n",
       "      <td>0.683785</td>\n",
       "      <td>0.593587</td>\n",
       "      <td>0.700573</td>\n",
       "      <td>-0.508013</td>\n",
       "      <td>-1.182165</td>\n",
       "      <td>-0.424068</td>\n",
       "      <td>0.672739</td>\n",
       "      <td>-0.196326</td>\n",
       "      <td>-0.031572</td>\n",
       "      <td>-0.659620</td>\n",
       "      <td>-0.111626</td>\n",
       "      <td>-0.663243</td>\n",
       "      <td>-0.828182</td>\n",
       "      <td>0.270393</td>\n",
       "      <td>-0.394489</td>\n",
       "      <td>1.900808</td>\n",
       "      <td>0.380494</td>\n",
       "      <td>0.661577</td>\n",
       "      <td>-0.665127</td>\n",
       "      <td>-0.35507</td>\n",
       "      <td>0.904718</td>\n",
       "      <td>0.856841</td>\n",
       "      <td>0.359961</td>\n",
       "      <td>-0.945763</td>\n",
       "      <td>-0.005923</td>\n",
       "      <td>0.378899</td>\n",
       "      <td>-0.479288</td>\n",
       "      <td>-0.702245</td>\n",
       "      <td>-0.751551</td>\n",
       "      <td>-0.5419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id book_id  rating    original_title          authors  \\\n",
       "0     313       0       5  The Hunger Games  Suzanne Collins   \n",
       "1     438       0       3  The Hunger Games  Suzanne Collins   \n",
       "2     587       0       5  The Hunger Games  Suzanne Collins   \n",
       "\n",
       "   original_publication_year language_code  average_rating  ratings_count  \\\n",
       "0                     2008.0           eng            4.34        4780653   \n",
       "1                     2008.0           eng            4.34        4780653   \n",
       "2                     2008.0           eng            4.34        4780653   \n",
       "\n",
       "   to_read_book_id  u_latent_1  u_latent_2  u_latent_3  u_latent_4  \\\n",
       "0             10.0    0.565416    0.546839    0.256609   -1.007740   \n",
       "1            120.0    0.811270    0.483355    0.393725   -0.617435   \n",
       "2           2115.0    0.683785    0.593587    0.700573   -0.508013   \n",
       "\n",
       "   u_latent_5  u_latent_6  u_latent_7  u_latent_8  u_latent_9  u_latent_10  \\\n",
       "0   -0.473202    0.049479    0.280110    0.210727   -0.532448    -0.860113   \n",
       "1    0.300784    0.259413    0.422586    0.058931   -0.734391    -0.499431   \n",
       "2   -1.182165   -0.424068    0.672739   -0.196326   -0.031572    -0.659620   \n",
       "\n",
       "   u_latent_11  u_latent_12  u_latent_13  u_latent_14  u_latent_15  \\\n",
       "0     0.335041     0.148334    -0.337264    -0.586449    -0.603003   \n",
       "1    -0.014451     0.281844    -0.162854     0.475232    -0.825033   \n",
       "2    -0.111626    -0.663243    -0.828182     0.270393    -0.394489   \n",
       "\n",
       "   i_latent_1  i_latent_2  i_latent_3  i_latent_4  i_latent_5  i_latent_6  \\\n",
       "0    1.900808    0.380494    0.661577   -0.665127    -0.35507    0.904718   \n",
       "1    1.900808    0.380494    0.661577   -0.665127    -0.35507    0.904718   \n",
       "2    1.900808    0.380494    0.661577   -0.665127    -0.35507    0.904718   \n",
       "\n",
       "   i_latent_7  i_latent_8  i_latent_9  i_latent_10  i_latent_11  i_latent_12  \\\n",
       "0    0.856841    0.359961   -0.945763    -0.005923     0.378899    -0.479288   \n",
       "1    0.856841    0.359961   -0.945763    -0.005923     0.378899    -0.479288   \n",
       "2    0.856841    0.359961   -0.945763    -0.005923     0.378899    -0.479288   \n",
       "\n",
       "   i_latent_13  i_latent_14  i_latent_15  \n",
       "0    -0.702245    -0.751551      -0.5419  \n",
       "1    -0.702245    -0.751551      -0.5419  \n",
       "2    -0.702245    -0.751551      -0.5419  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_data_base.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c6f5b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id                       object\n",
       "book_id                       object\n",
       "rating                         int64\n",
       "original_title                object\n",
       "authors                       object\n",
       "original_publication_year    float64\n",
       "language_code                 object\n",
       "average_rating               float64\n",
       "ratings_count                  int64\n",
       "to_read_book_id              float64\n",
       "u_latent_1                   float64\n",
       "u_latent_2                   float64\n",
       "u_latent_3                   float64\n",
       "u_latent_4                   float64\n",
       "u_latent_5                   float64\n",
       "u_latent_6                   float64\n",
       "u_latent_7                   float64\n",
       "u_latent_8                   float64\n",
       "u_latent_9                   float64\n",
       "u_latent_10                  float64\n",
       "u_latent_11                  float64\n",
       "u_latent_12                  float64\n",
       "u_latent_13                  float64\n",
       "u_latent_14                  float64\n",
       "u_latent_15                  float64\n",
       "i_latent_1                   float64\n",
       "i_latent_2                   float64\n",
       "i_latent_3                   float64\n",
       "i_latent_4                   float64\n",
       "i_latent_5                   float64\n",
       "i_latent_6                   float64\n",
       "i_latent_7                   float64\n",
       "i_latent_8                   float64\n",
       "i_latent_9                   float64\n",
       "i_latent_10                  float64\n",
       "i_latent_11                  float64\n",
       "i_latent_12                  float64\n",
       "i_latent_13                  float64\n",
       "i_latent_14                  float64\n",
       "i_latent_15                  float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_data_base.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84ae16f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings_df = hybrid_data_base[['user_id','book_id']].drop_duplicates()\n",
    "# users_df = ratings_df['user_id'].unique()\n",
    "# books_df = ratings_df['book_id'].unique()\n",
    "\n",
    "# ratings_ds = tf.data.Dataset.from_tensor_slices(dict(ratings_df))\n",
    "# books_ds = tf.data.Dataset.from_tensor_slices(books_df)\n",
    "\n",
    "# tf.random.set_seed(42)\n",
    "# shuffled = ratings_ds.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "# train = shuffled.take(60_000)\n",
    "# test = shuffled.skip(60_000).take(20_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9244e0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "### define interactions data and user data\n",
    "\n",
    "### interactions \n",
    "### here we create a reference table of the user , item, and quantity purchased\n",
    "interactions_dict = hybrid_data_base.groupby(['user_id', 'book_id'])['rating'].sum().reset_index()\n",
    "\n",
    "## we tansform the table inta a dictionary , which then we feed into tensor slices\n",
    "# this step is crucial as this will be the type of data fed into the embedding layers\n",
    "interactions_dict = {name: np.array(value) for name, value in interactions_dict.items()}\n",
    "interactions = tf.data.Dataset.from_tensor_slices(interactions_dict)\n",
    "\n",
    "## we do similar step for item, where this is the reference table for items to be recommended\n",
    "items_dict = hybrid_data_base[['book_id']].drop_duplicates()\n",
    "items_dict = {name: np.array(value) for name, value in items_dict.items()}\n",
    "items = tf.data.Dataset.from_tensor_slices(items_dict)\n",
    "\n",
    "## map the features in interactions and items to an identifier that we will use throught the embedding layers\n",
    "## do it for all the items in interaction and item table\n",
    "## you may often get itemtype error, so that is why here i am casting the quantity type as float to ensure consistency\n",
    "interactions = interactions.map(lambda x: {\n",
    "    'user_id' : x['user_id'], \n",
    "    'book_id' : x['book_id'],\n",
    "    'rating' : float(x['rating'])\n",
    "\n",
    "})\n",
    "\n",
    "items = items.map(lambda x: x['book_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "110aa7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_item_titles = np.unique(np.concatenate(list(items.batch(1000))))\n",
    "unique_user_ids = np.unique(np.concatenate(list(interactions.batch(1_000).map(lambda x: x[\"user_id\"]))))\n",
    "\n",
    "# Randomly shuffle data and split between train and test.\n",
    "tf.random.set_seed(42)\n",
    "shuffled = interactions.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(60_000)\n",
    "test = shuffled.skip(60_000).take(20_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23031c54",
   "metadata": {},
   "source": [
    "\n",
    "### Retrieval Model — Fitting and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a9cc7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Text\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8733584c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetailModel(tfrs.Model):\n",
    "\n",
    "    def __init__(self, user_model, item_model):\n",
    "        super().__init__()\n",
    "        \n",
    "        ### Candidate model (item)\n",
    "        ### This is Keras preprocessing layers to first convert user ids to integers, \n",
    "        ### and then convert those to user embeddings via an Embedding layer. \n",
    "        ### We use the list of unique user ids we computed earlier as a vocabulary:\n",
    "        item_model = tf.keras.Sequential([\n",
    "                                        tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                                        vocabulary=unique_item_titles, mask_token=None),\n",
    "                                        tf.keras.layers.Embedding(len(unique_item_titles) + 1, embedding_dimension)\n",
    "                                        ])\n",
    "        ### we pass the embedding layer into item model\n",
    "        self.item_model: tf.keras.Model = item_model\n",
    "            \n",
    "        ### Query model (users)    \n",
    "        user_model = tf.keras.Sequential([\n",
    "                                        tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                                        vocabulary=unique_user_ids, mask_token=None),\n",
    "                                        # We add an additional embedding to account for unknown tokens.\n",
    "                                        tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "                                        ])\n",
    "        self.user_model: tf.keras.Model = user_model\n",
    "        \n",
    "        ### for retrieval model. we take top-k accuracy as metrics\n",
    "        metrics = tfrs.metrics.FactorizedTopK(\n",
    "                                            candidates=items.batch(128).map(item_model)\n",
    "        )\n",
    "        task = tfrs.tasks.Retrieval(\n",
    "                                    metrics=metrics\n",
    "                                    )\n",
    "       \n",
    "        self.task: tf.keras.layers.Layer = task\n",
    "\n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "        # We pick out the user features and pass them into the user model.\n",
    "        user_embeddings = self.user_model(features[\"user_id\"])\n",
    "        # And pick out the movie features and pass them into the movie model,\n",
    "        # getting embeddings back.\n",
    "        book_embeddings = self.item_model(features[\"book_id\"])\n",
    "\n",
    "        # The task computes the loss and the metrics.\n",
    "        return self.task(user_embeddings, book_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "039af814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 17s 2s/step - factorized_top_k/top_1_categorical_accuracy: 3.3333e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0039 - factorized_top_k/top_10_categorical_accuracy: 0.0085 - factorized_top_k/top_50_categorical_accuracy: 0.0404 - factorized_top_k/top_100_categorical_accuracy: 0.0753 - loss: 61981.7630 - regularization_loss: 0.0000e+00 - total_loss: 61981.7630\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 15s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0091 - factorized_top_k/top_5_categorical_accuracy: 0.0457 - factorized_top_k/top_10_categorical_accuracy: 0.0791 - factorized_top_k/top_50_categorical_accuracy: 0.2460 - factorized_top_k/top_100_categorical_accuracy: 0.3770 - loss: 59479.7665 - regularization_loss: 0.0000e+00 - total_loss: 59479.7665\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 17s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0314 - factorized_top_k/top_5_categorical_accuracy: 0.1079 - factorized_top_k/top_10_categorical_accuracy: 0.1642 - factorized_top_k/top_50_categorical_accuracy: 0.3883 - factorized_top_k/top_100_categorical_accuracy: 0.5365 - loss: 55697.3155 - regularization_loss: 0.0000e+00 - total_loss: 55697.3155\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 15s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0534 - factorized_top_k/top_5_categorical_accuracy: 0.1635 - factorized_top_k/top_10_categorical_accuracy: 0.2365 - factorized_top_k/top_50_categorical_accuracy: 0.4942 - factorized_top_k/top_100_categorical_accuracy: 0.6389 - loss: 52575.4054 - regularization_loss: 0.0000e+00 - total_loss: 52575.4054\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 15s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0608 - factorized_top_k/top_5_categorical_accuracy: 0.1964 - factorized_top_k/top_10_categorical_accuracy: 0.2796 - factorized_top_k/top_50_categorical_accuracy: 0.5557 - factorized_top_k/top_100_categorical_accuracy: 0.6989 - loss: 50024.9724 - regularization_loss: 0.0000e+00 - total_loss: 50024.9724\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 15s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0671 - factorized_top_k/top_5_categorical_accuracy: 0.2180 - factorized_top_k/top_10_categorical_accuracy: 0.3074 - factorized_top_k/top_50_categorical_accuracy: 0.5952 - factorized_top_k/top_100_categorical_accuracy: 0.7353 - loss: 47984.8655 - regularization_loss: 0.0000e+00 - total_loss: 47984.8655\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 15s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0670 - factorized_top_k/top_5_categorical_accuracy: 0.2320 - factorized_top_k/top_10_categorical_accuracy: 0.3277 - factorized_top_k/top_50_categorical_accuracy: 0.6232 - factorized_top_k/top_100_categorical_accuracy: 0.7613 - loss: 46420.2758 - regularization_loss: 0.0000e+00 - total_loss: 46420.2758\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 15s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0680 - factorized_top_k/top_5_categorical_accuracy: 0.2437 - factorized_top_k/top_10_categorical_accuracy: 0.3453 - factorized_top_k/top_50_categorical_accuracy: 0.6436 - factorized_top_k/top_100_categorical_accuracy: 0.7786 - loss: 45249.8624 - regularization_loss: 0.0000e+00 - total_loss: 45249.8624\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 15s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0700 - factorized_top_k/top_5_categorical_accuracy: 0.2528 - factorized_top_k/top_10_categorical_accuracy: 0.3570 - factorized_top_k/top_50_categorical_accuracy: 0.6599 - factorized_top_k/top_100_categorical_accuracy: 0.7920 - loss: 44367.9319 - regularization_loss: 0.0000e+00 - total_loss: 44367.9319\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 15s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0704 - factorized_top_k/top_5_categorical_accuracy: 0.2588 - factorized_top_k/top_10_categorical_accuracy: 0.3670 - factorized_top_k/top_50_categorical_accuracy: 0.6723 - factorized_top_k/top_100_categorical_accuracy: 0.8019 - loss: 43688.1764 - regularization_loss: 0.0000e+00 - total_loss: 43688.1764\n",
      "5/5 [==============================] - 5s 916ms/step - factorized_top_k/top_1_categorical_accuracy: 6.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0157 - factorized_top_k/top_10_categorical_accuracy: 0.0408 - factorized_top_k/top_50_categorical_accuracy: 0.1813 - factorized_top_k/top_100_categorical_accuracy: 0.3032 - loss: 32273.5410 - regularization_loss: 0.0000e+00 - total_loss: 32273.5410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'factorized_top_k/top_1_categorical_accuracy': 0.0006000000284984708,\n",
       " 'factorized_top_k/top_5_categorical_accuracy': 0.015699999406933784,\n",
       " 'factorized_top_k/top_10_categorical_accuracy': 0.04084999859333038,\n",
       " 'factorized_top_k/top_50_categorical_accuracy': 0.1813499927520752,\n",
       " 'factorized_top_k/top_100_categorical_accuracy': 0.30320000648498535,\n",
       " 'loss': 29743.26171875,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 29743.26171875}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Fitting and evaluating\n",
    "\n",
    "### we choose the dimensionality of the query and candicate representation.\n",
    "embedding_dimension = 32\n",
    "\n",
    "## we pass the model, which is the same model we created in the query and candidate tower, into the model\n",
    "item_model = tf.keras.Sequential([\n",
    "                                tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                                vocabulary=unique_item_titles, mask_token=None),\n",
    "                                tf.keras.layers.Embedding(len(unique_item_titles) + 1, embedding_dimension)\n",
    "                                ])\n",
    "\n",
    "user_model = tf.keras.Sequential([\n",
    "                                tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                                vocabulary=unique_user_ids, mask_token=None),\n",
    "                                # We add an additional embedding to account for unknown tokens.\n",
    "                                tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "                                ])\n",
    "\n",
    "model = RetailModel(user_model, item_model)\n",
    "\n",
    "# a smaller learning rate may make the model move slower and prone to overfitting, so we stick to 0.1\n",
    "# other optimizers, such as SGD and Adam, are listed here https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
    "\n",
    "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()\n",
    "\n",
    "## fit the model with ten epochs\n",
    "model_hist = model.fit(cached_train, epochs=10)\n",
    "\n",
    "#evaluate the model\n",
    "model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "332534ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 4s 860ms/step - factorized_top_k/top_1_categorical_accuracy: 6.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0157 - factorized_top_k/top_10_categorical_accuracy: 0.0408 - factorized_top_k/top_50_categorical_accuracy: 0.1813 - factorized_top_k/top_100_categorical_accuracy: 0.3032 - loss: 32273.5410 - regularization_loss: 0.0000e+00 - total_loss: 32273.5410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'factorized_top_k/top_1_categorical_accuracy': 0.0006000000284984708,\n",
       " 'factorized_top_k/top_5_categorical_accuracy': 0.015699999406933784,\n",
       " 'factorized_top_k/top_10_categorical_accuracy': 0.04084999859333038,\n",
       " 'factorized_top_k/top_50_categorical_accuracy': 0.1813499927520752,\n",
       " 'factorized_top_k/top_100_categorical_accuracy': 0.30320000648498535,\n",
       " 'loss': 29743.26171875,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 29743.26171875}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f62c5a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x291aa43e550>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# num_validation_runs = len(one_layer_history.history[\"val_factorized_top_k/top_100_categorical_accuracy\"])\n",
    "epochs = [i for i in range(10)]\n",
    "\n",
    "plt.plot(epochs, model_hist.history[\"factorized_top_k/top_100_categorical_accuracy\"], label=\"accuracy\")\n",
    "plt.title(\"Accuracy vs epoch\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"Top-100 accuracy\");\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba92bccf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Attempt to convert a value (<MapDataset shapes: (None, 32), types: tf.float32>) with an unsupported type (<class 'tensorflow.python.data.ops.dataset_ops.MapDataset'>) to a Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-bfb2413e91ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfactorized_top_k\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBruteForce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# recommends movies out of the entire movies dataset.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Get recommendations.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\tensorflow_recommenders\\layers\\factorized_top_k.py\u001b[0m in \u001b[0;36mindex\u001b[1;34m(self, candidates, identifiers)\u001b[0m\n\u001b[0;32m    517\u001b[0m       \u001b[0midentifiers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    520\u001b[0m       raise ValueError(\n\u001b[0;32m    521\u001b[0m           f\"The candidates tensor must be 2D (got {candidates.shape}).\")\n",
      "\u001b[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mrank\u001b[1;34m(input, name)\u001b[0m\n\u001b[0;32m    837\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mend_compatibility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    838\u001b[0m   \"\"\"\n\u001b[1;32m--> 839\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mrank_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mrank_internal\u001b[1;34m(input, name, optimize)\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m       \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0moptimize\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1565\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1566\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1567\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1568\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    344\u001b[0m                                          as_ref=False):\n\u001b[0;32m    345\u001b[0m   \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m   \"\"\"\n\u001b[1;32m--> 271\u001b[1;33m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[0;32m    272\u001b[0m                         allow_broadcast=True)\n\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    281\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tf.constant\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m   \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m   \u001b[1;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m   \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    309\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Attempt to convert a value (<MapDataset shapes: (None, 32), types: tf.float32>) with an unsupported type (<class 'tensorflow.python.data.ops.dataset_ops.MapDataset'>) to a Tensor."
     ]
    }
   ],
   "source": [
    "# Create a model that takes in raw query features, and\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model, k = 100)\n",
    "# recommends movies out of the entire movies dataset.\n",
    "index.index(items.batch(100).map(model.item_model), items)\n",
    "\n",
    "# Get recommendations.\n",
    "j = str(40)\n",
    "_, titles = index(tf.constant([j]))\n",
    "print(f\"Recommendations for user %s: {titles[0]}\" %(j))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ff3111",
   "metadata": {},
   "source": [
    "### Ranking Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "77648823",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankingModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        embedding_dimension = 32\n",
    "\n",
    "        # Compute embeddings for users.\n",
    "        self.user_embeddings = tf.keras.Sequential([\n",
    "          tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "            vocabulary=unique_user_ids, mask_token=None),\n",
    "          tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        # Compute embeddings for movies.\n",
    "        self.movie_embeddings = tf.keras.Sequential([\n",
    "          tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "            vocabulary=unique_item_titles, mask_token=None),\n",
    "          tf.keras.layers.Embedding(len(unique_item_titles) + 1, embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        # Compute predictions.\n",
    "        self.ratings = tf.keras.Sequential([\n",
    "          # Learn multiple dense layers.\n",
    "          tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "          tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "          # Make rating predictions in the final layer.\n",
    "          tf.keras.layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        user_id, book_title = inputs\n",
    "\n",
    "        user_embedding = self.user_embeddings(user_id)\n",
    "        book_embedding = self.movie_embeddings(book_title)\n",
    "\n",
    "        return self.ratings(tf.concat([user_embedding, book_embedding], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3bb8569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>original_title</th>\n",
       "      <th>authors</th>\n",
       "      <th>original_publication_year</th>\n",
       "      <th>language_code</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>to_read_book_id</th>\n",
       "      <th>u_latent_1</th>\n",
       "      <th>u_latent_2</th>\n",
       "      <th>u_latent_3</th>\n",
       "      <th>u_latent_4</th>\n",
       "      <th>u_latent_5</th>\n",
       "      <th>u_latent_6</th>\n",
       "      <th>u_latent_7</th>\n",
       "      <th>u_latent_8</th>\n",
       "      <th>u_latent_9</th>\n",
       "      <th>u_latent_10</th>\n",
       "      <th>u_latent_11</th>\n",
       "      <th>u_latent_12</th>\n",
       "      <th>u_latent_13</th>\n",
       "      <th>u_latent_14</th>\n",
       "      <th>u_latent_15</th>\n",
       "      <th>i_latent_1</th>\n",
       "      <th>i_latent_2</th>\n",
       "      <th>i_latent_3</th>\n",
       "      <th>i_latent_4</th>\n",
       "      <th>i_latent_5</th>\n",
       "      <th>i_latent_6</th>\n",
       "      <th>i_latent_7</th>\n",
       "      <th>i_latent_8</th>\n",
       "      <th>i_latent_9</th>\n",
       "      <th>i_latent_10</th>\n",
       "      <th>i_latent_11</th>\n",
       "      <th>i_latent_12</th>\n",
       "      <th>i_latent_13</th>\n",
       "      <th>i_latent_14</th>\n",
       "      <th>i_latent_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>eng</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4780653</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.565416</td>\n",
       "      <td>0.546839</td>\n",
       "      <td>0.256609</td>\n",
       "      <td>-1.007740</td>\n",
       "      <td>-0.473202</td>\n",
       "      <td>0.049479</td>\n",
       "      <td>0.280110</td>\n",
       "      <td>0.210727</td>\n",
       "      <td>-0.532448</td>\n",
       "      <td>-0.860113</td>\n",
       "      <td>0.335041</td>\n",
       "      <td>0.148334</td>\n",
       "      <td>-0.337264</td>\n",
       "      <td>-0.586449</td>\n",
       "      <td>-0.603003</td>\n",
       "      <td>1.900808</td>\n",
       "      <td>0.380494</td>\n",
       "      <td>0.661577</td>\n",
       "      <td>-0.665127</td>\n",
       "      <td>-0.35507</td>\n",
       "      <td>0.904718</td>\n",
       "      <td>0.856841</td>\n",
       "      <td>0.359961</td>\n",
       "      <td>-0.945763</td>\n",
       "      <td>-0.005923</td>\n",
       "      <td>0.378899</td>\n",
       "      <td>-0.479288</td>\n",
       "      <td>-0.702245</td>\n",
       "      <td>-0.751551</td>\n",
       "      <td>-0.5419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>438</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>eng</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4780653</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.811270</td>\n",
       "      <td>0.483355</td>\n",
       "      <td>0.393725</td>\n",
       "      <td>-0.617435</td>\n",
       "      <td>0.300784</td>\n",
       "      <td>0.259413</td>\n",
       "      <td>0.422586</td>\n",
       "      <td>0.058931</td>\n",
       "      <td>-0.734391</td>\n",
       "      <td>-0.499431</td>\n",
       "      <td>-0.014451</td>\n",
       "      <td>0.281844</td>\n",
       "      <td>-0.162854</td>\n",
       "      <td>0.475232</td>\n",
       "      <td>-0.825033</td>\n",
       "      <td>1.900808</td>\n",
       "      <td>0.380494</td>\n",
       "      <td>0.661577</td>\n",
       "      <td>-0.665127</td>\n",
       "      <td>-0.35507</td>\n",
       "      <td>0.904718</td>\n",
       "      <td>0.856841</td>\n",
       "      <td>0.359961</td>\n",
       "      <td>-0.945763</td>\n",
       "      <td>-0.005923</td>\n",
       "      <td>0.378899</td>\n",
       "      <td>-0.479288</td>\n",
       "      <td>-0.702245</td>\n",
       "      <td>-0.751551</td>\n",
       "      <td>-0.5419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>587</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>eng</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4780653</td>\n",
       "      <td>2115.0</td>\n",
       "      <td>0.683785</td>\n",
       "      <td>0.593587</td>\n",
       "      <td>0.700573</td>\n",
       "      <td>-0.508013</td>\n",
       "      <td>-1.182165</td>\n",
       "      <td>-0.424068</td>\n",
       "      <td>0.672739</td>\n",
       "      <td>-0.196326</td>\n",
       "      <td>-0.031572</td>\n",
       "      <td>-0.659620</td>\n",
       "      <td>-0.111626</td>\n",
       "      <td>-0.663243</td>\n",
       "      <td>-0.828182</td>\n",
       "      <td>0.270393</td>\n",
       "      <td>-0.394489</td>\n",
       "      <td>1.900808</td>\n",
       "      <td>0.380494</td>\n",
       "      <td>0.661577</td>\n",
       "      <td>-0.665127</td>\n",
       "      <td>-0.35507</td>\n",
       "      <td>0.904718</td>\n",
       "      <td>0.856841</td>\n",
       "      <td>0.359961</td>\n",
       "      <td>-0.945763</td>\n",
       "      <td>-0.005923</td>\n",
       "      <td>0.378899</td>\n",
       "      <td>-0.479288</td>\n",
       "      <td>-0.702245</td>\n",
       "      <td>-0.751551</td>\n",
       "      <td>-0.5419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id book_id  rating    original_title          authors  \\\n",
       "0     313       0       5  The Hunger Games  Suzanne Collins   \n",
       "1     438       0       3  The Hunger Games  Suzanne Collins   \n",
       "2     587       0       5  The Hunger Games  Suzanne Collins   \n",
       "\n",
       "   original_publication_year language_code  average_rating  ratings_count  \\\n",
       "0                     2008.0           eng            4.34        4780653   \n",
       "1                     2008.0           eng            4.34        4780653   \n",
       "2                     2008.0           eng            4.34        4780653   \n",
       "\n",
       "   to_read_book_id  u_latent_1  u_latent_2  u_latent_3  u_latent_4  \\\n",
       "0             10.0    0.565416    0.546839    0.256609   -1.007740   \n",
       "1            120.0    0.811270    0.483355    0.393725   -0.617435   \n",
       "2           2115.0    0.683785    0.593587    0.700573   -0.508013   \n",
       "\n",
       "   u_latent_5  u_latent_6  u_latent_7  u_latent_8  u_latent_9  u_latent_10  \\\n",
       "0   -0.473202    0.049479    0.280110    0.210727   -0.532448    -0.860113   \n",
       "1    0.300784    0.259413    0.422586    0.058931   -0.734391    -0.499431   \n",
       "2   -1.182165   -0.424068    0.672739   -0.196326   -0.031572    -0.659620   \n",
       "\n",
       "   u_latent_11  u_latent_12  u_latent_13  u_latent_14  u_latent_15  \\\n",
       "0     0.335041     0.148334    -0.337264    -0.586449    -0.603003   \n",
       "1    -0.014451     0.281844    -0.162854     0.475232    -0.825033   \n",
       "2    -0.111626    -0.663243    -0.828182     0.270393    -0.394489   \n",
       "\n",
       "   i_latent_1  i_latent_2  i_latent_3  i_latent_4  i_latent_5  i_latent_6  \\\n",
       "0    1.900808    0.380494    0.661577   -0.665127    -0.35507    0.904718   \n",
       "1    1.900808    0.380494    0.661577   -0.665127    -0.35507    0.904718   \n",
       "2    1.900808    0.380494    0.661577   -0.665127    -0.35507    0.904718   \n",
       "\n",
       "   i_latent_7  i_latent_8  i_latent_9  i_latent_10  i_latent_11  i_latent_12  \\\n",
       "0    0.856841    0.359961   -0.945763    -0.005923     0.378899    -0.479288   \n",
       "1    0.856841    0.359961   -0.945763    -0.005923     0.378899    -0.479288   \n",
       "2    0.856841    0.359961   -0.945763    -0.005923     0.378899    -0.479288   \n",
       "\n",
       "   i_latent_13  i_latent_14  i_latent_15  \n",
       "0    -0.702245    -0.751551      -0.5419  \n",
       "1    -0.702245    -0.751551      -0.5419  \n",
       "2    -0.702245    -0.751551      -0.5419  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_data_base.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7371948a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: ['313']\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: ['The Hunger Games']\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-0.01187348]], dtype=float32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RankingModel()(([\"313\"], [\"The Hunger Games\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "952ea3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetailModel(tfrs.models.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ranking_model: tf.keras.Model = RankingModel()\n",
    "        self.task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "          loss = tf.keras.losses.MeanSquaredError(),\n",
    "          metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "        )\n",
    "\n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "        rating_predictions = self.ranking_model(\n",
    "            (features[\"user_id\"], features[\"book_id\"]))\n",
    "\n",
    "        # The task computes the loss and the metrics.\n",
    "        return self.task(labels=features[\"rating\"], predictions=rating_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d2d436d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 3s 45ms/step - root_mean_squared_error: 4.5021 - loss: 17.5704 - regularization_loss: 0.0000e+00 - total_loss: 17.5704\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 25ms/step - root_mean_squared_error: 1.8056 - loss: 3.0255 - regularization_loss: 0.0000e+00 - total_loss: 3.0255\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 26ms/step - root_mean_squared_error: 1.0900 - loss: 1.1631 - regularization_loss: 0.0000e+00 - total_loss: 1.1631\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 24ms/step - root_mean_squared_error: 1.0010 - loss: 1.0099 - regularization_loss: 0.0000e+00 - total_loss: 1.0099\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 24ms/step - root_mean_squared_error: 0.9993 - loss: 1.0063 - regularization_loss: 0.0000e+00 - total_loss: 1.0063\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 27ms/step - root_mean_squared_error: 0.9973 - loss: 1.0019 - regularization_loss: 0.0000e+00 - total_loss: 1.0019\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 27ms/step - root_mean_squared_error: 0.9943 - loss: 0.9949 - regularization_loss: 0.0000e+00 - total_loss: 0.9949\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 24ms/step - root_mean_squared_error: 0.9895 - loss: 0.9842 - regularization_loss: 0.0000e+00 - total_loss: 0.9842\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 25ms/step - root_mean_squared_error: 0.9823 - loss: 0.9683 - regularization_loss: 0.0000e+00 - total_loss: 0.9683\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 27ms/step - root_mean_squared_error: 0.9723 - loss: 0.9464 - regularization_loss: 0.0000e+00 - total_loss: 0.9464\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 25ms/step - root_mean_squared_error: 0.9599 - loss: 0.9195 - regularization_loss: 0.0000e+00 - total_loss: 0.9195\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 24ms/step - root_mean_squared_error: 0.9460 - loss: 0.8901 - regularization_loss: 0.0000e+00 - total_loss: 0.8901\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 26ms/step - root_mean_squared_error: 0.9323 - loss: 0.8612 - regularization_loss: 0.0000e+00 - total_loss: 0.8612\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 27ms/step - root_mean_squared_error: 0.9196 - loss: 0.8345 - regularization_loss: 0.0000e+00 - total_loss: 0.8345\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 26ms/step - root_mean_squared_error: 0.9082 - loss: 0.8105 - regularization_loss: 0.0000e+00 - total_loss: 0.8105\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 24ms/step - root_mean_squared_error: 0.8978 - loss: 0.7886 - regularization_loss: 0.0000e+00 - total_loss: 0.7886\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 29ms/step - root_mean_squared_error: 0.8882 - loss: 0.7682 - regularization_loss: 0.0000e+00 - total_loss: 0.7682\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 25ms/step - root_mean_squared_error: 0.8790 - loss: 0.7489 - regularization_loss: 0.0000e+00 - total_loss: 0.7489\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 27ms/step - root_mean_squared_error: 0.8701 - loss: 0.7303 - regularization_loss: 0.0000e+00 - total_loss: 0.7303\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 25ms/step - root_mean_squared_error: 0.8612 - loss: 0.7120 - regularization_loss: 0.0000e+00 - total_loss: 0.7120\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 25ms/step - root_mean_squared_error: 0.8524 - loss: 0.6940 - regularization_loss: 0.0000e+00 - total_loss: 0.6940\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 25ms/step - root_mean_squared_error: 0.8435 - loss: 0.6762 - regularization_loss: 0.0000e+00 - total_loss: 0.6762\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 24ms/step - root_mean_squared_error: 0.8347 - loss: 0.6590 - regularization_loss: 0.0000e+00 - total_loss: 0.6590\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 25ms/step - root_mean_squared_error: 0.8261 - loss: 0.6424 - regularization_loss: 0.0000e+00 - total_loss: 0.6424\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 27ms/step - root_mean_squared_error: 0.8179 - loss: 0.6270 - regularization_loss: 0.0000e+00 - total_loss: 0.6270\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 25ms/step - root_mean_squared_error: 0.8103 - loss: 0.6128 - regularization_loss: 0.0000e+00 - total_loss: 0.6128\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 24ms/step - root_mean_squared_error: 0.8034 - loss: 0.6002 - regularization_loss: 0.0000e+00 - total_loss: 0.6002\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 29ms/step - root_mean_squared_error: 0.7972 - loss: 0.5892 - regularization_loss: 0.0000e+00 - total_loss: 0.5892\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 24ms/step - root_mean_squared_error: 0.7918 - loss: 0.5797 - regularization_loss: 0.0000e+00 - total_loss: 0.5797\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 25ms/step - root_mean_squared_error: 0.7871 - loss: 0.5717 - regularization_loss: 0.0000e+00 - total_loss: 0.5717\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 26ms/step - root_mean_squared_error: 0.7831 - loss: 0.5649 - regularization_loss: 0.0000e+00 - total_loss: 0.5649\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 28ms/step - root_mean_squared_error: 0.7796 - loss: 0.5591 - regularization_loss: 0.0000e+00 - total_loss: 0.5591\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 24ms/step - root_mean_squared_error: 0.7767 - loss: 0.5543 - regularization_loss: 0.0000e+00 - total_loss: 0.5543\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 24ms/step - root_mean_squared_error: 0.7741 - loss: 0.5502 - regularization_loss: 0.0000e+00 - total_loss: 0.5502\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 24ms/step - root_mean_squared_error: 0.7718 - loss: 0.5467 - regularization_loss: 0.0000e+00 - total_loss: 0.5467\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 25ms/step - root_mean_squared_error: 0.7698 - loss: 0.5436 - regularization_loss: 0.0000e+00 - total_loss: 0.5436\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 25ms/step - root_mean_squared_error: 0.7680 - loss: 0.5410 - regularization_loss: 0.0000e+00 - total_loss: 0.5410\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 24ms/step - root_mean_squared_error: 0.7665 - loss: 0.5387 - regularization_loss: 0.0000e+00 - total_loss: 0.5387\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 24ms/step - root_mean_squared_error: 0.7651 - loss: 0.5367 - regularization_loss: 0.0000e+00 - total_loss: 0.5367\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 26ms/step - root_mean_squared_error: 0.7638 - loss: 0.5349 - regularization_loss: 0.0000e+00 - total_loss: 0.5349\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 25ms/step - root_mean_squared_error: 0.7627 - loss: 0.5333 - regularization_loss: 0.0000e+00 - total_loss: 0.5333\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 25ms/step - root_mean_squared_error: 0.7617 - loss: 0.5319 - regularization_loss: 0.0000e+00 - total_loss: 0.5319\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 25ms/step - root_mean_squared_error: 0.7608 - loss: 0.5306 - regularization_loss: 0.0000e+00 - total_loss: 0.5306\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 24ms/step - root_mean_squared_error: 0.7599 - loss: 0.5295 - regularization_loss: 0.0000e+00 - total_loss: 0.5295\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 27ms/step - root_mean_squared_error: 0.7592 - loss: 0.5284 - regularization_loss: 0.0000e+00 - total_loss: 0.5284\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 25ms/step - root_mean_squared_error: 0.7585 - loss: 0.5275 - regularization_loss: 0.0000e+00 - total_loss: 0.5275\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 25ms/step - root_mean_squared_error: 0.7578 - loss: 0.5266 - regularization_loss: 0.0000e+00 - total_loss: 0.5266\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 24ms/step - root_mean_squared_error: 0.7572 - loss: 0.5258 - regularization_loss: 0.0000e+00 - total_loss: 0.5258\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 26ms/step - root_mean_squared_error: 0.7567 - loss: 0.5250 - regularization_loss: 0.0000e+00 - total_loss: 0.5250\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 24ms/step - root_mean_squared_error: 0.7562 - loss: 0.5244 - regularization_loss: 0.0000e+00 - total_loss: 0.5244\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 24ms/step - root_mean_squared_error: 0.7557 - loss: 0.5237 - regularization_loss: 0.0000e+00 - total_loss: 0.5237\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 24ms/step - root_mean_squared_error: 0.7552 - loss: 0.5231 - regularization_loss: 0.0000e+00 - total_loss: 0.5231\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 28ms/step - root_mean_squared_error: 0.7548 - loss: 0.5226 - regularization_loss: 0.0000e+00 - total_loss: 0.5226\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 29ms/step - root_mean_squared_error: 0.7544 - loss: 0.5221 - regularization_loss: 0.0000e+00 - total_loss: 0.5221\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 24ms/step - root_mean_squared_error: 0.7540 - loss: 0.5216 - regularization_loss: 0.0000e+00 - total_loss: 0.5216\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 23ms/step - root_mean_squared_error: 0.7537 - loss: 0.5211 - regularization_loss: 0.0000e+00 - total_loss: 0.5211\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 24ms/step - root_mean_squared_error: 0.7534 - loss: 0.5207 - regularization_loss: 0.0000e+00 - total_loss: 0.5207\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 35ms/step - root_mean_squared_error: 0.7531 - loss: 0.5203 - regularization_loss: 0.0000e+00 - total_loss: 0.5203\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 25ms/step - root_mean_squared_error: 0.7528 - loss: 0.5199 - regularization_loss: 0.0000e+00 - total_loss: 0.5199\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 24ms/step - root_mean_squared_error: 0.7525 - loss: 0.5195 - regularization_loss: 0.0000e+00 - total_loss: 0.5195\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 24ms/step - root_mean_squared_error: 0.7522 - loss: 0.5192 - regularization_loss: 0.0000e+00 - total_loss: 0.5192\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 31ms/step - root_mean_squared_error: 0.7520 - loss: 0.5189 - regularization_loss: 0.0000e+00 - total_loss: 0.5189\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 26ms/step - root_mean_squared_error: 0.7517 - loss: 0.5186 - regularization_loss: 0.0000e+00 - total_loss: 0.5186\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 24ms/step - root_mean_squared_error: 0.7515 - loss: 0.5183 - regularization_loss: 0.0000e+00 - total_loss: 0.5183\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 24ms/step - root_mean_squared_error: 0.7513 - loss: 0.5180 - regularization_loss: 0.0000e+00 - total_loss: 0.5180\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 27ms/step - root_mean_squared_error: 0.7511 - loss: 0.5177 - regularization_loss: 0.0000e+00 - total_loss: 0.5177\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 25ms/step - root_mean_squared_error: 0.7509 - loss: 0.5174 - regularization_loss: 0.0000e+00 - total_loss: 0.5174\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 23ms/step - root_mean_squared_error: 0.7507 - loss: 0.5172 - regularization_loss: 0.0000e+00 - total_loss: 0.5172\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 29ms/step - root_mean_squared_error: 0.7505 - loss: 0.5169 - regularization_loss: 0.0000e+00 - total_loss: 0.5169\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 24ms/step - root_mean_squared_error: 0.7503 - loss: 0.5167 - regularization_loss: 0.0000e+00 - total_loss: 0.5167\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 30ms/step - root_mean_squared_error: 0.7501 - loss: 0.5165 - regularization_loss: 0.0000e+00 - total_loss: 0.5165\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 24ms/step - root_mean_squared_error: 0.7500 - loss: 0.5163 - regularization_loss: 0.0000e+00 - total_loss: 0.5163\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 24ms/step - root_mean_squared_error: 0.7498 - loss: 0.5161 - regularization_loss: 0.0000e+00 - total_loss: 0.5161\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 24ms/step - root_mean_squared_error: 0.7497 - loss: 0.5159 - regularization_loss: 0.0000e+00 - total_loss: 0.5159\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 24ms/step - root_mean_squared_error: 0.7495 - loss: 0.5157 - regularization_loss: 0.0000e+00 - total_loss: 0.5157\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 24ms/step - root_mean_squared_error: 0.7494 - loss: 0.5155 - regularization_loss: 0.0000e+00 - total_loss: 0.5155\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 23ms/step - root_mean_squared_error: 0.7492 - loss: 0.5153 - regularization_loss: 0.0000e+00 - total_loss: 0.5153\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 24ms/step - root_mean_squared_error: 0.7491 - loss: 0.5151 - regularization_loss: 0.0000e+00 - total_loss: 0.5151\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 25ms/step - root_mean_squared_error: 0.7490 - loss: 0.5149 - regularization_loss: 0.0000e+00 - total_loss: 0.5149\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 23ms/step - root_mean_squared_error: 0.7488 - loss: 0.5148 - regularization_loss: 0.0000e+00 - total_loss: 0.5148\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 23ms/step - root_mean_squared_error: 0.7487 - loss: 0.5146 - regularization_loss: 0.0000e+00 - total_loss: 0.5146\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 24ms/step - root_mean_squared_error: 0.7486 - loss: 0.5144 - regularization_loss: 0.0000e+00 - total_loss: 0.5144\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 24ms/step - root_mean_squared_error: 0.7485 - loss: 0.5143 - regularization_loss: 0.0000e+00 - total_loss: 0.5143\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 23ms/step - root_mean_squared_error: 0.7484 - loss: 0.5141 - regularization_loss: 0.0000e+00 - total_loss: 0.5141\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 24ms/step - root_mean_squared_error: 0.7483 - loss: 0.5140 - regularization_loss: 0.0000e+00 - total_loss: 0.5140\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 24ms/step - root_mean_squared_error: 0.7481 - loss: 0.5138 - regularization_loss: 0.0000e+00 - total_loss: 0.5138\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 24ms/step - root_mean_squared_error: 0.7480 - loss: 0.5137 - regularization_loss: 0.0000e+00 - total_loss: 0.5137\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 25ms/step - root_mean_squared_error: 0.7479 - loss: 0.5136 - regularization_loss: 0.0000e+00 - total_loss: 0.5136\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 25ms/step - root_mean_squared_error: 0.7478 - loss: 0.5134 - regularization_loss: 0.0000e+00 - total_loss: 0.5134\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 24ms/step - root_mean_squared_error: 0.7477 - loss: 0.5133 - regularization_loss: 0.0000e+00 - total_loss: 0.5133\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 24ms/step - root_mean_squared_error: 0.7476 - loss: 0.5132 - regularization_loss: 0.0000e+00 - total_loss: 0.5132\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 25ms/step - root_mean_squared_error: 0.7476 - loss: 0.5130 - regularization_loss: 0.0000e+00 - total_loss: 0.5130\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 23ms/step - root_mean_squared_error: 0.7475 - loss: 0.5129 - regularization_loss: 0.0000e+00 - total_loss: 0.5129\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 24ms/step - root_mean_squared_error: 0.7474 - loss: 0.5128 - regularization_loss: 0.0000e+00 - total_loss: 0.5128\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 25ms/step - root_mean_squared_error: 0.7473 - loss: 0.5127 - regularization_loss: 0.0000e+00 - total_loss: 0.5127\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 25ms/step - root_mean_squared_error: 0.7472 - loss: 0.5126 - regularization_loss: 0.0000e+00 - total_loss: 0.5126\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 30ms/step - root_mean_squared_error: 0.7471 - loss: 0.5124 - regularization_loss: 0.0000e+00 - total_loss: 0.5124\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 23ms/step - root_mean_squared_error: 0.7470 - loss: 0.5123 - regularization_loss: 0.0000e+00 - total_loss: 0.5123\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 26ms/step - root_mean_squared_error: 0.7469 - loss: 0.5122 - regularization_loss: 0.0000e+00 - total_loss: 0.5122\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 27ms/step - root_mean_squared_error: 0.7469 - loss: 0.5121 - regularization_loss: 0.0000e+00 - total_loss: 0.5121\n",
      "5/5 [==============================] - 3s 78ms/step - root_mean_squared_error: 1.0152 - loss: 1.0284 - regularization_loss: 0.0000e+00 - total_loss: 1.0284\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'root_mean_squared_error': 1.0151989459991455,\n",
       " 'loss': 1.0186195373535156,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 1.0186195373535156}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RetailModel()\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.5))\n",
    "\n",
    "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()\n",
    "\n",
    "model.fit(cached_train, epochs=100)\n",
    "\n",
    "model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8966771b",
   "metadata": {},
   "source": [
    "### Adding Text and Time Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "45f7cf84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>original_title</th>\n",
       "      <th>authors</th>\n",
       "      <th>original_publication_year</th>\n",
       "      <th>language_code</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>to_read_book_id</th>\n",
       "      <th>u_latent_1</th>\n",
       "      <th>u_latent_2</th>\n",
       "      <th>u_latent_3</th>\n",
       "      <th>u_latent_4</th>\n",
       "      <th>u_latent_5</th>\n",
       "      <th>u_latent_6</th>\n",
       "      <th>u_latent_7</th>\n",
       "      <th>u_latent_8</th>\n",
       "      <th>u_latent_9</th>\n",
       "      <th>u_latent_10</th>\n",
       "      <th>u_latent_11</th>\n",
       "      <th>u_latent_12</th>\n",
       "      <th>u_latent_13</th>\n",
       "      <th>u_latent_14</th>\n",
       "      <th>u_latent_15</th>\n",
       "      <th>i_latent_1</th>\n",
       "      <th>i_latent_2</th>\n",
       "      <th>i_latent_3</th>\n",
       "      <th>i_latent_4</th>\n",
       "      <th>i_latent_5</th>\n",
       "      <th>i_latent_6</th>\n",
       "      <th>i_latent_7</th>\n",
       "      <th>i_latent_8</th>\n",
       "      <th>i_latent_9</th>\n",
       "      <th>i_latent_10</th>\n",
       "      <th>i_latent_11</th>\n",
       "      <th>i_latent_12</th>\n",
       "      <th>i_latent_13</th>\n",
       "      <th>i_latent_14</th>\n",
       "      <th>i_latent_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>eng</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4780653</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.565416</td>\n",
       "      <td>0.546839</td>\n",
       "      <td>0.256609</td>\n",
       "      <td>-1.007740</td>\n",
       "      <td>-0.473202</td>\n",
       "      <td>0.049479</td>\n",
       "      <td>0.280110</td>\n",
       "      <td>0.210727</td>\n",
       "      <td>-0.532448</td>\n",
       "      <td>-0.860113</td>\n",
       "      <td>0.335041</td>\n",
       "      <td>0.148334</td>\n",
       "      <td>-0.337264</td>\n",
       "      <td>-0.586449</td>\n",
       "      <td>-0.603003</td>\n",
       "      <td>1.900808</td>\n",
       "      <td>0.380494</td>\n",
       "      <td>0.661577</td>\n",
       "      <td>-0.665127</td>\n",
       "      <td>-0.35507</td>\n",
       "      <td>0.904718</td>\n",
       "      <td>0.856841</td>\n",
       "      <td>0.359961</td>\n",
       "      <td>-0.945763</td>\n",
       "      <td>-0.005923</td>\n",
       "      <td>0.378899</td>\n",
       "      <td>-0.479288</td>\n",
       "      <td>-0.702245</td>\n",
       "      <td>-0.751551</td>\n",
       "      <td>-0.5419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>438</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>eng</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4780653</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.811270</td>\n",
       "      <td>0.483355</td>\n",
       "      <td>0.393725</td>\n",
       "      <td>-0.617435</td>\n",
       "      <td>0.300784</td>\n",
       "      <td>0.259413</td>\n",
       "      <td>0.422586</td>\n",
       "      <td>0.058931</td>\n",
       "      <td>-0.734391</td>\n",
       "      <td>-0.499431</td>\n",
       "      <td>-0.014451</td>\n",
       "      <td>0.281844</td>\n",
       "      <td>-0.162854</td>\n",
       "      <td>0.475232</td>\n",
       "      <td>-0.825033</td>\n",
       "      <td>1.900808</td>\n",
       "      <td>0.380494</td>\n",
       "      <td>0.661577</td>\n",
       "      <td>-0.665127</td>\n",
       "      <td>-0.35507</td>\n",
       "      <td>0.904718</td>\n",
       "      <td>0.856841</td>\n",
       "      <td>0.359961</td>\n",
       "      <td>-0.945763</td>\n",
       "      <td>-0.005923</td>\n",
       "      <td>0.378899</td>\n",
       "      <td>-0.479288</td>\n",
       "      <td>-0.702245</td>\n",
       "      <td>-0.751551</td>\n",
       "      <td>-0.5419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>587</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>eng</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4780653</td>\n",
       "      <td>2115.0</td>\n",
       "      <td>0.683785</td>\n",
       "      <td>0.593587</td>\n",
       "      <td>0.700573</td>\n",
       "      <td>-0.508013</td>\n",
       "      <td>-1.182165</td>\n",
       "      <td>-0.424068</td>\n",
       "      <td>0.672739</td>\n",
       "      <td>-0.196326</td>\n",
       "      <td>-0.031572</td>\n",
       "      <td>-0.659620</td>\n",
       "      <td>-0.111626</td>\n",
       "      <td>-0.663243</td>\n",
       "      <td>-0.828182</td>\n",
       "      <td>0.270393</td>\n",
       "      <td>-0.394489</td>\n",
       "      <td>1.900808</td>\n",
       "      <td>0.380494</td>\n",
       "      <td>0.661577</td>\n",
       "      <td>-0.665127</td>\n",
       "      <td>-0.35507</td>\n",
       "      <td>0.904718</td>\n",
       "      <td>0.856841</td>\n",
       "      <td>0.359961</td>\n",
       "      <td>-0.945763</td>\n",
       "      <td>-0.005923</td>\n",
       "      <td>0.378899</td>\n",
       "      <td>-0.479288</td>\n",
       "      <td>-0.702245</td>\n",
       "      <td>-0.751551</td>\n",
       "      <td>-0.5419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id book_id  rating    original_title          authors  \\\n",
       "0     313       0       5  The Hunger Games  Suzanne Collins   \n",
       "1     438       0       3  The Hunger Games  Suzanne Collins   \n",
       "2     587       0       5  The Hunger Games  Suzanne Collins   \n",
       "\n",
       "   original_publication_year language_code  average_rating  ratings_count  \\\n",
       "0                     2008.0           eng            4.34        4780653   \n",
       "1                     2008.0           eng            4.34        4780653   \n",
       "2                     2008.0           eng            4.34        4780653   \n",
       "\n",
       "   to_read_book_id  u_latent_1  u_latent_2  u_latent_3  u_latent_4  \\\n",
       "0             10.0    0.565416    0.546839    0.256609   -1.007740   \n",
       "1            120.0    0.811270    0.483355    0.393725   -0.617435   \n",
       "2           2115.0    0.683785    0.593587    0.700573   -0.508013   \n",
       "\n",
       "   u_latent_5  u_latent_6  u_latent_7  u_latent_8  u_latent_9  u_latent_10  \\\n",
       "0   -0.473202    0.049479    0.280110    0.210727   -0.532448    -0.860113   \n",
       "1    0.300784    0.259413    0.422586    0.058931   -0.734391    -0.499431   \n",
       "2   -1.182165   -0.424068    0.672739   -0.196326   -0.031572    -0.659620   \n",
       "\n",
       "   u_latent_11  u_latent_12  u_latent_13  u_latent_14  u_latent_15  \\\n",
       "0     0.335041     0.148334    -0.337264    -0.586449    -0.603003   \n",
       "1    -0.014451     0.281844    -0.162854     0.475232    -0.825033   \n",
       "2    -0.111626    -0.663243    -0.828182     0.270393    -0.394489   \n",
       "\n",
       "   i_latent_1  i_latent_2  i_latent_3  i_latent_4  i_latent_5  i_latent_6  \\\n",
       "0    1.900808    0.380494    0.661577   -0.665127    -0.35507    0.904718   \n",
       "1    1.900808    0.380494    0.661577   -0.665127    -0.35507    0.904718   \n",
       "2    1.900808    0.380494    0.661577   -0.665127    -0.35507    0.904718   \n",
       "\n",
       "   i_latent_7  i_latent_8  i_latent_9  i_latent_10  i_latent_11  i_latent_12  \\\n",
       "0    0.856841    0.359961   -0.945763    -0.005923     0.378899    -0.479288   \n",
       "1    0.856841    0.359961   -0.945763    -0.005923     0.378899    -0.479288   \n",
       "2    0.856841    0.359961   -0.945763    -0.005923     0.378899    -0.479288   \n",
       "\n",
       "   i_latent_13  i_latent_14  i_latent_15  \n",
       "0    -0.702245    -0.751551      -0.5419  \n",
       "1    -0.702245    -0.751551      -0.5419  \n",
       "2    -0.702245    -0.751551      -0.5419  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_data_base.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "578df34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'original_title': array(['The Hunger Games', \"Harry Potter and the Philosopher's Stone\",\n",
       "        'Twilight', ..., 'Means of Ascent ', 'The Mauritius Command',\n",
       "        'Cinderella Ate My Daughter: Dispatches from the Frontlines of the New Girlie-Girl Culture'],\n",
       "       dtype=object)}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "abafff7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_id': array(['0', '0', '0', ..., '9997', '9999', '9999'], dtype=object),\n",
       " 'original_title': array(['Born on a Blue Day: Inside the Extraordinary Mind of an Autistic Savant',\n",
       "        \"Brunelleschi's Dome: How a Renaissance Genius Reinvented Architecture\",\n",
       "        'The Forty Rules of Love', ..., 'The Uncommon Reader ',\n",
       "        \"The Foot Book: Dr. Seuss's Wacky Book of Opposites (Bright & Early Board Books)\",\n",
       "        \"There's a Wocket in My Pocket\"], dtype=object),\n",
       " 'rating': array([4, 3, 4, ..., 3, 3, 4], dtype=int64)}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "081c4987",
   "metadata": {},
   "outputs": [],
   "source": [
    "### define interactions data and user data\n",
    "\n",
    "### interactions \n",
    "### here we create a reference table of the user , item, and quantity purchased\n",
    "interactions_dict = hybrid_data_base.groupby(['user_id', 'original_title'])['rating'].sum().reset_index()\n",
    "\n",
    "## we tansform the table inta a dictionary , which then we feed into tensor slices\n",
    "# this step is crucial as this will be the type of data fed into the embedding layers\n",
    "interactions_dict = {name: np.array(value) for name, value in interactions_dict.items()}\n",
    "interactions = tf.data.Dataset.from_tensor_slices(interactions_dict)\n",
    "\n",
    "## we do similar step for item, where this is the reference table for items to be recommended\n",
    "items_dict = hybrid_data_base[['original_title']].drop_duplicates()\n",
    "items_dict = {name: np.array(value) for name, value in items_dict.items()}\n",
    "items = tf.data.Dataset.from_tensor_slices(items_dict)\n",
    "\n",
    "## map the features in interactions and items to an identifier that we will use throught the embedding layers\n",
    "## do it for all the items in interaction and item table\n",
    "## you may often get itemtype error, so that is why here i am casting the quantity type as float to ensure consistency\n",
    "interactions = interactions.map(lambda x: {\n",
    "    'user_id' : x['user_id'], \n",
    "    'book_id' : x['original_title'],\n",
    "    'rating' : float(x['rating'])\n",
    "\n",
    "})\n",
    "\n",
    "items = items.map(lambda x: {\n",
    "    'book_id': x['original_title']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "cfb2afbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_titles = interactions.batch(10_000).map(lambda x: x[\"book_id\"])\n",
    "user_ids = interactions.batch(10_000).map(lambda x: x[\"user_id\"])\n",
    "\n",
    "# unique_item_titles = np.unique(np.concatenate(list(item_titles)))\n",
    "unique_item_titles = np.unique(np.concatenate(list(item_titles)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))\n",
    "\n",
    "# Randomly shuffle data and split between train and test.\n",
    "tf.random.set_seed(42)\n",
    "shuffled = interactions.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(60_000)\n",
    "test = shuffled.skip(60_000).take(20_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "580abab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = interactions.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(60_000)\n",
    "test = shuffled.skip(60_000).take(20_000)\n",
    "\n",
    "cached_train = train.shuffle(100_000).batch(2048)\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "abd5c81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        ## embed user id from unique_user_ids\n",
    "        self.user_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "                vocabulary=unique_user_ids, mask_token=None),\n",
    "            tf.keras.layers.Embedding(len(unique_user_ids) + 1, 32),\n",
    "        ])\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        ## all features here\n",
    "        return tf.concat([\n",
    "            self.user_embedding(inputs[\"user_id\"])\n",
    "        ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a0ea919a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        max_tokens = 10_000\n",
    "\n",
    "        ## embed title from unique_item_titles\n",
    "        self.title_embedding = tf.keras.Sequential([\n",
    "          tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "              vocabulary=unique_item_titles, mask_token=None),\n",
    "          tf.keras.layers.Embedding(len(unique_item_titles) + 1, 32)\n",
    "        ])\n",
    "\n",
    "        ## processing text features: item title vectorizer (see self.title_vectorizer)\n",
    "        self.title_vectorizer = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "            max_tokens=max_tokens)\n",
    "\n",
    "        ## we apply title vectorizer to items\n",
    "        self.title_text_embedding = tf.keras.Sequential([\n",
    "          self.title_vectorizer,\n",
    "          tf.keras.layers.Embedding(max_tokens, 32, mask_zero=True),\n",
    "          tf.keras.layers.GlobalAveragePooling1D(),\n",
    "        ])\n",
    "\n",
    "        self.title_vectorizer.adapt(items)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.concat([\n",
    "            self.title_embedding(inputs[\"book_id\"]),\n",
    "            self.title_text_embedding(inputs[\"book_id\"]),\n",
    "        ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "26b20ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetailModel(tfrs.models.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        ## query model is user model\n",
    "        self.query_model = tf.keras.Sequential([\n",
    "          UserModel(),\n",
    "          tf.keras.layers.Dense(32)\n",
    "        ])\n",
    "        \n",
    "        ## candidate model is the item model\n",
    "        self.candidate_model = tf.keras.Sequential([\n",
    "          ItemModel(),\n",
    "          tf.keras.layers.Dense(32)\n",
    "        ])\n",
    "        \n",
    "        ## retrieval task, choose metrics\n",
    "        self.task = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                candidates=items.batch(128).map(self.candidate_model),\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def compute_loss(self, features, training=False):\n",
    "        # We only pass the user id and timestamp features into the query model. This\n",
    "        # is to ensure that the training inputs would have the same keys as the\n",
    "        # query inputs. Otherwise the discrepancy in input structure would cause an\n",
    "        # error when loading the query model after saving it.\n",
    "        \n",
    "        query_embeddings = self.query_model({\n",
    "            \"user_id\": features[\"user_id\"]\n",
    "        })\n",
    "        \n",
    "        item_embeddings = self.candidate_model({\n",
    "            \"book_id\": features[\"book_id\"]\n",
    "        })\n",
    "\n",
    "        return self.task(query_embeddings, item_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "85c531fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    C:\\Users\\luoyan011\\.conda\\envs\\nlp\\lib\\site-packages\\keras\\engine\\base_preprocessing_layer.py:121 adapt_step  *\n        self._adapt_maybe_build(data)\n    C:\\Users\\luoyan011\\.conda\\envs\\nlp\\lib\\site-packages\\keras\\engine\\base_preprocessing_layer.py:284 _adapt_maybe_build  **\n        self.build(data_shape)\n    C:\\Users\\luoyan011\\.conda\\envs\\nlp\\lib\\site-packages\\keras\\layers\\preprocessing\\text_vectorization.py:415 build\n        if input_shape.ndims > 1 and not input_shape[-1] == 1:  # pylint: disable=g-comparison-negation\n\n    AttributeError: 'NoneType' object has no attribute 'ndims'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-157-850aaee5b2b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRetailModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdagrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcached_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcached_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-156-e8fee2529ebc>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m## candidate model is the item model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         self.candidate_model = tf.keras.Sequential([\n\u001b[1;32m---> 14\u001b[1;33m           \u001b[0mItemModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m           \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         ])\n",
      "\u001b[1;32m<ipython-input-155-90e4a6fe1e45>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     24\u001b[0m         ])\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle_vectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\keras\\engine\\base_preprocessing_layer.py\u001b[0m in \u001b[0;36madapt\u001b[1;34m(self, data, batch_size, steps)\u001b[0m\n\u001b[0;32m    246\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_adapt_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    757\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 759\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    760\u001b[0m             *args, **kwds))\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3065\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3066\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3067\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3463\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3298\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    992\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 994\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    995\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: in user code:\n\n    C:\\Users\\luoyan011\\.conda\\envs\\nlp\\lib\\site-packages\\keras\\engine\\base_preprocessing_layer.py:121 adapt_step  *\n        self._adapt_maybe_build(data)\n    C:\\Users\\luoyan011\\.conda\\envs\\nlp\\lib\\site-packages\\keras\\engine\\base_preprocessing_layer.py:284 _adapt_maybe_build  **\n        self.build(data_shape)\n    C:\\Users\\luoyan011\\.conda\\envs\\nlp\\lib\\site-packages\\keras\\layers\\preprocessing\\text_vectorization.py:415 build\n        if input_shape.ndims > 1 and not input_shape[-1] == 1:  # pylint: disable=g-comparison-negation\n\n    AttributeError: 'NoneType' object has no attribute 'ndims'\n"
     ]
    }
   ],
   "source": [
    "model = RetailModel()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "model.fit(cached_train, epochs=3)\n",
    "model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81baf243",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
