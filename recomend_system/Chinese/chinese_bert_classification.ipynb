{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2bf9056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import torch\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.optim import optimizer\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from torch.nn import CrossEntropyLoss,BCEWithLogitsLoss\n",
    "from tqdm import tqdm_notebook, trange\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM, BertForSequenceClassification\n",
    "from pytorch_pretrained_bert.optimization import BertAdam, WarmupLinearSchedule\n",
    "from sklearn.metrics import precision_recall_curve,classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "root_path = 'C:\\\\Users\\\\luoyan011\\\\Desktop\\\\PersonalLearning\\\\GitHub\\\\NLP_data\\\\simplifyweibo_4_moods'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40982c1f",
   "metadata": {},
   "source": [
    "Reference: https://zhuanlan.zhihu.com/p/72448986"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0404e796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9953</th>\n",
       "      <td>。胔 igh 啊。。。然后我被阿紫追问【您是有安装着怪逼搜索雷达摸】。。。</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3850</th>\n",
       "      <td>明天参加老爷子的遗体告别仪式。只希望所有人都坚强！</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4962</th>\n",
       "      <td>过了过了~ (投稿)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       text  label\n",
       "9953  。胔 igh 啊。。。然后我被阿紫追问【您是有安装着怪逼搜索雷达摸】。。。      2\n",
       "3850              明天参加老爷子的遗体告别仪式。只希望所有人都坚强！      2\n",
       "4962                             过了过了~ (投稿)      0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(os.path.join(root_path, \"weibo_sample_4mood.csv\"))\n",
    "data.columns = ['label','text']\n",
    "data = data[['text','label']]\n",
    "data.sample(3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a85aebbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9953</th>\n",
       "      <td>。胔 igh 啊。。。然后我被阿紫追问【您是有安装着怪逼搜索雷达摸】。。。</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3850</th>\n",
       "      <td>明天参加老爷子的遗体告别仪式。只希望所有人都坚强！</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4962</th>\n",
       "      <td>过了过了~ (投稿)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       text  label\n",
       "9953  。胔 igh 啊。。。然后我被阿紫追问【您是有安装着怪逼搜索雷达摸】。。。      2\n",
       "3850              明天参加老爷子的遗体告别仪式。只希望所有人都坚强！      2\n",
       "4962                             过了过了~ (投稿)      0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(data.label.tolist())\n",
    "data['label'] = le.transform(data.label.tolist())\n",
    "data.sample(3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21a72d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The pre-trained model you are loading is an uncased model but you have set `do_lower_case` to False. We are setting `do_lower_case=True` for you but you may want to check this behavior.\n",
      "100%|███████████████████████████████| 109540/109540 [00:00<00:00, 685778.35B/s]\n"
     ]
    }
   ],
   "source": [
    "# 分词工具\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-chinese', do_lower_case=False)\n",
    "\n",
    "# 封装类\n",
    "class DataPrecessForSingleSentence(object):\n",
    "    \"\"\"\n",
    "    对文本进行处理\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, bert_tokenizer, max_workers=10):\n",
    "        \"\"\"\n",
    "        bert_tokenizer :分词器\n",
    "        dataset        :包含列名为'text'与'label'的pandas dataframe\n",
    "        \"\"\"\n",
    "        self.bert_tokenizer = bert_tokenizer\n",
    "        # 创建多线程池\n",
    "        self.pool = ThreadPoolExecutor(max_workers=max_workers)\n",
    "        # 获取文本与标签\n",
    "\n",
    "    def get_input(self, dataset, max_seq_len=30):\n",
    "        \"\"\"\n",
    "        通过多线程（因为notebook中多进程使用存在一些问题）的方式对输入文本进行分词、ID化、截断、填充等流程得到最终的可用于模型输入的序列。\n",
    "        \n",
    "        入参:\n",
    "            dataset     : pandas的dataframe格式，包含两列，第一列为文本，第二列为标签。标签取值为{0,1}，其中0表示负样本，1代表正样本。\n",
    "            max_seq_len : 目标序列长度，该值需要预先对文本长度进行分别得到，可以设置为小于等于512（BERT的最长文本序列长度为512）的整数。\n",
    "        \n",
    "        出参:\n",
    "            seq         : 在入参seq的头尾分别拼接了'CLS'与'SEP'符号，如果长度仍小于max_seq_len，则使用0在尾部进行了填充。\n",
    "            seq_mask    : 只包含0、1且长度等于seq的序列，用于表征seq中的符号是否是有意义的，如果seq序列对应位上为填充符号，\n",
    "                          那么取值为1，否则为0。\n",
    "            seq_segment : shape等于seq，因为是单句，所以取值都为0。\n",
    "            labels      : 标签取值为{0,1}，其中0表示负样本，1代表正样本。\n",
    "        \n",
    "            \n",
    "        \"\"\"\n",
    "        sentences = dataset.iloc[:, 0].tolist()\n",
    "        labels = dataset.iloc[:, 1].tolist()\n",
    "        # 切词\n",
    "        tokens_seq = list(\n",
    "            self.pool.map(self.bert_tokenizer.tokenize, sentences))\n",
    "        # 获取定长序列及其mask\n",
    "        result = list(\n",
    "            self.pool.map(self.trunate_and_pad, tokens_seq,\n",
    "                          [max_seq_len] * len(tokens_seq)))\n",
    "        seqs = [i[0] for i in result]\n",
    "        seq_masks = [i[1] for i in result]\n",
    "        seq_segments = [i[2] for i in result]\n",
    "        return seqs, seq_masks, seq_segments, labels\n",
    "\n",
    "    def trunate_and_pad(self, seq, max_seq_len):\n",
    "        \"\"\"\n",
    "        1. 因为本类处理的是单句序列，按照BERT中的序列处理方式，需要在输入序列头尾分别拼接特殊字符'CLS'与'SEP'，\n",
    "           因此不包含两个特殊字符的序列长度应该小于等于max_seq_len-2，如果序列长度大于该值需要那么进行截断。\n",
    "        2. 对输入的序列 最终形成['CLS',seq,'SEP']的序列，该序列的长度如果小于max_seq_len，那么使用0进行填充。\n",
    "        \n",
    "        入参: \n",
    "            seq         : 输入序列，在本处其为单个句子。\n",
    "            max_seq_len : 拼接'CLS'与'SEP'这两个特殊字符后的序列长度\n",
    "        \n",
    "        出参:\n",
    "            seq         : 在入参seq的头尾分别拼接了'CLS'与'SEP'符号，如果长度仍小于max_seq_len，则使用0在尾部进行了填充。\n",
    "            seq_mask    : 只包含0、1且长度等于seq的序列，用于表征seq中的符号是否是有意义的，如果seq序列对应位上为填充符号，\n",
    "                          那么取值为1，否则为0。\n",
    "            seq_segment : shape等于seq，因为是单句，所以取值都为0。\n",
    "           \n",
    "        \"\"\"\n",
    "        # 对超长序列进行截断\n",
    "        if len(seq) > (max_seq_len - 2):\n",
    "            seq = seq[0:(max_seq_len - 2)]\n",
    "        # 分别在首尾拼接特殊符号\n",
    "        seq = ['[CLS]'] + seq + ['[SEP]']\n",
    "        # ID化\n",
    "        seq = self.bert_tokenizer.convert_tokens_to_ids(seq)\n",
    "        # 根据max_seq_len与seq的长度产生填充序列\n",
    "        padding = [0] * (max_seq_len - len(seq))\n",
    "        # 创建seq_mask\n",
    "        seq_mask = [1] * len(seq) + padding\n",
    "        # 创建seq_segment\n",
    "        seq_segment = [0] * len(seq) + padding\n",
    "        # 对seq拼接填充序列\n",
    "        seq += padding\n",
    "        assert len(seq) == max_seq_len\n",
    "        assert len(seq_mask) == max_seq_len\n",
    "        assert len(seq_segment) == max_seq_len\n",
    "        return seq, seq_mask, seq_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3e6d9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 类初始化\n",
    "processor = DataPrecessForSingleSentence(bert_tokenizer= bert_tokenizer)\n",
    "# 产生输入ju 数据\n",
    "seqs, seq_masks, seq_segments, labels = processor.get_input(\n",
    "    dataset=data\n",
    "    , max_seq_len=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4230e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                             | 0/382072689 [00:00<?, ?B/s]\u001b[A\n",
      "  0%|                             | 52224/382072689 [00:00<12:39, 502768.89B/s]\u001b[A\n",
      "  0%|                           | 329728/382072689 [00:00<03:48, 1670456.41B/s]\u001b[A\n",
      "  0%|                           | 870400/382072689 [00:00<02:03, 3090815.72B/s]\u001b[A\n",
      "  0%|                          | 1583104/382072689 [00:00<01:24, 4529231.04B/s]\u001b[A\n",
      "  1%|▏                         | 2429952/382072689 [00:00<01:07, 5597072.48B/s]\u001b[A\n",
      "  1%|▏                         | 3101696/382072689 [00:00<01:03, 5924659.35B/s]\u001b[A\n",
      "  1%|▎                         | 3958784/382072689 [00:00<00:58, 6460207.77B/s]\u001b[A\n",
      "  1%|▎                         | 4603904/382072689 [00:01<01:23, 4497046.70B/s]\u001b[A\n",
      "  2%|▍                         | 6411264/382072689 [00:01<00:50, 7511747.06B/s]\u001b[A\n",
      "  2%|▍                         | 7307264/382072689 [00:01<00:51, 7296942.20B/s]\u001b[A\n",
      "  2%|▌                         | 8136704/382072689 [00:01<00:51, 7247606.76B/s]\u001b[A\n",
      "  2%|▌                         | 8930304/382072689 [00:01<00:50, 7349420.20B/s]\u001b[A\n",
      "  3%|▋                         | 9714688/382072689 [00:01<01:18, 4758473.19B/s]\u001b[A\n",
      "  3%|▊                        | 11736064/382072689 [00:01<00:49, 7534323.84B/s]\u001b[A\n",
      "  3%|▊                        | 12706816/382072689 [00:02<00:49, 7494658.37B/s]\u001b[A\n",
      "  4%|▉                        | 13607936/382072689 [00:02<00:50, 7290259.53B/s]\u001b[A\n",
      "  4%|▉                        | 14441472/382072689 [00:02<00:52, 6971698.28B/s]\u001b[A\n",
      "  4%|▉                        | 15209472/382072689 [00:02<00:53, 6881795.79B/s]\u001b[A\n",
      "  4%|█                        | 15945728/382072689 [00:02<00:54, 6714182.28B/s]\u001b[A\n",
      "  4%|█                        | 16649216/382072689 [00:02<00:56, 6473974.32B/s]\u001b[A\n",
      "  5%|█▏                       | 17356800/382072689 [00:02<00:55, 6615722.21B/s]\u001b[A\n",
      "  5%|█▏                       | 18035712/382072689 [00:02<00:55, 6538317.25B/s]\u001b[A\n",
      "  5%|█▏                       | 18701312/382072689 [00:02<00:57, 6356729.74B/s]\u001b[A\n",
      "  5%|█▎                       | 19354624/382072689 [00:03<00:56, 6399052.10B/s]\u001b[A\n",
      "  5%|█▎                       | 20000768/382072689 [00:03<00:56, 6399008.05B/s]\u001b[A\n",
      "  5%|█▎                       | 20644864/382072689 [00:03<00:57, 6264692.79B/s]\u001b[A\n",
      "  6%|█▍                       | 21386240/382072689 [00:03<00:57, 6321243.99B/s]\u001b[A\n",
      "  6%|█▍                       | 22021120/382072689 [00:03<00:59, 6087217.96B/s]\u001b[A\n",
      "  6%|█▍                       | 22632448/382072689 [00:03<00:59, 6021087.52B/s]\u001b[A\n",
      "  6%|█▌                       | 23235584/382072689 [00:03<01:07, 5329197.39B/s]\u001b[A\n",
      "  6%|█▌                       | 23782400/382072689 [00:03<01:07, 5306924.85B/s]\u001b[A\n",
      "  6%|█▌                       | 24433664/382072689 [00:03<01:03, 5632326.75B/s]\u001b[A\n",
      "  7%|█▋                       | 25007104/382072689 [00:04<01:14, 4824447.06B/s]\u001b[A\n",
      "  7%|█▋                       | 25515008/382072689 [00:04<01:13, 4853540.97B/s]\u001b[A\n",
      "  7%|█▋                       | 26072064/382072689 [00:04<01:11, 5007613.82B/s]\u001b[A\n",
      "  7%|█▋                       | 26587136/382072689 [00:04<01:16, 4669670.15B/s]\u001b[A\n",
      "  7%|█▊                       | 27202560/382072689 [00:04<01:10, 5026671.29B/s]\u001b[A\n",
      "  7%|█▊                       | 27939840/382072689 [00:04<01:05, 5439456.07B/s]\u001b[A\n",
      "  8%|█▉                       | 28660736/382072689 [00:04<01:04, 5445880.75B/s]\u001b[A\n",
      "  8%|█▉                       | 29211648/382072689 [00:04<01:05, 5412740.89B/s]\u001b[A\n",
      "  8%|█▉                       | 29757440/382072689 [00:05<01:10, 5004451.47B/s]\u001b[A\n",
      "  8%|█▉                       | 30413824/382072689 [00:05<01:05, 5400389.67B/s]\u001b[A\n",
      "  8%|██                       | 31167488/382072689 [00:05<00:58, 5968690.92B/s]\u001b[A\n",
      "  8%|██                       | 31953920/382072689 [00:05<00:56, 6244772.23B/s]\u001b[A\n",
      "  9%|██▏                      | 32642048/382072689 [00:05<00:54, 6391568.60B/s]\u001b[A\n",
      "  9%|██▏                      | 33297408/382072689 [00:05<00:56, 6175891.14B/s]\u001b[A\n",
      "  9%|██▏                      | 34083840/382072689 [00:05<00:52, 6616437.63B/s]\u001b[A\n",
      "  9%|██▎                      | 34903040/382072689 [00:05<00:51, 6769724.78B/s]\u001b[A\n",
      "  9%|██▎                      | 35584000/382072689 [00:05<00:51, 6727961.78B/s]\u001b[A\n",
      "  9%|██▎                      | 36295680/382072689 [00:06<00:52, 6549261.96B/s]\u001b[A\n",
      " 10%|██▍                      | 37049344/382072689 [00:06<00:52, 6541620.29B/s]\u001b[A\n",
      " 10%|██▍                      | 37705728/382072689 [00:06<00:54, 6269685.70B/s]\u001b[A\n",
      " 10%|██▌                      | 38335488/382072689 [00:06<00:54, 6266046.79B/s]\u001b[A\n",
      " 10%|██▌                      | 38971392/382072689 [00:06<00:54, 6291956.87B/s]\u001b[A\n",
      " 10%|██▌                      | 39602176/382072689 [00:06<00:56, 6013454.23B/s]\u001b[A\n",
      " 11%|██▋                      | 40206336/382072689 [00:06<00:57, 5996491.36B/s]\u001b[A\n",
      " 11%|██▋                      | 40808448/382072689 [00:06<00:56, 5996936.57B/s]\u001b[A\n",
      " 11%|██▋                      | 41409536/382072689 [00:06<00:59, 5736770.77B/s]\u001b[A\n",
      " 11%|██▋                      | 41986048/382072689 [00:06<00:59, 5731494.71B/s]\u001b[A\n",
      " 11%|██▊                      | 42570752/382072689 [00:07<01:01, 5529020.82B/s]\u001b[A\n",
      " 11%|██▊                      | 43126784/382072689 [00:07<01:09, 4873225.19B/s]\u001b[A\n",
      " 11%|██▊                      | 43628544/382072689 [00:07<01:08, 4906120.81B/s]\u001b[A\n",
      " 12%|██▉                      | 44356608/382072689 [00:07<01:01, 5524769.41B/s]\u001b[A\n",
      " 12%|██▉                      | 45082624/382072689 [00:07<00:58, 5758778.79B/s]\u001b[A\n",
      " 12%|██▉                      | 45732864/382072689 [00:07<00:56, 5941911.93B/s]\u001b[A\n",
      " 12%|███                      | 46339072/382072689 [00:07<00:56, 5975465.01B/s]\u001b[A\n",
      " 12%|███                      | 46942208/382072689 [00:07<00:56, 5956283.73B/s]\u001b[A\n",
      " 12%|███                      | 47622144/382072689 [00:07<00:56, 5943682.29B/s]\u001b[A\n",
      " 13%|███▏                     | 48219136/382072689 [00:08<00:56, 5942351.19B/s]\u001b[A\n",
      " 13%|███▏                     | 48816128/382072689 [00:08<00:56, 5948937.83B/s]\u001b[A\n",
      " 13%|███▏                     | 49468416/382072689 [00:08<00:54, 6078721.35B/s]\u001b[A\n",
      " 13%|███▎                     | 50077696/382072689 [00:08<00:56, 5877425.92B/s]\u001b[A\n",
      " 13%|███▎                     | 50680832/382072689 [00:08<00:56, 5916936.08B/s]\u001b[A\n",
      " 13%|███▎                     | 51274752/382072689 [00:08<01:03, 5176874.54B/s]\u001b[A\n",
      " 14%|███▍                     | 51844096/382072689 [00:08<01:02, 5276454.73B/s]\u001b[A\n",
      " 14%|███▍                     | 52417536/382072689 [00:08<01:01, 5397770.31B/s]\u001b[A\n",
      " 14%|███▍                     | 52977664/382072689 [00:08<01:00, 5454737.91B/s]\u001b[A\n",
      " 14%|███▌                     | 53695488/382072689 [00:09<00:57, 5703584.57B/s]\u001b[A\n",
      " 14%|███▌                     | 54269952/382072689 [00:09<01:02, 5251110.01B/s]\u001b[A\n",
      " 14%|███▌                     | 54957056/382072689 [00:09<00:58, 5633654.79B/s]\u001b[A\n",
      " 15%|███▋                     | 55529472/382072689 [00:09<00:59, 5449160.65B/s]\u001b[A\n",
      " 15%|███▋                     | 56218624/382072689 [00:09<00:55, 5831235.78B/s]\u001b[A\n",
      " 15%|███▋                     | 56906752/382072689 [00:09<00:53, 6105679.07B/s]\u001b[A\n",
      " 15%|███▊                     | 57545728/382072689 [00:09<00:52, 6180799.70B/s]\u001b[A\n",
      " 15%|███▊                     | 58201088/382072689 [00:09<00:53, 6018859.88B/s]\u001b[A\n",
      " 15%|███▊                     | 58971136/382072689 [00:09<00:49, 6486775.60B/s]\u001b[A\n",
      " 16%|███▉                     | 59675648/382072689 [00:10<00:50, 6379191.18B/s]\u001b[A\n",
      " 16%|███▉                     | 60347392/382072689 [00:10<00:49, 6436873.00B/s]\u001b[A\n",
      " 16%|███▉                     | 61101056/382072689 [00:10<00:47, 6736871.58B/s]\u001b[A\n",
      " 17%|████▏                    | 64654336/382072689 [00:25<00:43, 7242425.29B/s]\u001b[A\n",
      " 16%|████                     | 62510080/382072689 [00:10<00:49, 6419577.67B/s]\u001b[A\n",
      " 17%|████▏                    | 63280128/382072689 [00:10<00:47, 6738506.86B/s]\u001b[A\n",
      " 17%|████▏                    | 63984640/382072689 [00:10<00:46, 6814376.22B/s]\u001b[A\n",
      " 17%|████▏                    | 64705536/382072689 [00:10<00:47, 6644475.51B/s]\u001b[A\n",
      " 17%|████▎                    | 65377280/382072689 [00:10<00:47, 6635908.88B/s]\u001b[A\n",
      " 17%|████▎                    | 66043904/382072689 [00:11<00:49, 6363264.06B/s]\u001b[A\n",
      " 17%|████▎                    | 66753536/382072689 [00:11<00:48, 6564832.30B/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████▍                    | 67414016/382072689 [00:11<00:47, 6564181.74B/s]\u001b[A\n",
      " 18%|████▍                    | 68073472/382072689 [00:11<00:50, 6272981.98B/s]\u001b[A\n",
      " 18%|████▌                    | 68834304/382072689 [00:11<00:48, 6395957.63B/s]\u001b[A\n",
      " 18%|████▌                    | 69555200/382072689 [00:11<00:47, 6598003.30B/s]\u001b[A\n",
      " 18%|████▌                    | 70217728/382072689 [00:11<00:51, 6081806.94B/s]\u001b[A\n",
      " 19%|████▋                    | 70920192/382072689 [00:11<00:49, 6275355.42B/s]\u001b[A\n",
      " 19%|████▋                    | 71586816/382072689 [00:11<00:50, 6124661.30B/s]\u001b[A\n",
      " 19%|████▋                    | 72389632/382072689 [00:12<00:46, 6624709.86B/s]\u001b[A\n",
      " 19%|████▊                    | 73192448/382072689 [00:12<00:45, 6742333.65B/s]\u001b[A\n",
      " 19%|████▊                    | 73913344/382072689 [00:12<00:45, 6835085.92B/s]\u001b[A\n",
      " 20%|████▉                    | 74650624/382072689 [00:12<00:44, 6968697.46B/s]\u001b[A\n",
      " 20%|████▉                    | 75351040/382072689 [00:12<00:51, 5947299.60B/s]\u001b[A\n",
      " 20%|████▉                    | 76010496/382072689 [00:12<00:50, 6027915.70B/s]\u001b[A\n",
      " 20%|█████                    | 76805120/382072689 [00:12<00:48, 6292856.05B/s]\u001b[A\n",
      " 20%|█████                    | 77468672/382072689 [00:12<00:47, 6369433.72B/s]\u001b[A\n",
      " 20%|█████                    | 78124032/382072689 [00:12<00:49, 6158611.86B/s]\u001b[A\n",
      " 21%|█████▏                   | 78748672/382072689 [00:13<00:55, 5456827.50B/s]\u001b[A\n",
      " 21%|█████▏                   | 79336448/382072689 [00:13<00:54, 5523998.20B/s]\u001b[A\n",
      " 21%|█████▏                   | 79942656/382072689 [00:13<00:53, 5667015.10B/s]\u001b[A\n",
      " 21%|█████▎                   | 80521216/382072689 [00:13<01:20, 3755036.17B/s]\u001b[A\n",
      " 22%|█████▍                   | 82351104/382072689 [00:13<00:45, 6587867.08B/s]\u001b[A\n",
      " 22%|█████▍                   | 83165184/382072689 [00:13<00:43, 6915945.78B/s]\u001b[A\n",
      " 22%|█████▍                   | 83976192/382072689 [00:13<00:46, 6463781.78B/s]\u001b[A\n",
      " 22%|█████▌                   | 84709376/382072689 [00:14<00:48, 6172372.86B/s]\u001b[A\n",
      " 22%|█████▌                   | 85386240/382072689 [00:14<00:48, 6080234.15B/s]\u001b[A\n",
      " 23%|█████▋                   | 86070272/382072689 [00:14<00:47, 6238828.22B/s]\u001b[A\n",
      " 23%|█████▋                   | 86726656/382072689 [00:14<00:52, 5638101.78B/s]\u001b[A\n",
      " 23%|█████▋                   | 87479296/382072689 [00:14<00:48, 6071837.16B/s]\u001b[A\n",
      " 23%|█████▊                   | 88118272/382072689 [00:14<00:47, 6154298.47B/s]\u001b[A\n",
      " 23%|█████▊                   | 88790016/382072689 [00:14<00:46, 6295604.06B/s]\u001b[A\n",
      " 23%|█████▊                   | 89478144/382072689 [00:14<00:47, 6204372.85B/s]\u001b[A\n",
      " 24%|█████▉                   | 90264576/382072689 [00:14<00:43, 6636670.09B/s]\u001b[A\n",
      " 24%|█████▉                   | 90940416/382072689 [00:15<00:45, 6393304.62B/s]\u001b[A\n",
      " 24%|█████▉                   | 91640832/382072689 [00:15<00:44, 6528707.47B/s]\u001b[A\n",
      " 24%|██████                   | 92328960/382072689 [00:15<00:45, 6353871.49B/s]\u001b[A\n",
      " 24%|██████                   | 92971008/382072689 [00:15<00:47, 6102941.27B/s]\u001b[A\n",
      " 25%|██████▏                  | 93651968/382072689 [00:15<00:46, 6253479.03B/s]\u001b[A\n",
      " 25%|██████▏                  | 94442496/382072689 [00:15<00:44, 6450392.64B/s]\u001b[A\n",
      " 25%|██████▏                  | 95114240/382072689 [00:15<00:44, 6510484.72B/s]\u001b[A\n",
      " 25%|██████▎                  | 95785984/382072689 [00:15<00:45, 6290598.62B/s]\u001b[A\n",
      " 25%|██████▎                  | 96417792/382072689 [00:15<00:45, 6286534.19B/s]\u001b[A\n",
      " 25%|██████▎                  | 97048576/382072689 [00:16<00:45, 6289702.24B/s]\u001b[A\n",
      " 26%|██████▍                  | 97679360/382072689 [00:16<00:45, 6274899.61B/s]\u001b[A\n",
      " 26%|██████▍                  | 98308096/382072689 [00:16<00:45, 6269823.95B/s]\u001b[A\n",
      " 26%|██████▍                  | 98935808/382072689 [00:16<00:47, 6015515.58B/s]\u001b[A\n",
      " 26%|██████▌                  | 99585024/382072689 [00:16<00:46, 6140876.23B/s]\u001b[A\n",
      " 26%|██████▎                 | 100324352/382072689 [00:16<00:43, 6498777.36B/s]\u001b[A\n",
      " 26%|██████▎                 | 101012480/382072689 [00:16<00:42, 6610229.16B/s]\u001b[A\n",
      " 27%|██████▍                 | 101676032/382072689 [00:16<00:42, 6595165.12B/s]\u001b[A\n",
      " 27%|██████▍                 | 102361088/382072689 [00:16<00:43, 6387059.90B/s]\u001b[A\n",
      " 27%|██████▍                 | 103027712/382072689 [00:16<00:43, 6460143.85B/s]\u001b[A\n",
      " 27%|██████▌                 | 103814144/382072689 [00:17<00:42, 6575387.15B/s]\u001b[A\n",
      " 27%|██████▌                 | 104472576/382072689 [00:17<00:42, 6537278.34B/s]\u001b[A\n",
      " 28%|██████▌                 | 105134080/382072689 [00:17<00:42, 6553415.46B/s]\u001b[A\n",
      " 28%|██████▋                 | 105790464/382072689 [00:17<00:42, 6540007.30B/s]\u001b[A\n",
      " 28%|██████▋                 | 106444800/382072689 [00:17<00:53, 5154296.45B/s]\u001b[A\n",
      " 28%|██████▋                 | 107005952/382072689 [00:17<00:53, 5181375.57B/s]\u001b[A\n",
      " 28%|██████▊                 | 107727872/382072689 [00:17<00:49, 5499602.15B/s]\u001b[A\n",
      " 28%|██████▊                 | 108302336/382072689 [00:17<00:53, 5112415.65B/s]\u001b[A\n",
      " 29%|██████▊                 | 109007872/382072689 [00:18<00:48, 5590011.53B/s]\u001b[A\n",
      " 29%|██████▉                 | 109696000/382072689 [00:18<00:45, 5933164.94B/s]\u001b[A\n",
      " 29%|██████▉                 | 110367744/382072689 [00:18<00:44, 6138562.62B/s]\u001b[A\n",
      " 29%|██████▉                 | 110997504/382072689 [00:18<00:55, 4892078.50B/s]\u001b[A\n",
      " 29%|███████                 | 111563776/382072689 [00:18<00:54, 4997645.85B/s]\u001b[A\n",
      " 29%|███████                 | 112100352/382072689 [00:18<01:25, 3153099.46B/s]\u001b[A\n",
      " 30%|███████▏                | 113824768/382072689 [00:18<00:46, 5735359.69B/s]\u001b[A\n",
      " 30%|███████▏                | 114636800/382072689 [00:19<00:44, 5970747.17B/s]\u001b[A\n",
      " 30%|███████▏                | 115406848/382072689 [00:19<00:43, 6116401.40B/s]\u001b[A\n",
      " 30%|███████▎                | 116142080/382072689 [00:19<00:46, 5743359.35B/s]\u001b[A\n",
      " 31%|███████▎                | 116804608/382072689 [00:19<00:48, 5516815.61B/s]\u001b[A\n",
      " 31%|███████▍                | 117478400/382072689 [00:19<00:45, 5771432.10B/s]\u001b[A\n",
      " 31%|███████▍                | 118105088/382072689 [00:19<00:46, 5673146.60B/s]\u001b[A\n",
      " 31%|███████▍                | 118706176/382072689 [00:19<00:47, 5525369.44B/s]\u001b[A\n",
      " 31%|███████▍                | 119281664/382072689 [00:19<00:49, 5359421.30B/s]\u001b[A\n",
      " 31%|███████▌                | 119836672/382072689 [00:20<00:48, 5389607.50B/s]\u001b[A\n",
      " 32%|███████▌                | 120493056/382072689 [00:20<00:49, 5267185.07B/s]\u001b[A\n",
      " 32%|███████▌                | 121230336/382072689 [00:20<00:45, 5788591.12B/s]\u001b[A\n",
      " 32%|███████▋                | 121822208/382072689 [00:20<00:44, 5809855.62B/s]\u001b[A\n",
      " 32%|███████▋                | 122541056/382072689 [00:20<00:43, 5940049.43B/s]\u001b[A\n",
      " 32%|███████▋                | 123141120/382072689 [00:20<00:43, 5914668.47B/s]\u001b[A\n",
      " 32%|███████▊                | 123900928/382072689 [00:20<00:42, 6142287.98B/s]\u001b[A\n",
      " 33%|███████▊                | 124523520/382072689 [00:20<00:41, 6140265.28B/s]\u001b[A\n",
      " 33%|███████▊                | 125178880/382072689 [00:20<00:42, 5998985.45B/s]\u001b[A\n",
      " 33%|███████▉                | 125780992/382072689 [00:21<00:44, 5726651.20B/s]\u001b[A\n",
      " 33%|███████▉                | 126356480/382072689 [00:21<00:46, 5496888.60B/s]\u001b[A\n",
      " 33%|███████▉                | 126908416/382072689 [00:21<00:50, 5055880.58B/s]\u001b[A\n",
      " 33%|████████                | 127472640/382072689 [00:21<00:49, 5180798.38B/s]\u001b[A\n",
      " 34%|████████                | 128013312/382072689 [00:21<00:48, 5228120.06B/s]\u001b[A\n",
      " 34%|████████                | 128619520/382072689 [00:21<00:46, 5450974.27B/s]\u001b[A\n",
      " 34%|████████                | 129324032/382072689 [00:21<00:44, 5681404.31B/s]\u001b[A\n",
      " 34%|████████▏               | 129963008/382072689 [00:21<00:43, 5861459.33B/s]\u001b[A\n",
      " 34%|████████▏               | 130552832/382072689 [00:21<00:43, 5845999.73B/s]\u001b[A\n",
      " 34%|████████▏               | 131159040/382072689 [00:22<00:44, 5659571.19B/s]\u001b[A\n",
      " 34%|████████▎               | 131798016/382072689 [00:22<00:42, 5851117.29B/s]\u001b[A\n",
      " 35%|████████▎               | 132385792/382072689 [00:22<00:46, 5382960.75B/s]\u001b[A\n",
      " 35%|████████▎               | 132932608/382072689 [00:22<00:46, 5399317.19B/s]\u001b[A\n",
      " 35%|████████▍               | 133534720/382072689 [00:22<00:44, 5545356.44B/s]\u001b[A\n",
      " 35%|████████▍               | 134173696/382072689 [00:22<00:42, 5783601.36B/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|████████▍               | 134796288/382072689 [00:22<00:43, 5678743.81B/s]\u001b[A\n",
      " 35%|████████▌               | 135368704/382072689 [00:22<00:43, 5672821.32B/s]\u001b[A\n",
      " 36%|████████▌               | 135939072/382072689 [00:22<00:45, 5451276.91B/s]\u001b[A\n",
      " 36%|████████▌               | 136487936/382072689 [00:22<00:45, 5442523.32B/s]\u001b[A\n",
      " 36%|████████▌               | 137036800/382072689 [00:23<00:44, 5448914.03B/s]\u001b[A\n",
      " 36%|████████▋               | 137729024/382072689 [00:23<00:43, 5628676.82B/s]\u001b[A\n",
      " 36%|████████▋               | 138292224/382072689 [00:23<00:45, 5372545.24B/s]\u001b[A\n",
      " 36%|████████▋               | 138843136/382072689 [00:23<00:45, 5387918.00B/s]\u001b[A\n",
      " 36%|████████▊               | 139422720/382072689 [00:23<00:45, 5276057.65B/s]\u001b[A\n",
      " 37%|████████▊               | 140027904/382072689 [00:23<00:44, 5488185.21B/s]\u001b[A\n",
      " 37%|████████▊               | 140694528/382072689 [00:23<00:41, 5817987.95B/s]\u001b[A\n",
      " 37%|████████▊               | 141284352/382072689 [00:23<00:41, 5823603.87B/s]\u001b[A\n",
      " 37%|████████▉               | 141923328/382072689 [00:23<00:41, 5737618.85B/s]\u001b[A\n",
      " 37%|████████▉               | 142499840/382072689 [00:24<00:41, 5736646.78B/s]\u001b[A\n",
      " 37%|████████▉               | 143085568/382072689 [00:24<00:41, 5766422.92B/s]\u001b[A\n",
      " 38%|█████████               | 143692800/382072689 [00:24<00:40, 5839136.37B/s]\u001b[A\n",
      " 38%|█████████               | 144278528/382072689 [00:24<00:44, 5347416.34B/s]\u001b[A\n",
      " 38%|█████████               | 144872448/382072689 [00:24<00:43, 5497415.74B/s]\u001b[A\n",
      " 38%|█████████▏              | 145626112/382072689 [00:24<00:40, 5826645.86B/s]\u001b[A\n",
      " 38%|█████████▏              | 146212864/382072689 [00:24<00:52, 4460139.00B/s]\u001b[A\n",
      " 38%|█████████▏              | 146772992/382072689 [00:24<00:50, 4644576.76B/s]\u001b[A\n",
      " 39%|█████████▎              | 147379200/382072689 [00:25<00:47, 4989910.23B/s]\u001b[A\n",
      " 39%|█████████▎              | 148152320/382072689 [00:25<00:42, 5491416.95B/s]\u001b[A\n",
      " 39%|█████████▎              | 148820992/382072689 [00:25<00:40, 5786538.09B/s]\u001b[A\n",
      " 39%|█████████▍              | 149422080/382072689 [00:25<00:41, 5615069.31B/s]\u001b[A\n",
      " 39%|█████████▍              | 150017024/382072689 [00:25<00:40, 5680555.55B/s]\u001b[A\n",
      " 39%|█████████▍              | 150596608/382072689 [00:25<00:42, 5479886.28B/s]\u001b[A\n",
      " 40%|█████████▌              | 151278592/382072689 [00:25<00:39, 5816075.29B/s]\u001b[A\n",
      " 40%|█████████▌              | 151868416/382072689 [00:25<00:41, 5596644.43B/s]\u001b[A\n",
      " 40%|█████████▌              | 152434688/382072689 [00:25<00:40, 5607898.67B/s]\u001b[A\n",
      " 40%|█████████▌              | 153000960/382072689 [00:26<00:42, 5368959.25B/s]\u001b[A\n",
      " 40%|█████████▋              | 153621504/382072689 [00:26<00:40, 5582767.40B/s]\u001b[A\n",
      " 40%|█████████▋              | 154358784/382072689 [00:26<00:38, 5851116.25B/s]\u001b[A\n",
      " 41%|█████████▋              | 154946560/382072689 [00:26<00:40, 5601271.88B/s]\u001b[A\n",
      " 41%|█████████▊              | 155538432/382072689 [00:26<00:39, 5677105.40B/s]\u001b[A\n",
      " 41%|█████████▊              | 156177408/382072689 [00:26<00:38, 5864860.34B/s]\u001b[A\n",
      " 41%|█████████▊              | 156816384/382072689 [00:26<00:37, 6000503.60B/s]\u001b[A\n",
      " 41%|█████████▉              | 157419520/382072689 [00:26<00:37, 6008895.84B/s]\u001b[A\n",
      " 41%|█████████▉              | 158035968/382072689 [00:26<00:38, 5793677.82B/s]\u001b[A\n",
      " 42%|█████████▉              | 158684160/382072689 [00:26<00:37, 5972079.72B/s]\u001b[A\n",
      " 42%|██████████              | 159413248/382072689 [00:27<00:36, 6097232.13B/s]\u001b[A\n",
      " 42%|██████████              | 160024576/382072689 [00:27<00:36, 6084035.74B/s]\u001b[A\n",
      " 42%|██████████              | 160633856/382072689 [00:27<00:36, 6053425.75B/s]\u001b[A\n",
      " 42%|██████████▏             | 161240064/382072689 [00:27<00:39, 5570073.58B/s]\u001b[A\n",
      " 42%|██████████▏             | 161804288/382072689 [00:27<00:39, 5576483.78B/s]\u001b[A\n",
      " 43%|██████████▏             | 162449408/382072689 [00:27<00:37, 5810941.66B/s]\u001b[A\n",
      " 43%|██████████▏             | 163075072/382072689 [00:27<00:40, 5455284.43B/s]\u001b[A\n",
      " 43%|██████████▎             | 163629056/382072689 [00:27<00:40, 5452041.82B/s]\u001b[A\n",
      " 43%|██████████▎             | 164186112/382072689 [00:27<00:39, 5467693.38B/s]\u001b[A\n",
      " 43%|██████████▎             | 164803584/382072689 [00:28<00:39, 5438542.17B/s]\u001b[A\n",
      " 43%|██████████▍             | 165350400/382072689 [00:28<00:39, 5424102.42B/s]\u001b[A\n",
      " 43%|██████████▍             | 165991424/382072689 [00:28<00:38, 5684696.05B/s]\u001b[A\n",
      " 44%|██████████▍             | 166564864/382072689 [00:28<00:39, 5462654.66B/s]\u001b[A\n",
      " 44%|██████████▌             | 167175168/382072689 [00:28<00:38, 5642243.02B/s]\u001b[A\n",
      " 44%|██████████▌             | 167744512/382072689 [00:28<00:37, 5647116.44B/s]\u001b[A\n",
      " 44%|██████████▌             | 168399872/382072689 [00:28<00:36, 5909743.99B/s]\u001b[A\n",
      " 44%|██████████▌             | 169006080/382072689 [00:28<00:37, 5701989.93B/s]\u001b[A\n",
      " 44%|██████████▋             | 169579520/382072689 [00:28<00:40, 5220876.99B/s]\u001b[A\n",
      " 45%|██████████▋             | 170136576/382072689 [00:29<00:40, 5291269.54B/s]\u001b[A\n",
      " 45%|██████████▋             | 170710016/382072689 [00:29<00:40, 5194102.57B/s]\u001b[A\n",
      " 45%|██████████▊             | 171452416/382072689 [00:29<00:36, 5799029.18B/s]\u001b[A\n",
      " 45%|██████████▊             | 172041216/382072689 [00:29<00:39, 5354610.60B/s]\u001b[A\n",
      " 45%|██████████▊             | 172643328/382072689 [00:29<00:38, 5482103.55B/s]\u001b[A\n",
      " 45%|██████████▉             | 173495296/382072689 [00:29<00:34, 6078955.58B/s]\u001b[A\n",
      " 46%|██████████▉             | 174199808/382072689 [00:29<00:32, 6306229.36B/s]\u001b[A\n",
      " 46%|██████████▉             | 174969856/382072689 [00:29<00:32, 6446358.04B/s]\u001b[A\n",
      " 46%|███████████             | 175618048/382072689 [00:29<00:35, 5898223.05B/s]\u001b[A\n",
      " 46%|███████████             | 176217088/382072689 [00:30<00:35, 5866358.83B/s]\u001b[A\n",
      " 46%|███████████             | 176821248/382072689 [00:30<00:36, 5697517.91B/s]\u001b[A\n",
      " 46%|███████████▏            | 177607680/382072689 [00:30<00:33, 6033113.57B/s]\u001b[A\n",
      " 47%|███████████▏            | 178219008/382072689 [00:30<00:33, 6028603.11B/s]\u001b[A\n",
      " 47%|███████████▏            | 178983936/382072689 [00:30<00:32, 6218217.86B/s]\u001b[A\n",
      " 47%|███████████▎            | 179655680/382072689 [00:30<00:32, 6315104.55B/s]\u001b[A\n",
      " 47%|███████████▎            | 180288512/382072689 [00:30<00:34, 5807384.56B/s]\u001b[A\n",
      " 47%|███████████▎            | 180876288/382072689 [00:30<00:37, 5345680.43B/s]\u001b[A\n",
      " 47%|███████████▍            | 181457920/382072689 [00:30<00:36, 5457092.20B/s]\u001b[A\n",
      " 48%|███████████▍            | 182260736/382072689 [00:31<00:33, 5908378.39B/s]\u001b[A\n",
      " 48%|███████████▍            | 182916096/382072689 [00:31<00:32, 6060304.63B/s]\u001b[A\n",
      " 48%|███████████▌            | 183784448/382072689 [00:31<00:30, 6511884.76B/s]\u001b[A\n",
      " 48%|███████████▌            | 184438784/382072689 [00:31<00:30, 6498752.88B/s]\u001b[A\n",
      " 48%|███████████▋            | 185091072/382072689 [00:31<00:30, 6470553.33B/s]\u001b[A\n",
      " 49%|███████████▋            | 185739264/382072689 [00:31<00:30, 6468502.36B/s]\u001b[A\n",
      " 49%|███████████▋            | 186387456/382072689 [00:31<00:30, 6471505.72B/s]\u001b[A\n",
      " 49%|███████████▊            | 187159552/382072689 [00:31<00:29, 6556923.99B/s]\u001b[A\n",
      " 49%|███████████▊            | 187815936/382072689 [00:31<00:31, 6244414.60B/s]\u001b[A\n",
      " 49%|███████████▊            | 188442624/382072689 [00:32<00:30, 6249423.31B/s]\u001b[A\n",
      " 49%|███████████▉            | 189109248/382072689 [00:32<00:31, 6099049.66B/s]\u001b[A\n",
      " 50%|███████████▉            | 189721600/382072689 [00:32<00:31, 6103689.45B/s]\u001b[A\n",
      " 50%|███████████▉            | 190333952/382072689 [00:32<00:32, 5832102.81B/s]\u001b[A\n",
      " 50%|███████████▉            | 190919680/382072689 [00:32<00:32, 5824570.94B/s]\u001b[A\n",
      " 50%|████████████            | 191534080/382072689 [00:32<00:33, 5666783.87B/s]\u001b[A\n",
      " 50%|████████████            | 192142336/382072689 [00:32<00:32, 5765723.82B/s]\u001b[A\n",
      " 50%|████████████            | 192795648/382072689 [00:32<00:31, 5971611.78B/s]\u001b[A\n",
      " 51%|████████████▏           | 193395712/382072689 [00:32<00:31, 5968942.26B/s]\u001b[A\n",
      " 51%|████████████▏           | 193994752/382072689 [00:32<00:32, 5710761.69B/s]\u001b[A\n",
      " 51%|████████████▏           | 194614272/382072689 [00:33<00:32, 5837221.19B/s]\u001b[A\n",
      " 51%|████████████▎           | 195364864/382072689 [00:33<00:30, 6058623.04B/s]\u001b[A\n",
      " 51%|████████████▎           | 195972096/382072689 [00:33<00:30, 6049341.79B/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|████████████▎           | 196645888/382072689 [00:33<00:31, 5978746.23B/s]\u001b[A\n",
      " 52%|████████████▍           | 197366784/382072689 [00:33<00:29, 6299756.67B/s]\u001b[A\n",
      " 52%|████████████▍           | 197999616/382072689 [00:33<00:30, 6080131.41B/s]\u001b[A\n",
      " 52%|████████████▍           | 198611968/382072689 [00:33<00:30, 6052088.97B/s]\u001b[A\n",
      " 52%|████████████▌           | 199219200/382072689 [00:33<00:30, 6057448.68B/s]\u001b[A\n",
      " 52%|████████████▌           | 199826432/382072689 [00:33<00:31, 5774496.66B/s]\u001b[A\n",
      " 52%|████████████▌           | 200578048/382072689 [00:34<00:30, 6003634.19B/s]\u001b[A\n",
      " 53%|████████████▋           | 201180160/382072689 [00:34<00:30, 6004281.50B/s]\u001b[A\n",
      " 53%|████████████▋           | 201792512/382072689 [00:34<00:29, 6017331.73B/s]\u001b[A\n",
      " 53%|████████████▋           | 202396672/382072689 [00:34<00:31, 5774306.10B/s]\u001b[A\n",
      " 53%|████████████▊           | 203117568/382072689 [00:34<00:29, 6169549.19B/s]\u001b[A\n",
      " 53%|████████████▊           | 203805696/382072689 [00:34<00:28, 6354503.40B/s]\u001b[A\n",
      " 54%|████████████▊           | 204444672/382072689 [00:34<00:34, 5201102.70B/s]\u001b[A\n",
      " 54%|████████████▉           | 205000704/382072689 [00:34<00:33, 5227648.40B/s]\u001b[A\n",
      " 54%|████████████▉           | 205607936/382072689 [00:34<00:32, 5432122.87B/s]\u001b[A\n",
      " 54%|████████████▉           | 206172160/382072689 [00:35<00:51, 3441563.23B/s]\u001b[A\n",
      " 54%|█████████████           | 207770624/382072689 [00:35<00:30, 5743811.54B/s]\u001b[A\n",
      " 55%|█████████████           | 208504832/382072689 [00:35<00:28, 6080371.99B/s]\u001b[A\n",
      " 55%|█████████████▏          | 209238016/382072689 [00:35<00:27, 6343182.12B/s]\u001b[A\n",
      " 55%|█████████████▏          | 209967104/382072689 [00:35<00:27, 6333261.09B/s]\u001b[A\n",
      " 55%|█████████████▏          | 210666496/382072689 [00:35<00:27, 6248534.45B/s]\u001b[A\n",
      " 55%|█████████████▎          | 211337216/382072689 [00:35<00:26, 6363266.19B/s]\u001b[A\n",
      " 55%|█████████████▎          | 212007936/382072689 [00:36<00:26, 6453829.68B/s]\u001b[A\n",
      " 56%|█████████████▎          | 212678656/382072689 [00:36<00:26, 6514176.61B/s]\u001b[A\n",
      " 56%|█████████████▍          | 213488640/382072689 [00:36<00:26, 6415580.19B/s]\u001b[A\n",
      " 56%|█████████████▍          | 214144000/382072689 [00:36<00:26, 6409835.70B/s]\u001b[A\n",
      " 56%|█████████████▍          | 214881280/382072689 [00:36<00:26, 6401287.44B/s]\u001b[A\n",
      " 56%|█████████████▌          | 215711744/382072689 [00:36<00:25, 6641142.17B/s]\u001b[A\n",
      " 57%|█████████████▌          | 216418304/382072689 [00:36<00:24, 6735732.16B/s]\u001b[A\n",
      " 57%|█████████████▋          | 217196544/382072689 [00:36<00:24, 6738487.06B/s]\u001b[A\n",
      " 57%|█████████████▋          | 217873408/382072689 [00:36<00:24, 6720065.57B/s]\u001b[A\n",
      " 57%|█████████████▋          | 218547200/382072689 [00:37<00:24, 6722043.06B/s]\u001b[A\n",
      " 57%|█████████████▊          | 219337728/382072689 [00:37<00:24, 6761505.76B/s]\u001b[A\n",
      " 58%|█████████████▊          | 220107776/382072689 [00:37<00:23, 7004778.67B/s]\u001b[A\n",
      " 58%|█████████████▊          | 220810240/382072689 [00:37<00:24, 6712390.18B/s]\u001b[A\n",
      " 58%|█████████████▉          | 221485056/382072689 [00:37<00:23, 6710793.83B/s]\u001b[A\n",
      " 58%|█████████████▉          | 222158848/382072689 [00:37<00:23, 6691347.37B/s]\u001b[A\n",
      " 58%|██████████████          | 222958592/382072689 [00:37<00:23, 6784392.12B/s]\u001b[A\n",
      " 59%|██████████████          | 223637504/382072689 [00:37<00:24, 6478582.30B/s]\u001b[A\n",
      " 59%|██████████████          | 224287744/382072689 [00:37<00:24, 6435517.31B/s]\u001b[A\n",
      " 59%|██████████████▏         | 224951296/382072689 [00:38<00:25, 6225646.51B/s]\u001b[A\n",
      " 59%|██████████████▏         | 225667072/382072689 [00:38<00:25, 6222618.36B/s]\u001b[A\n",
      " 59%|██████████████▏         | 226317312/382072689 [00:38<00:24, 6276131.85B/s]\u001b[A\n",
      " 59%|██████████████▎         | 226947072/382072689 [00:38<00:26, 5767739.64B/s]\u001b[A\n",
      " 60%|██████████████▎         | 227595264/382072689 [00:38<00:26, 5930695.04B/s]\u001b[A\n",
      " 60%|██████████████▎         | 228250624/382072689 [00:38<00:25, 6097230.47B/s]\u001b[A\n",
      " 60%|██████████████▍         | 229004288/382072689 [00:38<00:23, 6464184.44B/s]\u001b[A\n",
      " 60%|██████████████▍         | 229822464/382072689 [00:38<00:22, 6684250.41B/s]\u001b[A\n",
      " 60%|██████████████▍         | 230565888/382072689 [00:38<00:22, 6614083.91B/s]\u001b[A\n",
      " 61%|██████████████▌         | 231232512/382072689 [00:38<00:22, 6610864.50B/s]\u001b[A\n",
      " 61%|██████████████▌         | 231969792/382072689 [00:39<00:22, 6811176.47B/s]\u001b[A\n",
      " 61%|██████████████▌         | 232772608/382072689 [00:39<00:21, 6858885.19B/s]\u001b[A\n",
      " 61%|██████████████▋         | 233459712/382072689 [00:39<00:22, 6556090.09B/s]\u001b[A\n",
      " 61%|██████████████▋         | 234118144/382072689 [00:39<00:22, 6553813.20B/s]\u001b[A\n",
      " 61%|██████████████▋         | 234775552/382072689 [00:39<00:22, 6536230.53B/s]\u001b[A\n",
      " 62%|██████████████▊         | 235459584/382072689 [00:39<00:22, 6614453.75B/s]\u001b[A\n",
      " 62%|██████████████▊         | 236295168/382072689 [00:39<00:21, 6816035.51B/s]\u001b[A\n",
      " 62%|██████████████▉         | 236976128/382072689 [00:39<00:23, 6256374.38B/s]\u001b[A\n",
      " 62%|██████████████▉         | 237608960/382072689 [00:39<00:24, 5969333.21B/s]\u001b[A\n",
      " 62%|██████████████▉         | 238244864/382072689 [00:40<00:23, 6067253.73B/s]\u001b[A\n",
      " 63%|███████████████         | 238900224/382072689 [00:40<00:41, 3482896.50B/s]\u001b[A\n",
      " 63%|███████████████▏        | 241193984/382072689 [00:40<00:20, 7003864.23B/s]\u001b[A\n",
      " 63%|███████████████▏        | 242204672/382072689 [00:40<00:20, 6932915.72B/s]\u001b[A\n",
      " 64%|███████████████▎        | 243115008/382072689 [00:40<00:21, 6518433.79B/s]\u001b[A\n",
      " 64%|███████████████▎        | 243918848/382072689 [00:41<00:21, 6561658.75B/s]\u001b[A\n",
      " 64%|███████████████▎        | 244682752/382072689 [00:41<00:20, 6561113.06B/s]\u001b[A\n",
      " 64%|███████████████▍        | 245414912/382072689 [00:41<00:21, 6464748.19B/s]\u001b[A\n",
      " 64%|███████████████▍        | 246113280/382072689 [00:41<00:22, 6118908.90B/s]\u001b[A\n",
      " 65%|███████████████▌        | 246764544/382072689 [00:41<00:21, 6185190.98B/s]\u001b[A\n",
      " 65%|███████████████▌        | 247649280/382072689 [00:41<00:20, 6632401.69B/s]\u001b[A\n",
      " 65%|███████████████▌        | 248334336/382072689 [00:41<00:20, 6639842.82B/s]\u001b[A\n",
      " 65%|███████████████▋        | 249013248/382072689 [00:41<00:20, 6403662.12B/s]\u001b[A\n",
      " 65%|███████████████▋        | 249664512/382072689 [00:41<00:20, 6417298.29B/s]\u001b[A\n",
      " 66%|███████████████▋        | 250467328/382072689 [00:42<00:19, 6585618.12B/s]\u001b[A\n",
      " 66%|███████████████▊        | 251130880/382072689 [00:42<00:19, 6589031.86B/s]\u001b[A\n",
      " 66%|███████████████▊        | 251810816/382072689 [00:42<00:19, 6648246.19B/s]\u001b[A\n",
      " 66%|███████████████▊        | 252531712/382072689 [00:42<00:19, 6539561.24B/s]\u001b[A\n",
      " 66%|███████████████▉        | 253189120/382072689 [00:42<00:20, 6399229.47B/s]\u001b[A\n",
      " 66%|███████████████▉        | 253924352/382072689 [00:42<00:19, 6459040.65B/s]\u001b[A\n",
      " 67%|███████████████▉        | 254571520/382072689 [00:42<00:19, 6461034.62B/s]\u001b[A\n",
      " 67%|████████████████        | 255235072/382072689 [00:42<00:20, 6257804.61B/s]\u001b[A\n",
      " 67%|████████████████        | 255923200/382072689 [00:42<00:20, 6163028.71B/s]\u001b[A\n",
      " 67%|████████████████        | 256594944/382072689 [00:42<00:19, 6294899.45B/s]\u001b[A\n",
      " 67%|████████████████▏       | 257266688/382072689 [00:43<00:19, 6389050.16B/s]\u001b[A\n",
      " 68%|████████████████▏       | 258020352/382072689 [00:43<00:18, 6693152.83B/s]\u001b[A\n",
      " 68%|████████████████▎       | 258774016/382072689 [00:43<00:18, 6640583.05B/s]\u001b[A\n",
      " 68%|████████████████▎       | 259440640/382072689 [00:43<00:19, 6352933.87B/s]\u001b[A\n",
      " 68%|████████████████▎       | 260079616/382072689 [00:43<00:20, 6074391.86B/s]\u001b[A\n",
      " 68%|████████████████▍       | 260756480/382072689 [00:43<00:20, 6008328.04B/s]\u001b[A\n",
      " 68%|████████████████▍       | 261428224/382072689 [00:43<00:19, 6178460.04B/s]\u001b[A\n",
      " 69%|████████████████▍       | 262049792/382072689 [00:43<00:19, 6185952.17B/s]\u001b[A\n",
      " 69%|████████████████▌       | 262820864/382072689 [00:43<00:18, 6352125.54B/s]\u001b[A\n",
      " 69%|████████████████▌       | 263456768/382072689 [00:44<00:18, 6347437.37B/s]\u001b[A\n",
      " 69%|████████████████▌       | 264092672/382072689 [00:44<00:19, 6077312.81B/s]\u001b[A\n",
      " 69%|████████████████▋       | 264702976/382072689 [00:44<00:21, 5556342.39B/s]\u001b[A\n",
      " 69%|████████████████▋       | 265267200/382072689 [00:44<00:21, 5342928.34B/s]\u001b[A\n",
      " 70%|████████████████▋       | 265835520/382072689 [00:44<00:21, 5401104.97B/s]\u001b[A\n",
      " 70%|████████████████▋       | 266441728/382072689 [00:44<00:20, 5577771.36B/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████▊       | 267113472/382072689 [00:44<00:19, 5890032.76B/s]\u001b[A\n",
      " 70%|████████████████▊       | 267768832/382072689 [00:44<00:19, 5822150.21B/s]\u001b[A\n",
      " 70%|████████████████▊       | 268407808/382072689 [00:44<00:19, 5762618.79B/s]\u001b[A\n",
      " 70%|████████████████▉       | 269030400/382072689 [00:45<00:19, 5849252.21B/s]\u001b[A\n",
      " 71%|████████████████▉       | 269699072/382072689 [00:45<00:18, 6071840.39B/s]\u001b[A\n",
      " 71%|████████████████▉       | 270373888/382072689 [00:45<00:18, 6032979.59B/s]\u001b[A\n",
      " 71%|█████████████████       | 270980096/382072689 [00:45<00:18, 6024568.04B/s]\u001b[A\n",
      " 71%|█████████████████       | 271635456/382072689 [00:45<00:17, 6167060.98B/s]\u001b[A\n",
      " 71%|█████████████████       | 272290816/382072689 [00:45<00:17, 6142333.27B/s]\u001b[A\n",
      " 71%|█████████████████▏      | 272967680/382072689 [00:45<00:19, 5663297.56B/s]\u001b[A\n",
      " 72%|█████████████████▏      | 273979392/382072689 [00:45<00:15, 6839094.16B/s]\u001b[A\n",
      " 72%|█████████████████▎      | 274748416/382072689 [00:45<00:15, 7066716.06B/s]\u001b[A\n",
      " 72%|█████████████████▎      | 275534848/382072689 [00:46<00:18, 5760836.29B/s]\u001b[A\n",
      " 72%|█████████████████▎      | 276161536/382072689 [00:46<00:18, 5785733.19B/s]\u001b[A\n",
      " 72%|█████████████████▍      | 276775936/382072689 [00:46<00:17, 5850530.42B/s]\u001b[A\n",
      " 73%|█████████████████▍      | 277419008/382072689 [00:46<00:18, 5807848.57B/s]\u001b[A\n",
      " 73%|█████████████████▍      | 278238208/382072689 [00:46<00:16, 6289389.59B/s]\u001b[A\n",
      " 73%|█████████████████▌      | 278882304/382072689 [00:46<00:16, 6182133.76B/s]\u001b[A\n",
      " 73%|█████████████████▌      | 279581696/382072689 [00:46<00:16, 6393025.34B/s]\u001b[A\n",
      " 73%|█████████████████▌      | 280302592/382072689 [00:46<00:15, 6363639.00B/s]\u001b[A\n",
      " 74%|█████████████████▋      | 280945664/382072689 [00:46<00:15, 6351908.27B/s]\u001b[A\n",
      " 74%|█████████████████▋      | 281629696/382072689 [00:47<00:16, 6222700.79B/s]\u001b[A\n",
      " 74%|█████████████████▋      | 282256384/382072689 [00:47<00:16, 6206396.75B/s]\u001b[A\n",
      " 74%|█████████████████▊      | 283005952/382072689 [00:47<00:15, 6310222.66B/s]\u001b[A\n",
      " 74%|█████████████████▊      | 283710464/382072689 [00:47<00:15, 6487071.30B/s]\u001b[A\n",
      " 74%|█████████████████▊      | 284480512/382072689 [00:47<00:14, 6816583.57B/s]\u001b[A\n",
      " 75%|█████████████████▉      | 285234176/382072689 [00:47<00:14, 6726697.22B/s]\u001b[A\n",
      " 75%|█████████████████▉      | 286007296/382072689 [00:47<00:14, 6715974.80B/s]\u001b[A\n",
      " 75%|██████████████████      | 286681088/382072689 [00:47<00:14, 6696553.04B/s]\u001b[A\n",
      " 75%|██████████████████      | 287352832/382072689 [00:47<00:14, 6397564.50B/s]\u001b[A\n",
      " 75%|██████████████████      | 288134144/382072689 [00:48<00:14, 6511196.34B/s]\u001b[A\n",
      " 76%|██████████████████▏     | 288822272/382072689 [00:48<00:14, 6596690.43B/s]\u001b[A\n",
      " 76%|██████████████████▏     | 289483776/382072689 [00:48<00:15, 6066097.58B/s]\u001b[A\n",
      " 76%|██████████████████▏     | 290209792/382072689 [00:48<00:14, 6351748.10B/s]\u001b[A\n",
      " 76%|██████████████████▎     | 290852864/382072689 [00:48<00:14, 6362614.80B/s]\u001b[A\n",
      " 76%|██████████████████▎     | 291509248/382072689 [00:48<00:14, 6417360.23B/s]\u001b[A\n",
      " 76%|██████████████████▎     | 292246528/382072689 [00:48<00:13, 6649579.80B/s]\u001b[A\n",
      " 77%|██████████████████▍     | 292967424/382072689 [00:48<00:13, 6553865.21B/s]\u001b[A\n",
      " 77%|██████████████████▍     | 293721088/382072689 [00:48<00:12, 6833385.22B/s]\u001b[A\n",
      " 77%|██████████████████▍     | 294438912/382072689 [00:49<00:12, 6917421.33B/s]\u001b[A\n",
      " 77%|██████████████████▌     | 295165952/382072689 [00:49<00:12, 6737968.01B/s]\u001b[A\n",
      " 77%|██████████████████▌     | 295929856/382072689 [00:49<00:12, 6956702.91B/s]\u001b[A\n",
      " 78%|██████████████████▋     | 296629248/382072689 [00:49<00:12, 6668011.42B/s]\u001b[A\n",
      " 78%|██████████████████▋     | 297299968/382072689 [00:49<00:12, 6641872.76B/s]\u001b[A\n",
      " 78%|██████████████████▋     | 297967616/382072689 [00:49<00:12, 6638825.47B/s]\u001b[A\n",
      " 78%|██████████████████▊     | 298669056/382072689 [00:49<00:12, 6466139.92B/s]\u001b[A\n",
      " 78%|██████████████████▊     | 299504640/382072689 [00:49<00:12, 6711414.16B/s]\u001b[A\n",
      " 79%|██████████████████▊     | 300176384/382072689 [00:49<00:12, 6676600.27B/s]\u001b[A\n",
      " 79%|██████████████████▉     | 300845056/382072689 [00:50<00:12, 6669354.86B/s]\u001b[A\n",
      " 79%|██████████████████▉     | 301657088/382072689 [00:50<00:11, 6784529.63B/s]\u001b[A\n",
      " 79%|██████████████████▉     | 302404608/382072689 [00:50<00:11, 6695321.04B/s]\u001b[A\n",
      " 79%|███████████████████     | 303074304/382072689 [00:50<00:11, 6677526.49B/s]\u001b[A\n",
      " 79%|███████████████████     | 303741952/382072689 [00:50<00:12, 6379049.36B/s]\u001b[A\n",
      " 80%|███████████████████     | 304384000/382072689 [00:50<00:12, 6362928.14B/s]\u001b[A\n",
      " 80%|███████████████████▏    | 305173504/382072689 [00:50<00:11, 6518827.17B/s]\u001b[A\n",
      " 80%|███████████████████▏    | 305890304/382072689 [00:50<00:11, 6692230.30B/s]\u001b[A\n",
      " 80%|███████████████████▎    | 306561024/382072689 [00:50<00:11, 6402750.25B/s]\u001b[A\n",
      " 80%|███████████████████▎    | 307270656/382072689 [00:50<00:11, 6566719.23B/s]\u001b[A\n",
      " 81%|███████████████████▎    | 307958784/382072689 [00:51<00:11, 6655306.25B/s]\u001b[A\n",
      " 81%|███████████████████▍    | 308765696/382072689 [00:51<00:10, 6761409.26B/s]\u001b[A\n",
      " 81%|███████████████████▍    | 309443584/382072689 [00:51<00:10, 6764120.32B/s]\u001b[A\n",
      " 81%|███████████████████▍    | 310121472/382072689 [00:51<00:10, 6737656.48B/s]\u001b[A\n",
      " 81%|███████████████████▌    | 310842368/382072689 [00:51<00:10, 6868959.09B/s]\u001b[A\n",
      " 82%|███████████████████▌    | 311645184/382072689 [00:51<00:10, 6898274.91B/s]\u001b[A\n",
      " 82%|███████████████████▌    | 312335360/382072689 [00:51<00:10, 6882227.79B/s]\u001b[A\n",
      " 82%|███████████████████▋    | 313024512/382072689 [00:51<00:10, 6585084.97B/s]\u001b[A\n",
      " 82%|███████████████████▋    | 313775104/382072689 [00:51<00:09, 6836856.99B/s]\u001b[A\n",
      " 82%|███████████████████▊    | 314462208/382072689 [00:52<00:09, 6842081.21B/s]\u001b[A\n",
      " 83%|███████████████████▊    | 315266048/382072689 [00:52<00:09, 7161056.59B/s]\u001b[A\n",
      " 83%|███████████████████▊    | 315984896/382072689 [00:52<00:09, 6856462.54B/s]\u001b[A\n",
      " 83%|███████████████████▉    | 316691456/382072689 [00:52<00:09, 6635430.63B/s]\u001b[A\n",
      " 83%|███████████████████▉    | 317412352/382072689 [00:52<00:09, 6768486.09B/s]\u001b[A\n",
      " 83%|███████████████████▉    | 318093312/382072689 [00:52<00:09, 6760489.38B/s]\u001b[A\n",
      " 83%|████████████████████    | 318772224/382072689 [00:52<00:09, 6488769.30B/s]\u001b[A\n",
      " 84%|████████████████████    | 319493120/382072689 [00:52<00:09, 6676630.40B/s]\u001b[A\n",
      " 84%|████████████████████    | 320231424/382072689 [00:52<00:09, 6589111.14B/s]\u001b[A\n",
      " 84%|████████████████████▏   | 320984064/382072689 [00:53<00:08, 6833680.84B/s]\u001b[A\n",
      " 84%|████████████████████▏   | 321803264/382072689 [00:53<00:08, 6927215.71B/s]\u001b[A\n",
      " 84%|████████████████████▎   | 322498560/382072689 [00:53<00:09, 6343684.99B/s]\u001b[A\n",
      " 85%|████████████████████▎   | 323141632/382072689 [00:53<00:09, 6339894.61B/s]\u001b[A\n",
      " 85%|████████████████████▎   | 323781632/382072689 [00:53<00:09, 6056039.50B/s]\u001b[A\n",
      " 85%|████████████████████▍   | 324392960/382072689 [00:53<00:09, 5835949.14B/s]\u001b[A\n",
      " 85%|████████████████████▍   | 324980736/382072689 [00:53<00:09, 5815311.44B/s]\u001b[A\n",
      " 85%|████████████████████▍   | 325739520/382072689 [00:53<00:09, 6053716.22B/s]\u001b[A\n",
      " 85%|████████████████████▍   | 326346752/382072689 [00:53<00:09, 5814317.37B/s]\u001b[A\n",
      " 86%|████████████████████▌   | 326964224/382072689 [00:54<00:09, 5879604.05B/s]\u001b[A\n",
      " 86%|████████████████████▌   | 327783424/382072689 [00:54<00:08, 6254985.91B/s]\u001b[A\n",
      " 86%|████████████████████▋   | 328409088/382072689 [00:54<00:08, 6236796.38B/s]\u001b[A\n",
      " 86%|████████████████████▋   | 329032704/382072689 [00:54<00:08, 5955415.78B/s]\u001b[A\n",
      " 86%|████████████████████▋   | 329629696/382072689 [00:54<00:09, 5694822.86B/s]\u001b[A\n",
      " 86%|████████████████████▋   | 330322944/382072689 [00:54<00:08, 6020680.72B/s]\u001b[A\n",
      " 87%|████████████████████▊   | 331109376/382072689 [00:54<00:08, 6291883.02B/s]\u001b[A\n",
      " 87%|████████████████████▊   | 331741184/382072689 [00:54<00:08, 5983424.52B/s]\u001b[A\n",
      " 87%|████████████████████▉   | 332343296/382072689 [00:54<00:08, 5992707.49B/s]\u001b[A\n",
      " 87%|████████████████████▉   | 333075456/382072689 [00:55<00:07, 6362928.32B/s]\u001b[A\n",
      " 87%|████████████████████▉   | 333716480/382072689 [00:55<00:07, 6376463.41B/s]\u001b[A\n",
      " 88%|█████████████████████   | 334511104/382072689 [00:55<00:07, 6539367.48B/s]\u001b[A\n",
      " 88%|█████████████████████   | 335172608/382072689 [00:55<00:07, 6554035.86B/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|█████████████████████   | 335828992/382072689 [00:55<00:07, 6532853.97B/s]\u001b[A\n",
      " 88%|█████████████████████▏  | 336712704/382072689 [00:55<00:06, 6891014.14B/s]\u001b[A\n",
      " 88%|█████████████████████▏  | 337547264/382072689 [00:55<00:06, 7010325.69B/s]\u001b[A\n",
      " 89%|█████████████████████▏  | 338246656/382072689 [00:55<00:06, 6996660.50B/s]\u001b[A\n",
      " 89%|█████████████████████▎  | 338945024/382072689 [00:55<00:06, 6684088.58B/s]\u001b[A\n",
      " 89%|█████████████████████▎  | 339694592/382072689 [00:55<00:06, 6885017.43B/s]\u001b[A\n",
      " 89%|█████████████████████▍  | 340481024/382072689 [00:56<00:06, 6871526.63B/s]\u001b[A\n",
      " 89%|█████████████████████▍  | 341185536/382072689 [00:56<00:05, 6878547.90B/s]\u001b[A\n",
      " 90%|█████████████████████▍  | 342021120/382072689 [00:56<00:05, 6993420.34B/s]\u001b[A\n",
      " 90%|█████████████████████▌  | 342721536/382072689 [00:56<00:05, 6987203.00B/s]\u001b[A\n",
      " 90%|█████████████████████▌  | 343420928/382072689 [00:56<00:05, 6674632.28B/s]\u001b[A\n",
      " 90%|█████████████████████▌  | 344134656/382072689 [00:56<00:05, 6788689.68B/s]\u001b[A\n",
      " 90%|█████████████████████▋  | 344928256/382072689 [00:56<00:05, 6817514.20B/s]\u001b[A\n",
      " 90%|█████████████████████▋  | 345611264/382072689 [00:56<00:05, 6516912.41B/s]\u001b[A\n",
      " 91%|█████████████████████▊  | 346265600/382072689 [00:56<00:05, 6504294.85B/s]\u001b[A\n",
      " 91%|█████████████████████▊  | 346917888/382072689 [00:57<00:08, 4017208.25B/s]\u001b[A\n",
      " 91%|█████████████████████▉  | 348771328/382072689 [00:57<00:04, 6733774.64B/s]\u001b[A\n",
      " 92%|█████████████████████▉  | 349623296/382072689 [00:57<00:04, 6673231.15B/s]\u001b[A\n",
      " 92%|██████████████████████  | 350414848/382072689 [00:57<00:04, 6658729.72B/s]\u001b[A\n",
      " 92%|██████████████████████  | 351167488/382072689 [00:57<00:04, 6404772.79B/s]\u001b[A\n",
      " 92%|██████████████████████  | 351867904/382072689 [00:57<00:04, 6505434.64B/s]\u001b[A\n",
      " 92%|██████████████████████▏ | 352563200/382072689 [00:57<00:04, 6602241.45B/s]\u001b[A\n",
      " 92%|██████████████████████▏ | 353256448/382072689 [00:58<00:04, 6687102.85B/s]\u001b[A\n",
      " 93%|██████████████████████▏ | 354030592/382072689 [00:58<00:04, 6694789.55B/s]\u001b[A\n",
      " 93%|██████████████████████▎ | 354751488/382072689 [00:58<00:04, 6809915.62B/s]\u001b[A\n",
      " 93%|██████████████████████▎ | 355445760/382072689 [00:58<00:04, 6590258.17B/s]\u001b[A\n",
      " 93%|██████████████████████▎ | 356114432/382072689 [00:58<00:03, 6554046.26B/s]\u001b[A\n",
      " 93%|██████████████████████▍ | 356799488/382072689 [00:58<00:03, 6373033.41B/s]\u001b[A\n",
      " 94%|██████████████████████▍ | 357504000/382072689 [00:58<00:03, 6559932.37B/s]\u001b[A\n",
      " 94%|██████████████████████▍ | 358165504/382072689 [00:58<00:03, 6299599.69B/s]\u001b[A\n",
      " 94%|██████████████████████▌ | 358847488/382072689 [00:58<00:03, 6411633.21B/s]\u001b[A\n",
      " 94%|██████████████████████▌ | 359524352/382072689 [00:59<00:03, 6496175.31B/s]\u001b[A\n",
      " 94%|██████████████████████▋ | 360240128/382072689 [00:59<00:03, 6424387.33B/s]\u001b[A\n",
      " 94%|██████████████████████▋ | 360961024/382072689 [00:59<00:03, 6624100.34B/s]\u001b[A\n",
      " 95%|██████████████████████▋ | 361626624/382072689 [00:59<00:03, 6631027.08B/s]\u001b[A\n",
      " 95%|██████████████████████▊ | 362292224/382072689 [00:59<00:03, 6079084.49B/s]\u001b[A\n",
      " 95%|██████████████████████▊ | 362953728/382072689 [00:59<00:03, 6203109.03B/s]\u001b[A\n",
      " 95%|██████████████████████▊ | 363664384/382072689 [00:59<00:02, 6442141.29B/s]\u001b[A\n",
      " 95%|██████████████████████▉ | 364434432/382072689 [00:59<00:02, 6514345.75B/s]\u001b[A\n",
      " 96%|██████████████████████▉ | 365090816/382072689 [00:59<00:02, 5984101.01B/s]\u001b[A\n",
      " 96%|██████████████████████▉ | 365699072/382072689 [01:00<00:02, 5964052.98B/s]\u001b[A\n",
      " 96%|███████████████████████ | 366466048/382072689 [01:00<00:02, 6175311.25B/s]\u001b[A\n",
      " 96%|███████████████████████ | 367367168/382072689 [01:00<00:02, 6682395.57B/s]\u001b[A\n",
      " 96%|███████████████████████ | 368037888/382072689 [01:00<00:02, 6623362.09B/s]\u001b[A\n",
      " 97%|███████████████████████▏| 368710656/382072689 [01:00<00:02, 6382717.07B/s]\u001b[A\n",
      " 97%|███████████████████████▏| 369350656/382072689 [01:00<00:02, 4601780.41B/s]\u001b[A\n",
      " 97%|███████████████████████▎| 370809856/382072689 [01:00<00:01, 6683463.81B/s]\u001b[A\n",
      " 97%|███████████████████████▎| 371581952/382072689 [01:00<00:01, 6450043.28B/s]\u001b[A\n",
      " 97%|███████████████████████▍| 372298752/382072689 [01:01<00:01, 6574470.44B/s]\u001b[A\n",
      " 98%|███████████████████████▍| 373009408/382072689 [01:01<00:01, 5988934.12B/s]\u001b[A\n",
      " 98%|███████████████████████▍| 373675008/382072689 [01:01<00:01, 6128637.71B/s]\u001b[A\n",
      " 98%|███████████████████████▌| 374321152/382072689 [01:01<00:01, 6168676.23B/s]\u001b[A\n",
      " 98%|███████████████████████▌| 375093248/382072689 [01:01<00:01, 6373234.05B/s]\u001b[A\n",
      " 98%|███████████████████████▌| 375788544/382072689 [01:01<00:00, 6503868.89B/s]\u001b[A\n",
      " 99%|███████████████████████▋| 376453120/382072689 [01:01<00:00, 6515091.75B/s]\u001b[A\n",
      " 99%|███████████████████████▋| 377148416/382072689 [01:01<00:00, 6362440.07B/s]\u001b[A\n",
      " 99%|███████████████████████▋| 377792512/382072689 [01:01<00:00, 6353564.48B/s]\u001b[A\n",
      " 99%|███████████████████████▊| 378564608/382072689 [01:02<00:00, 6489552.91B/s]\u001b[A\n",
      " 99%|███████████████████████▊| 379311104/382072689 [01:02<00:00, 6736700.23B/s]\u001b[A\n",
      " 99%|███████████████████████▊| 379988992/382072689 [01:02<00:00, 6737183.60B/s]\u001b[A\n",
      "100%|███████████████████████▉| 380665856/382072689 [01:02<00:00, 6436763.63B/s]\u001b[A\n",
      "100%|███████████████████████▉| 381314048/382072689 [01:02<00:00, 6170499.04B/s]\u001b[A\n",
      "100%|████████████████████████| 382072689/382072689 [01:02<00:00, 6098409.91B/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "# 加载预训练的bert模型\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-chinese', num_labels=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "153b0c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换为torch tensor\n",
    "t_seqs = torch.tensor(seqs, dtype=torch.long)\n",
    "t_seq_masks = torch.tensor(seq_masks, dtype = torch.long)\n",
    "t_seq_segments = torch.tensor(seq_segments, dtype = torch.long)\n",
    "t_labels = torch.tensor(labels, dtype = torch.long)\n",
    "\n",
    "train_data = TensorDataset(t_seqs, t_seq_masks, t_seq_segments, t_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloder = DataLoader(dataset= train_data, sampler= train_sampler,batch_size = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "30e4f074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将模型转换为trin mode\n",
    "model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "49d88652",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class BertPooler(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BertPooler, self).__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        # We \"pool\" the model by simply taking the hidden state corresponding\n",
    "        # to the first token.\n",
    "        first_token_tensor = hidden_states[:, 0]\n",
    "        pooled_output = self.dense(first_token_tensor)\n",
    "        pooled_output = self.activation(pooled_output)\n",
    "        return pooled_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "87b6397f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 待优化的参数\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        'params':\n",
    "        [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "        'weight_decay':\n",
    "        0.01\n",
    "    },\n",
    "    {\n",
    "        'params':\n",
    "        [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "        'weight_decay':\n",
    "        0.0\n",
    "    }\n",
    "]\n",
    "\n",
    "optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "                     lr=2e-05,\n",
    "                     warmup= 0.1 ,\n",
    "                     t_total= 2000)\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "53a08ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:   0%|                                             | 0/2 [00:00<?, ?it/s]\u001b[A<ipython-input-42-c1c9fc3715d6>:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  tqdm_notebook(train_dataloder, desc='Iteration')):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfbfd46f823e4ae092c936076ec62681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.181278"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  50%|█████████████████▌                 | 1/2 [28:38<28:38, 1718.66s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01f35fcc07784a2bb0db798ea3e87648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.305909"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 100%|███████████████████████████████████| 2/2 [57:55<00:00, 1737.82s/it]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "# 存储每一个batch的loss\n",
    "loss_collect = []\n",
    "for i in trange(2, desc='Epoch'):\n",
    "    for step, batch_data in enumerate(\n",
    "            tqdm_notebook(train_dataloder, desc='Iteration')):\n",
    "        batch_data = tuple(t.to(device) for t in batch_data)\n",
    "        batch_seqs, batch_seq_masks, batch_seq_segments, batch_labels = batch_data\n",
    "        # 对标签进行onehot编码\n",
    "        one_hot = torch.zeros(batch_labels.size(0), 4).long()\n",
    "        one_hot_batch_labels = one_hot.scatter_(\n",
    "            dim=1,\n",
    "            index=torch.unsqueeze(batch_labels, dim=1),\n",
    "            src=torch.ones(batch_labels.size(0), 4).long())\n",
    "\n",
    "        logits = model(\n",
    "            batch_seqs, batch_seq_masks, batch_seq_segments, labels=None)\n",
    "        logits = logits.softmax(dim=1)\n",
    "        loss_function = CrossEntropyLoss()\n",
    "        loss = loss_function(logits, batch_labels)\n",
    "        loss.backward()\n",
    "        loss_collect.append(loss.item())\n",
    "        print(\"\\r%f\" % loss, end='')\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5b4605c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.save(model,open(os.path.join(root_path,\"fine_tuned_chinese_bert.bin\"),\"wb\"))\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(range(len(loss_collect)), loss_collect,'g.')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "551e34d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7878</th>\n",
       "      <td>2</td>\n",
       "      <td>回复总有一些故事会让我们感动总有一些坚持让我们汗颜总有一些守望让我们看到希望~ ！看了，很感...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3224</th>\n",
       "      <td>0</td>\n",
       "      <td>【7种食物改善心情】①巧克力减少应激激素水平缓解紧张情绪②菠菜富含叶酸消除倦怠③花生酱富含蛋...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>0</td>\n",
       "      <td>好贱的狗郁闷中的时候成功笑了，谢谢~ ！装B 的最高境界。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4432</th>\n",
       "      <td>0</td>\n",
       "      <td>很无耐也很无辜，但是现实就是这么残酷，卡卡需要学习和成长。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4835</th>\n",
       "      <td>2</td>\n",
       "      <td>我最近变的好宅好宅.要发霉了谁带我出去溜达溜达~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>0</td>\n",
       "      <td>好饿啊咸味香肠面包的链接也重新放一次好了beitaichufang .com recipe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7269</th>\n",
       "      <td>0</td>\n",
       "      <td>拼国粹，他们哪里是对手哦中国队力压阿根廷</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>0</td>\n",
       "      <td>我的一个朋友的QQ 签名：再丑也要谈恋爱~ ~ 谈到世界充满爱~ ~ ~ ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>3</td>\n",
       "      <td>珍惜身边人加油啊！我们全部都支持你啊。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4628</th>\n",
       "      <td>1</td>\n",
       "      <td>伤得不轻！糖糖疼得站都站不起来！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7053</th>\n",
       "      <td>1</td>\n",
       "      <td>我来晚了咩？？被子大哥，早上好！久闻大名哇！晒被子都没位置了…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3634</th>\n",
       "      <td>3</td>\n",
       "      <td>北京的朋友注意一下。看到请帮忙转！！帮忙转万能的微博你显灵吧家里人肯定急死了~ 帮忙转【寻人...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3215</th>\n",
       "      <td>3</td>\n",
       "      <td>江苏综艺台8月2日起周一至周四每晚10：15播出“家族诞生”我哭……上海看不到这地方台</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3707</th>\n",
       "      <td>0</td>\n",
       "      <td>826快樂 ～～～</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7066</th>\n",
       "      <td>0</td>\n",
       "      <td>这要是06年决赛就好了。太他妈搞了！！！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2965</th>\n",
       "      <td>0</td>\n",
       "      <td>太酷了日本的新型红绿灯屏蔽墙~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8644</th>\n",
       "      <td>3</td>\n",
       "      <td>缅怀~ 迈克尔-杰克逊。于2009年6月25日离家，离家时身着白色衬衣，下身穿九分裤，白袜子...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6469</th>\n",
       "      <td>0</td>\n",
       "      <td>转，红版再开，一定要积极灌水，努力考据，及时沟通。怎样都行，红到那里，我到那里[花。]不过个...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8921</th>\n",
       "      <td>0</td>\n",
       "      <td>巴基斯坦馆</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>1</td>\n",
       "      <td>哈哈！爱你爱自己狮子座。第二名：天蝎座。第三名：水瓶座。第四名：射手座。第五名：双鱼座。第六...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7356</th>\n",
       "      <td>3</td>\n",
       "      <td>微博力量大。！！！不是说微博力量大吗？？可以吗？》？？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0</td>\n",
       "      <td>苏格兰那地方哪来的毛笋。。。o (╯ □╰ )o 真够背的熊猫其实很BH 的……人家是熊熊猫...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2167</th>\n",
       "      <td>0</td>\n",
       "      <td>据说一个在学中文的外国人看到\" wife \" 和\" I \" 的同义词表，吐血而亡。。。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5975</th>\n",
       "      <td>1</td>\n",
       "      <td>真的很喜歡 ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2105</th>\n",
       "      <td>3</td>\n",
       "      <td>好措的TINA 奶奶啊。。。如果有机会坐上时光机，我最想去到明年演唱会现场，好难熬啊如果有机...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7054</th>\n",
       "      <td>3</td>\n",
       "      <td>饭堂的菜好恶心啊，东西都好恶心啊~ ~ ~ 中午吃不下饭，搞到下午要吃零食充饥，晚上的饺子也...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6145</th>\n",
       "      <td>0</td>\n",
       "      <td>漂亮近来，由于太阳黑子活动频繁，极光屡屡光临地球，产生了一系列令人赞叹的天文奇观。图为9月1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2929</th>\n",
       "      <td>1</td>\n",
       "      <td>愤怒!真实再现菲律宾劫匪持枪杀害人质全过程</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5460</th>\n",
       "      <td>3</td>\n",
       "      <td>在家应该学习的。恩，学习，学习。光说不做，鄙视个自己先。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6810</th>\n",
       "      <td>0</td>\n",
       "      <td>中国，这个有着世界上最长的收费公路的国家是一个很神奇的国家此次大堵车事件，应该问责公安部，交...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8500</th>\n",
       "      <td>0</td>\n",
       "      <td>個 白鴿 轉 ...轉 得很遠 ...而且...吃得很飽 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>2</td>\n",
       "      <td>这就是我爱着的团啊~ T T 这才是SUJU ..永不分离发光的友情好好听你们永远同在SJ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>0</td>\n",
       "      <td>这小妞儿··贼俏！！！娇俏少女来咯。哈哈哈。笔笔今晚参加动漫节开幕式晚会的新发型，大家还喜欢吗？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>0</td>\n",
       "      <td>发个滚滚就专心吃滚滚滚滚真是忒可爱了</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3279</th>\n",
       "      <td>2</td>\n",
       "      <td>反正我就是会默默地不安逸到星期天晚上……</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>0</td>\n",
       "      <td>你爸爸不是国王，所以别再把自己当公主了，其实你没那么重要。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>2</td>\n",
       "      <td>MUA MUA 我发现自己长期以来一直在开批自批坚真纠错中执着开批自批坚真纠错。一篇社论5分...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5165</th>\n",
       "      <td>1</td>\n",
       "      <td>哎呦，3点半休息室领导找，我滴小心肝哟！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1906</th>\n",
       "      <td>3</td>\n",
       "      <td>送给共勉，哈哈失去的东西，其实从来未曾真正地属于你，也不必惋惜。早安</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713</th>\n",
       "      <td>0</td>\n",
       "      <td>（22）走出地下室，看看眼前一条破旧的小街道，恍然若梦。一抬头，见对面一家不大的烤肉店门头赫...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>0</td>\n",
       "      <td>几天的踢馆让27强领略到群众的力量！为了得到更多的智慧，从今天开始踢馆活动要并评论才能进入获...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4588</th>\n",
       "      <td>0</td>\n",
       "      <td>求详细，王导咋个流氓法？我也特爱流氓~ 尤其他这种雅痞 ，没免疫力啊哈哈~ 對 說 ：你太不...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4236</th>\n",
       "      <td>2</td>\n",
       "      <td>！！！。想妞啊。。一到半夜，DM 们都统一介样子了。。默默内牛..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>0</td>\n",
       "      <td>回复点开了这哪是猴子这是驴吧？对人类的报复啊（点开图看）</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2628</th>\n",
       "      <td>3</td>\n",
       "      <td>黑匣子？？沉重哀悼那些在伊春“8·24”客机失事中遇难的同胞们。对于失事原因，希望相关部门一...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3340</th>\n",
       "      <td>1</td>\n",
       "      <td>回复鼻子进水的大象小姐你好挖！你那什么名字？！眼睛进沙的勃勃车女王。。。哈哈哈，你是脖子进水...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7570</th>\n",
       "      <td>0</td>\n",
       "      <td>哎呀呀，就在明天了啊。。7月24日（本周六）晚的快乐大本营应广大观众的要求，在节目最后新增了...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1810</th>\n",
       "      <td>0</td>\n",
       "      <td>回复我现在努力爱每一个人。。。說 的是珍惜你的每一天，因為 它過 去了就不再回來 。早安，親...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0</td>\n",
       "      <td>这一张无比给力！我宝宝昨晚太美了...看的我内牛...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3709</th>\n",
       "      <td>3</td>\n",
       "      <td>等到开学了。。恐怕灰很久不会再见面了吧。。灰多久？两个月？三个月？还是~ ~ ~</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      text                                              label\n",
       "7878     2  回复总有一些故事会让我们感动总有一些坚持让我们汗颜总有一些守望让我们看到希望~ ！看了，很感...\n",
       "3224     0  【7种食物改善心情】①巧克力减少应激激素水平缓解紧张情绪②菠菜富含叶酸消除倦怠③花生酱富含蛋...\n",
       "1919     0                      好贱的狗郁闷中的时候成功笑了，谢谢~ ！装B 的最高境界。\n",
       "4432     0                      很无耐也很无辜，但是现实就是这么残酷，卡卡需要学习和成长。\n",
       "4835     2                           我最近变的好宅好宅.要发霉了谁带我出去溜达溜达~\n",
       "4895     0  好饿啊咸味香肠面包的链接也重新放一次好了beitaichufang .com recipe ...\n",
       "7269     0                               拼国粹，他们哪里是对手哦中国队力压阿根廷\n",
       "1451     0             我的一个朋友的QQ 签名：再丑也要谈恋爱~ ~ 谈到世界充满爱~ ~ ~ ~\n",
       "1742     3                                珍惜身边人加油啊！我们全部都支持你啊。\n",
       "4628     1                                   伤得不轻！糖糖疼得站都站不起来！\n",
       "7053     1                    我来晚了咩？？被子大哥，早上好！久闻大名哇！晒被子都没位置了…\n",
       "3634     3  北京的朋友注意一下。看到请帮忙转！！帮忙转万能的微博你显灵吧家里人肯定急死了~ 帮忙转【寻人...\n",
       "3215     3        江苏综艺台8月2日起周一至周四每晚10：15播出“家族诞生”我哭……上海看不到这地方台\n",
       "3707     0                                          826快樂 ～～～\n",
       "7066     0                               这要是06年决赛就好了。太他妈搞了！！！\n",
       "2965     0                                    太酷了日本的新型红绿灯屏蔽墙~\n",
       "8644     3  缅怀~ 迈克尔-杰克逊。于2009年6月25日离家，离家时身着白色衬衣，下身穿九分裤，白袜子...\n",
       "6469     0  转，红版再开，一定要积极灌水，努力考据，及时沟通。怎样都行，红到那里，我到那里[花。]不过个...\n",
       "8921     0                                              巴基斯坦馆\n",
       "1254     1  哈哈！爱你爱自己狮子座。第二名：天蝎座。第三名：水瓶座。第四名：射手座。第五名：双鱼座。第六...\n",
       "7356     3                        微博力量大。！！！不是说微博力量大吗？？可以吗？》？？\n",
       "180      0  苏格兰那地方哪来的毛笋。。。o (╯ □╰ )o 真够背的熊猫其实很BH 的……人家是熊熊猫...\n",
       "2167     0        据说一个在学中文的外国人看到\" wife \" 和\" I \" 的同义词表，吐血而亡。。。\n",
       "5975     1                                            真的很喜歡 ?\n",
       "2105     3  好措的TINA 奶奶啊。。。如果有机会坐上时光机，我最想去到明年演唱会现场，好难熬啊如果有机...\n",
       "7054     3  饭堂的菜好恶心啊，东西都好恶心啊~ ~ ~ 中午吃不下饭，搞到下午要吃零食充饥，晚上的饺子也...\n",
       "6145     0  漂亮近来，由于太阳黑子活动频繁，极光屡屡光临地球，产生了一系列令人赞叹的天文奇观。图为9月1...\n",
       "2929     1                              愤怒!真实再现菲律宾劫匪持枪杀害人质全过程\n",
       "5460     3                       在家应该学习的。恩，学习，学习。光说不做，鄙视个自己先。\n",
       "6810     0  中国，这个有着世界上最长的收费公路的国家是一个很神奇的国家此次大堵车事件，应该问责公安部，交...\n",
       "8500     0                   個 白鴿 轉 ...轉 得很遠 ...而且...吃得很飽 ...\n",
       "801      2  这就是我爱着的团啊~ T T 这才是SUJU ..永不分离发光的友情好好听你们永远同在SJ ...\n",
       "2024     0   这小妞儿··贼俏！！！娇俏少女来咯。哈哈哈。笔笔今晚参加动漫节开幕式晚会的新发型，大家还喜欢吗？\n",
       "1345     0                                 发个滚滚就专心吃滚滚滚滚真是忒可爱了\n",
       "3279     2                               反正我就是会默默地不安逸到星期天晚上……\n",
       "554      0                      你爸爸不是国王，所以别再把自己当公主了，其实你没那么重要。\n",
       "946      2  MUA MUA 我发现自己长期以来一直在开批自批坚真纠错中执着开批自批坚真纠错。一篇社论5分...\n",
       "5165     1                               哎呦，3点半休息室领导找，我滴小心肝哟！\n",
       "1906     3                 送给共勉，哈哈失去的东西，其实从来未曾真正地属于你，也不必惋惜。早安\n",
       "1713     0  （22）走出地下室，看看眼前一条破旧的小街道，恍然若梦。一抬头，见对面一家不大的烤肉店门头赫...\n",
       "1297     0  几天的踢馆让27强领略到群众的力量！为了得到更多的智慧，从今天开始踢馆活动要并评论才能进入获...\n",
       "4588     0  求详细，王导咋个流氓法？我也特爱流氓~ 尤其他这种雅痞 ，没免疫力啊哈哈~ 對 說 ：你太不...\n",
       "4236     2                  ！！！。想妞啊。。一到半夜，DM 们都统一介样子了。。默默内牛..\n",
       "338      0                       回复点开了这哪是猴子这是驴吧？对人类的报复啊（点开图看）\n",
       "2628     3  黑匣子？？沉重哀悼那些在伊春“8·24”客机失事中遇难的同胞们。对于失事原因，希望相关部门一...\n",
       "3340     1  回复鼻子进水的大象小姐你好挖！你那什么名字？！眼睛进沙的勃勃车女王。。。哈哈哈，你是脖子进水...\n",
       "7570     0  哎呀呀，就在明天了啊。。7月24日（本周六）晚的快乐大本营应广大观众的要求，在节目最后新增了...\n",
       "1810     0  回复我现在努力爱每一个人。。。說 的是珍惜你的每一天，因為 它過 去了就不再回來 。早安，親...\n",
       "127      0                        这一张无比给力！我宝宝昨晚太美了...看的我内牛...\n",
       "3709     3           等到开学了。。恐怕灰很久不会再见面了吧。。灰多久？两个月？三个月？还是~ ~ ~"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e14e0669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text  label\n",
      "7878  回复总有一些故事会让我们感动总有一些坚持让我们汗颜总有一些守望让我们看到希望~ ！看了，很感...      2\n",
      "3224  【7种食物改善心情】①巧克力减少应激激素水平缓解紧张情绪②菠菜富含叶酸消除倦怠③花生酱富含蛋...      0\n",
      "1919                      好贱的狗郁闷中的时候成功笑了，谢谢~ ！装B 的最高境界。      0\n",
      "4432                      很无耐也很无辜，但是现实就是这么残酷，卡卡需要学习和成长。      0\n",
      "4835                           我最近变的好宅好宅.要发霉了谁带我出去溜达溜达~      2\n",
      "4895  好饿啊咸味香肠面包的链接也重新放一次好了beitaichufang .com recipe ...      0\n",
      "7269                               拼国粹，他们哪里是对手哦中国队力压阿根廷      0\n",
      "1451             我的一个朋友的QQ 签名：再丑也要谈恋爱~ ~ 谈到世界充满爱~ ~ ~ ~      0\n",
      "1742                                珍惜身边人加油啊！我们全部都支持你啊。      3\n",
      "4628                                   伤得不轻！糖糖疼得站都站不起来！      1\n",
      "7053                    我来晚了咩？？被子大哥，早上好！久闻大名哇！晒被子都没位置了…      1\n",
      "3634  北京的朋友注意一下。看到请帮忙转！！帮忙转万能的微博你显灵吧家里人肯定急死了~ 帮忙转【寻人...      3\n",
      "3215        江苏综艺台8月2日起周一至周四每晚10：15播出“家族诞生”我哭……上海看不到这地方台      3\n",
      "3707                                          826快樂 ～～～      0\n",
      "7066                               这要是06年决赛就好了。太他妈搞了！！！      0\n",
      "2965                                    太酷了日本的新型红绿灯屏蔽墙~      0\n",
      "8644  缅怀~ 迈克尔-杰克逊。于2009年6月25日离家，离家时身着白色衬衣，下身穿九分裤，白袜子...      3\n",
      "6469  转，红版再开，一定要积极灌水，努力考据，及时沟通。怎样都行，红到那里，我到那里[花。]不过个...      0\n",
      "8921                                              巴基斯坦馆      0\n",
      "1254  哈哈！爱你爱自己狮子座。第二名：天蝎座。第三名：水瓶座。第四名：射手座。第五名：双鱼座。第六...      1\n",
      "7356                        微博力量大。！！！不是说微博力量大吗？？可以吗？》？？      3\n",
      "180   苏格兰那地方哪来的毛笋。。。o (╯ □╰ )o 真够背的熊猫其实很BH 的……人家是熊熊猫...      0\n",
      "2167        据说一个在学中文的外国人看到\" wife \" 和\" I \" 的同义词表，吐血而亡。。。      0\n",
      "5975                                            真的很喜歡 ?      1\n",
      "2105  好措的TINA 奶奶啊。。。如果有机会坐上时光机，我最想去到明年演唱会现场，好难熬啊如果有机...      3\n",
      "7054  饭堂的菜好恶心啊，东西都好恶心啊~ ~ ~ 中午吃不下饭，搞到下午要吃零食充饥，晚上的饺子也...      3\n",
      "6145  漂亮近来，由于太阳黑子活动频繁，极光屡屡光临地球，产生了一系列令人赞叹的天文奇观。图为9月1...      0\n",
      "2929                              愤怒!真实再现菲律宾劫匪持枪杀害人质全过程      1\n",
      "5460                       在家应该学习的。恩，学习，学习。光说不做，鄙视个自己先。      3\n",
      "6810  中国，这个有着世界上最长的收费公路的国家是一个很神奇的国家此次大堵车事件，应该问责公安部，交...      0\n",
      "8500                   個 白鴿 轉 ...轉 得很遠 ...而且...吃得很飽 ...      0\n",
      "801   这就是我爱着的团啊~ T T 这才是SUJU ..永不分离发光的友情好好听你们永远同在SJ ...      2\n",
      "2024   这小妞儿··贼俏！！！娇俏少女来咯。哈哈哈。笔笔今晚参加动漫节开幕式晚会的新发型，大家还喜欢吗？      0\n",
      "1345                                 发个滚滚就专心吃滚滚滚滚真是忒可爱了      0\n",
      "3279                               反正我就是会默默地不安逸到星期天晚上……      2\n",
      "554                       你爸爸不是国王，所以别再把自己当公主了，其实你没那么重要。      0\n",
      "946   MUA MUA 我发现自己长期以来一直在开批自批坚真纠错中执着开批自批坚真纠错。一篇社论5分...      2\n",
      "5165                               哎呦，3点半休息室领导找，我滴小心肝哟！      1\n",
      "1906                 送给共勉，哈哈失去的东西，其实从来未曾真正地属于你，也不必惋惜。早安      3\n",
      "1713  （22）走出地下室，看看眼前一条破旧的小街道，恍然若梦。一抬头，见对面一家不大的烤肉店门头赫...      0\n",
      "1297  几天的踢馆让27强领略到群众的力量！为了得到更多的智慧，从今天开始踢馆活动要并评论才能进入获...      0\n",
      "4588  求详细，王导咋个流氓法？我也特爱流氓~ 尤其他这种雅痞 ，没免疫力啊哈哈~ 對 說 ：你太不...      0\n",
      "4236                  ！！！。想妞啊。。一到半夜，DM 们都统一介样子了。。默默内牛..      2\n",
      "338                        回复点开了这哪是猴子这是驴吧？对人类的报复啊（点开图看）      0\n",
      "2628  黑匣子？？沉重哀悼那些在伊春“8·24”客机失事中遇难的同胞们。对于失事原因，希望相关部门一...      3\n",
      "3340  回复鼻子进水的大象小姐你好挖！你那什么名字？！眼睛进沙的勃勃车女王。。。哈哈哈，你是脖子进水...      1\n",
      "7570  哎呀呀，就在明天了啊。。7月24日（本周六）晚的快乐大本营应广大观众的要求，在节目最后新增了...      0\n",
      "1810  回复我现在努力爱每一个人。。。說 的是珍惜你的每一天，因為 它過 去了就不再回來 。早安，親...      0\n",
      "127                         这一张无比给力！我宝宝昨晚太美了...看的我内牛...      0\n",
      "3709           等到开学了。。恐怕灰很久不会再见面了吧。。灰多久？两个月？三个月？还是~ ~ ~      3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-72-456d06848cb3>:23: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch_data in tqdm_notebook(test_dataloder, desc = 'TEST'):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4be467e7c2f7429c8a77b4838d8aaa51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TEST:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.68        26\n",
      "           1       0.00      0.00      0.00         7\n",
      "           2       0.00      0.00      0.00         6\n",
      "           3       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.52        50\n",
      "   macro avg       0.13      0.25      0.17        50\n",
      "weighted avg       0.27      0.52      0.36        50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luoyan011\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luoyan011\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luoyan011\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# rawdata = pd.read_csv(os.path.join(root_path,'simplifyweibo_4_moods.csv'))\n",
    "rawdata = data.sample(50,random_state=2)\n",
    "# rawdata.columns = ['label','text']\n",
    "test_data = rawdata[['text','label']]\n",
    "print(test_data)\n",
    "# 标签ID化\n",
    "test_data['label'] = le.transform(test_data.label.tolist())\n",
    "# 转换为tensor\n",
    "test_seqs, test_seq_masks, test_seq_segments, test_labels = processor.get_input(\n",
    "    dataset=test_data, max_seq_len=30)\n",
    "test_seqs = torch.tensor(test_seqs, dtype=torch.long)\n",
    "test_seq_masks = torch.tensor(test_seq_masks, dtype = torch.long)\n",
    "test_seq_segments = torch.tensor(test_seq_segments, dtype = torch.long)\n",
    "test_labels = torch.tensor(test_labels, dtype = torch.long)\n",
    "test_data = TensorDataset(test_seqs, test_seq_masks, test_seq_segments, test_labels)\n",
    "test_dataloder = DataLoader(dataset= test_data, batch_size = 1)\n",
    "# 用于存储预测标签与真实标签\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "model.eval()\n",
    "# 预测\n",
    "with torch.no_grad():\n",
    "    for batch_data in tqdm_notebook(test_dataloder, desc = 'TEST'):\n",
    "        batch_data = tuple(t.to(device) for t in batch_data)\n",
    "        batch_seqs, batch_seq_masks, batch_seq_segments, batch_labels = batch_data        \n",
    "        logits = model(\n",
    "            batch_seqs, batch_seq_masks, batch_seq_segments, labels=None)\n",
    "        logits = logits.softmax(dim=1).argmax(dim = 1)\n",
    "        pred_labels.append(logits.detach().numpy())\n",
    "        true_labels.append(batch_labels.detach().numpy())\n",
    "# 查看各个类别的准召\n",
    "print(classification_report(np.concatenate(true_labels), np.concatenate(pred_labels)))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d1ac18cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64)]\n"
     ]
    }
   ],
   "source": [
    "print(pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "330b2ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([3], dtype=int64), array([0], dtype=int64), array([3], dtype=int64), array([0], dtype=int64), array([1], dtype=int64), array([0], dtype=int64), array([3], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([3], dtype=int64), array([2], dtype=int64), array([0], dtype=int64), array([2], dtype=int64), array([3], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([2], dtype=int64), array([3], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([2], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([2], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([2], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([1], dtype=int64), array([0], dtype=int64), array([1], dtype=int64), array([0], dtype=int64), array([1], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([0], dtype=int64), array([2], dtype=int64), array([0], dtype=int64), array([2], dtype=int64), array([0], dtype=int64)]\n"
     ]
    }
   ],
   "source": [
    "print(true_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
