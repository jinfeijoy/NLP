{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0fa7731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b674544e670417480188fa8327205d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.2.2.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-21 15:27:28 INFO: Downloading default packages for language: en (English)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89786bc31ad946fe979915e6705e50e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading http://nlp.stanford.edu/software/stanza/1.2.2/en/default.zip:   0%|          | 0.00/412M [00:00<?,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-21 15:31:04 INFO: Finished downloading models and saved to C:\\Users\\luoyan011\\stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "stanza.download('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cc7adac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-21 15:31:04 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| pos       | combined  |\n",
      "| lemma     | combined  |\n",
      "| depparse  | combined  |\n",
      "| sentiment | sstplus   |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2021-08-21 15:31:04 INFO: Use device: cpu\n",
      "2021-08-21 15:31:04 INFO: Loading: tokenize\n",
      "2021-08-21 15:31:04 INFO: Loading: pos\n",
      "2021-08-21 15:31:05 INFO: Loading: lemma\n",
      "2021-08-21 15:31:05 INFO: Loading: depparse\n",
      "2021-08-21 15:31:05 INFO: Loading: sentiment\n",
      "2021-08-21 15:31:06 INFO: Loading: ner\n",
      "2021-08-21 15:31:07 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86769fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('Barack Obama was born in Hawaii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3b09f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  [\n",
      "    {\n",
      "      \"id\": 1,\n",
      "      \"text\": \"Barack\",\n",
      "      \"lemma\": \"Barack\",\n",
      "      \"upos\": \"PROPN\",\n",
      "      \"xpos\": \"NNP\",\n",
      "      \"feats\": \"Number=Sing\",\n",
      "      \"head\": 4,\n",
      "      \"deprel\": \"nsubj:pass\",\n",
      "      \"start_char\": 0,\n",
      "      \"end_char\": 6,\n",
      "      \"ner\": \"B-PERSON\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 2,\n",
      "      \"text\": \"Obama\",\n",
      "      \"lemma\": \"Obama\",\n",
      "      \"upos\": \"PROPN\",\n",
      "      \"xpos\": \"NNP\",\n",
      "      \"feats\": \"Number=Sing\",\n",
      "      \"head\": 1,\n",
      "      \"deprel\": \"flat\",\n",
      "      \"start_char\": 7,\n",
      "      \"end_char\": 12,\n",
      "      \"ner\": \"E-PERSON\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 3,\n",
      "      \"text\": \"was\",\n",
      "      \"lemma\": \"be\",\n",
      "      \"upos\": \"AUX\",\n",
      "      \"xpos\": \"VBD\",\n",
      "      \"feats\": \"Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin\",\n",
      "      \"head\": 4,\n",
      "      \"deprel\": \"aux:pass\",\n",
      "      \"start_char\": 13,\n",
      "      \"end_char\": 16,\n",
      "      \"ner\": \"O\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 4,\n",
      "      \"text\": \"born\",\n",
      "      \"lemma\": \"bear\",\n",
      "      \"upos\": \"VERB\",\n",
      "      \"xpos\": \"VBN\",\n",
      "      \"feats\": \"Tense=Past|VerbForm=Part|Voice=Pass\",\n",
      "      \"head\": 0,\n",
      "      \"deprel\": \"root\",\n",
      "      \"start_char\": 17,\n",
      "      \"end_char\": 21,\n",
      "      \"ner\": \"O\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 5,\n",
      "      \"text\": \"in\",\n",
      "      \"lemma\": \"in\",\n",
      "      \"upos\": \"ADP\",\n",
      "      \"xpos\": \"IN\",\n",
      "      \"head\": 6,\n",
      "      \"deprel\": \"case\",\n",
      "      \"start_char\": 22,\n",
      "      \"end_char\": 24,\n",
      "      \"ner\": \"O\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 6,\n",
      "      \"text\": \"Hawaii\",\n",
      "      \"lemma\": \"Hawaii\",\n",
      "      \"upos\": \"PROPN\",\n",
      "      \"xpos\": \"NNP\",\n",
      "      \"feats\": \"Number=Sing\",\n",
      "      \"head\": 4,\n",
      "      \"deprel\": \"obl\",\n",
      "      \"start_char\": 25,\n",
      "      \"end_char\": 31,\n",
      "      \"ner\": \"S-GPE\"\n",
      "    }\n",
      "  ]\n",
      "]\n",
      "[{\n",
      "  \"text\": \"Barack Obama\",\n",
      "  \"type\": \"PERSON\",\n",
      "  \"start_char\": 0,\n",
      "  \"end_char\": 12\n",
      "}, {\n",
      "  \"text\": \"Hawaii\",\n",
      "  \"type\": \"GPE\",\n",
      "  \"start_char\": 25,\n",
      "  \"end_char\": 31\n",
      "}]\n"
     ]
    }
   ],
   "source": [
    "print(doc)\n",
    "print(doc.entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9f8e10",
   "metadata": {},
   "source": [
    "## Dependency Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dc59c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-21 15:40:39 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2021-08-21 15:40:39 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| pos       | combined |\n",
      "| lemma     | combined |\n",
      "| depparse  | combined |\n",
      "========================\n",
      "\n",
      "2021-08-21 15:40:39 INFO: Use device: cpu\n",
      "2021-08-21 15:40:39 INFO: Loading: tokenize\n",
      "2021-08-21 15:40:39 INFO: Loading: pos\n",
      "2021-08-21 15:40:39 INFO: Loading: lemma\n",
      "2021-08-21 15:40:39 INFO: Loading: depparse\n",
      "2021-08-21 15:40:40 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1\tword: Barack\thead id: 4\thead: born\tdeprel: nsubj:pass\n",
      "id: 2\tword: Obama\thead id: 1\thead: Barack\tdeprel: flat\n",
      "id: 3\tword: was\thead id: 4\thead: born\tdeprel: aux:pass\n",
      "id: 4\tword: born\thead id: 0\thead: root\tdeprel: root\n",
      "id: 5\tword: in\thead id: 6\thead: Hawaii\tdeprel: case\n",
      "id: 6\tword: Hawaii\thead id: 4\thead: born\tdeprel: obl\n",
      "id: 7\tword: .\thead id: 4\thead: born\tdeprel: punct\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma,depparse')\n",
    "doc = nlp('Barack Obama was born in Hawaii.')\n",
    "print(*[f'id: {word.id}\\tword: {word.text}\\thead id: {word.head}\\thead: {sent.words[word.head-1].text if word.head > 0 else \"root\"}\\tdeprel: {word.deprel}' for sent in doc.sentences for word in sent.words], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd545574",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-21 15:42:00 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| depparse  | combined |\n",
      "========================\n",
      "\n",
      "2021-08-21 15:42:00 INFO: Use device: cpu\n",
      "2021-08-21 15:42:00 INFO: Loading: depparse\n",
      "2021-08-21 15:42:01 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  [\n",
      "    {\n",
      "      \"id\": 1,\n",
      "      \"text\": \"Test\",\n",
      "      \"lemma\": \"Test\",\n",
      "      \"upos\": \"NOUN\",\n",
      "      \"xpos\": \"NN\",\n",
      "      \"feats\": \"Number=Sing\",\n",
      "      \"head\": 2,\n",
      "      \"deprel\": \"compound\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 2,\n",
      "      \"text\": \"sentence\",\n",
      "      \"lemma\": \"sentence\",\n",
      "      \"upos\": \"NOUN\",\n",
      "      \"xpos\": \"NN\",\n",
      "      \"feats\": \"Number=Sing\",\n",
      "      \"head\": 0,\n",
      "      \"deprel\": \"root\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 3,\n",
      "      \"text\": \".\",\n",
      "      \"lemma\": \".\",\n",
      "      \"upos\": \"PUNCT\",\n",
      "      \"xpos\": \".\",\n",
      "      \"head\": 2,\n",
      "      \"deprel\": \"punct\"\n",
      "    }\n",
      "  ]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from stanza.models.common.doc import Document\n",
    "nlp = stanza.Pipeline(lang='en', processors='depparse', depparse_pretagged=True)\n",
    "pretagged_doc = Document([[{'id': 1, 'text': 'Test', 'lemma': 'Test', 'upos': 'NOUN', 'xpos': 'NN', 'feats': 'Number=Sing'}, {'id': 2, 'text': 'sentence', 'lemma': 'sentence', 'upos': 'NOUN', 'xpos': 'NN', 'feats': 'Number=Sing'}, {'id': 3, 'text': '.', 'lemma': '.', 'upos': 'PUNCT', 'xpos': '.'}]])\n",
    "doc = nlp(pretagged_doc)\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f57a79",
   "metadata": {},
   "source": [
    "## Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b95395f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-21 15:46:28 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2021-08-21 15:46:28 INFO: Use device: cpu\n",
      "2021-08-21 15:46:28 INFO: Loading: tokenize\n",
      "2021-08-21 15:46:28 INFO: Loading: ner\n",
      "2021-08-21 15:46:29 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entity: Chris Manning\ttype: PERSON\n",
      "entity: Stanford University\ttype: ORG\n",
      "entity: the Bay Area\ttype: LOC\n",
      "=========\n",
      "token: Chris\tner: B-PERSON\n",
      "token: Manning\tner: E-PERSON\n",
      "token: teaches\tner: O\n",
      "token: at\tner: O\n",
      "token: Stanford\tner: B-ORG\n",
      "token: University\tner: E-ORG\n",
      "token: .\tner: O\n",
      "token: He\tner: O\n",
      "token: lives\tner: O\n",
      "token: in\tner: O\n",
      "token: the\tner: B-LOC\n",
      "token: Bay\tner: I-LOC\n",
      "token: Area\tner: E-LOC\n",
      "token: .\tner: O\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,ner')\n",
    "doc = nlp(\"Chris Manning teaches at Stanford University. He lives in the Bay Area.\")\n",
    "print(*[f'entity: {ent.text}\\ttype: {ent.type}' for ent in doc.ents], sep='\\n')\n",
    "print('=========')\n",
    "print(*[f'token: {token.text}\\tner: {token.ner}' for sent in doc.sentences for token in sent.tokens], sep='\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
