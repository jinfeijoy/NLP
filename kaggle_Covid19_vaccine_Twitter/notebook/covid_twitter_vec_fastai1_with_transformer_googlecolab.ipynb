{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "covid_twitter_vec_fastai1_with_transformer_googlecolab.ipynb",
      "provenance": [],
<<<<<<< HEAD
      "collapsed_sections": []
=======
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMGgFik1lqTPw4E2s98nDmt",
      "include_colab_link": true
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
<<<<<<< HEAD
    "accelerator": "GPU"
  },
  "cells": [
    {
=======
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c7ba7662891348378367ccf142cc1711": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1862ede431c94c85a47dd2f07f3eb46e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_71b8ec360ff042f3bbbb3b74557c38dc",
              "IPY_MODEL_e295dd0d28c04d929792329d4c09d241"
            ]
          }
        },
        "1862ede431c94c85a47dd2f07f3eb46e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "71b8ec360ff042f3bbbb3b74557c38dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b3060d5bb0cd430c97fd9825cbff8500",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898823,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898823,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d916225cc501423092777694788de930"
          }
        },
        "e295dd0d28c04d929792329d4c09d241": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d7797a21c9ac45e2a82d87870e4027ef",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 899k/899k [00:00&lt;00:00, 944kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4836893364e34f24aa60374f1864db27"
          }
        },
        "b3060d5bb0cd430c97fd9825cbff8500": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d916225cc501423092777694788de930": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d7797a21c9ac45e2a82d87870e4027ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4836893364e34f24aa60374f1864db27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0bea7a4366b84fbd94859ea9c916399b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_964cc5e00d41415f8f2e2d3e9172196d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_91b0f0e8ecd54bb6ae1ac9c35f8daa11",
              "IPY_MODEL_19c6d0dfb73e4daf85159e232675195e"
            ]
          }
        },
        "964cc5e00d41415f8f2e2d3e9172196d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "91b0f0e8ecd54bb6ae1ac9c35f8daa11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2437178dd0594198a869afd6b1163e25",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f29699d4d46949dcadf7e741623fc3fc"
          }
        },
        "19c6d0dfb73e4daf85159e232675195e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6fb79597483342ada61fbba8d76a0fdd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 1.31MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_33498899f1614f65ab37c0316f41eea6"
          }
        },
        "2437178dd0594198a869afd6b1163e25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f29699d4d46949dcadf7e741623fc3fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6fb79597483342ada61fbba8d76a0fdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "33498899f1614f65ab37c0316f41eea6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d825bba4a3724c80afd25f3a2d140c7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4426d80d3c964d5c9e0613c0f12a6135",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1873f6b1aa544e13b2bca4a256fbb425",
              "IPY_MODEL_c3185dca06f8474abca1115d7b261c76"
            ]
          }
        },
        "4426d80d3c964d5c9e0613c0f12a6135": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1873f6b1aa544e13b2bca4a256fbb425": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_26945c064dc34ed99893fa3404dc3af5",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 481,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 481,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_59ab3115bb354caf892497a73c4d37fc"
          }
        },
        "c3185dca06f8474abca1115d7b261c76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4afa9fe458d74aa0a51e2a8d6e0ae5ec",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 481/481 [00:46&lt;00:00, 10.3B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_41ac469186d0440baf517a6bf4a58a7a"
          }
        },
        "26945c064dc34ed99893fa3404dc3af5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "59ab3115bb354caf892497a73c4d37fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4afa9fe458d74aa0a51e2a8d6e0ae5ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "41ac469186d0440baf517a6bf4a58a7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cce0a1ae13a94c6f8a0dedb636a30d23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3876d4b1586f434e96b4dfc46e56edfa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b8a66352e78847aa999dff6e804ca933",
              "IPY_MODEL_42c6d4e981624d9787d46983dee3aa1a"
            ]
          }
        },
        "3876d4b1586f434e96b4dfc46e56edfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b8a66352e78847aa999dff6e804ca933": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1a7db21b58ef45e0a8efa0d6396ff5da",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 501200538,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 501200538,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2c4186c995d64a70900ae1d5dfd236ac"
          }
        },
        "42c6d4e981624d9787d46983dee3aa1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f0b6447c14c747fcb13ff96f9a69b10c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 501M/501M [00:30&lt;00:00, 16.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ed23ad8506bc4f36861928859ba8df7f"
          }
        },
        "1a7db21b58ef45e0a8efa0d6396ff5da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2c4186c995d64a70900ae1d5dfd236ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f0b6447c14c747fcb13ff96f9a69b10c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ed23ad8506bc4f36861928859ba8df7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jinfeijoy/NLP/blob/main/kaggle_Covid19_vaccine_Twitter/notebook/covid_twitter_vec_fastai1_with_transformer_googlecolab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Zm4Mzx2heBJ",
<<<<<<< HEAD
        "outputId": "1524b928-2b1f-470d-ae08-31014d3890ac"
=======
        "outputId": "ff3e9079-d619-4d76-bb48-5cdf8ab780a1"
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
      },
      "source": [
        "#Please select GPU first (from Edit->NotebookSetting)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "import os\n",
        "import re\n",
        "from google.colab import drive\n",
        "!pip install fastai==1.0.58\n",
<<<<<<< HEAD
        "# !pip install urllib3==1.25.4\n",
=======
        "!pip install urllib3 == 1.25.4\n",
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
        "!pip install transformers==2.5.1\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "import transformers\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import random \n",
        "from fastai import *\n",
        "from fastai.text import *\n",
        "from fastai.callbacks import *"
      ],
<<<<<<< HEAD
      "execution_count": 26,
=======
      "execution_count": 3,
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fastai==1.0.58 in /usr/local/lib/python3.7/dist-packages (1.0.58)\n",
<<<<<<< HEAD
            "Requirement already satisfied: spacy>=2.0.18 in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (2.2.4)\n",
            "Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (7.352.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (4.6.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (20.9)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (1.1.5)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (0.9.1+cu101)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (3.2.2)\n",
            "Requirement already satisfied: fastprogress>=0.1.19 in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (1.0.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (2.7.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (2.23.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (7.1.2)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (1.4.1)\n",
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (1.3.2)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (1.8.1+cu101)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (2.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (0.8.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (3.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (57.0.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (1.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->fastai==1.0.58) (2.4.7)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai==1.0.58) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai==1.0.58) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai==1.0.58) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai==1.0.58) (1.3.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==1.0.58) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==1.0.58) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==1.0.58) (1.25.4)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==1.0.58) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->fastai==1.0.58) (3.7.4.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.0.18->fastai==1.0.58) (4.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->fastai==1.0.58) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.0.18->fastai==1.0.58) (3.4.1)\n",
            "Requirement already satisfied: transformers==2.5.1 in /usr/local/lib/python3.7/dist-packages (2.5.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (1.17.88)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (0.0.45)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (0.5.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (0.1.95)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (3.0.12)\n",
            "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.5.1) (0.4.2)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.5.1) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.21.0,>=1.20.88 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.5.1) (1.20.88)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.1) (1.25.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.1) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.1) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.5.1) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.5.1) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.5.1) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.88->boto3->transformers==2.5.1) (2.8.1)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
=======
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (1.3.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (7.1.2)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (1.8.1+cu101)\n",
            "Requirement already satisfied: spacy>=2.0.18 in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (2.2.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (1.1.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (3.13)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (3.2.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (20.9)\n",
            "Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (7.352.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (4.6.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (1.4.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (0.9.1+cu101)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (2.7.3)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (1.19.5)\n",
            "Requirement already satisfied: fastprogress>=0.1.19 in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (1.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->fastai==1.0.58) (3.7.4.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (0.8.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (3.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (2.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (0.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (57.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai==1.0.58) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai==1.0.58) (2018.9)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai==1.0.58) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai==1.0.58) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai==1.0.58) (0.10.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==1.0.58) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==1.0.58) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==1.0.58) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==1.0.58) (2.10)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.0.18->fastai==1.0.58) (4.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->fastai==1.0.58) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.0.18->fastai==1.0.58) (3.4.1)\n",
            "\u001b[31mERROR: Invalid requirement: '=='\u001b[0m\n",
            "Requirement already satisfied: transformers==2.5.1 in /usr/local/lib/python3.7/dist-packages (2.5.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (0.0.45)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (1.19.5)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (0.5.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (0.1.95)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (4.41.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (1.17.88)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.5.1) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.5.1) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.5.1) (7.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.1) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.1) (3.0.4)\n",
            "Requirement already satisfied: botocore<1.21.0,>=1.20.88 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.5.1) (1.20.88)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.5.1) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.5.1) (0.4.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.88->boto3->transformers==2.5.1) (2.8.1)\n",
            "Mounted at /content/drive\n"
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnpFT7WmFswE"
      },
      "source": [
        ""
      ],
<<<<<<< HEAD
      "execution_count": 1,
=======
      "execution_count": 3,
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "000Lxer88C6x"
      },
      "source": [
        "# Load Data\n",
        "Reference: https://www.kaggle.com/maroberti/fastai-with-transformers-bert-roberta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AB5kSJ-qh9JV"
      },
      "source": [
        "path = '/content/drive/MyDrive/colab_data'\n",
        "def de_emojify(inputString):\n",
        "    return inputString.encode('ascii', 'ignore').decode('ascii')\n",
        "def tweet_proc(df, text_col='text'):\n",
        "    df['orig_text'] = df[text_col]\n",
        "    # Remove twitter handles\n",
        "    df[text_col] = df[text_col].apply(lambda x:re.sub('@[^\\s]+','',x))\n",
        "    # Remove URLs\n",
        "    df[text_col] = df[text_col].apply(lambda x:re.sub(r\"http\\S+\", \"\", x))\n",
        "    # Remove emojis\n",
        "    df[text_col] = df[text_col].apply(de_emojify)\n",
        "    # Remove hashtags\n",
        "    df[text_col] = df[text_col].apply(lambda x:re.sub(r'\\B#\\S+','',x))\n",
        "    return df[df[text_col]!='']\n"
      ],
<<<<<<< HEAD
      "execution_count": 27,
=======
      "execution_count": 4,
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
<<<<<<< HEAD
          "height": 159
        },
        "id": "Eif24MQRQANx",
        "outputId": "952914a1-2c85-42c8-dd68-19386a01e442"
      },
      "source": [
        "# basic_tweet = pd.read_csv(os.path.join(path, \"covid-19_articles_data.csv\"))\n",
        "# basic_tweet = basic_tweet[basic_tweet.sentiment!='empty'].drop_duplicates().sample(n=100, random_state=66).reset_index(drop=True)\n",
=======
          "height": 142
        },
        "id": "Eif24MQRQANx",
        "outputId": "396e39f9-1823-4b3f-cc2d-6c66ad4c8af4"
      },
      "source": [
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
        "basic_tweet = pd.read_csv(os.path.join(path, \"tweet_dataset.csv\"))\n",
        "basic_tweet = basic_tweet[basic_tweet.sentiment!='empty'].drop_duplicates().reset_index(drop=True)\n",
        "basic_tweet = basic_tweet[['sentiment','new_sentiment','old_text']].rename(columns={'old_text':'text', 'sentiment':'emotion', 'new_sentiment':'sentiment'})\n",
        "basic_tweet = tweet_proc(basic_tweet,'text').dropna(subset=['sentiment'])\n",
<<<<<<< HEAD
        "print(len(basic_tweet))\n",
        "basic_tweet.head(3)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30678\n"
          ],
          "name": "stdout"
        },
        {
=======
        "basic_tweet.head(3)"
      ],
      "execution_count": 5,
      "outputs": [
        {
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "      <th>orig_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sadness</td>\n",
              "      <td>negative</td>\n",
              "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
              "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sadness</td>\n",
              "      <td>negative</td>\n",
              "      <td>Funeral ceremony...gloomy friday...</td>\n",
              "      <td>Funeral ceremony...gloomy friday...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>enthusiasm</td>\n",
              "      <td>positive</td>\n",
              "      <td>wants to hang out with friends SOON!</td>\n",
              "      <td>wants to hang out with friends SOON!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      emotion  ...                                          orig_text\n",
              "0     sadness  ...  Layin n bed with a headache  ughhhh...waitin o...\n",
              "1     sadness  ...                Funeral ceremony...gloomy friday...\n",
              "2  enthusiasm  ...               wants to hang out with friends SOON!\n",
              "\n",
              "[3 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
<<<<<<< HEAD
          "execution_count": 68
=======
          "execution_count": 5
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
        }
      ]
    },
    {
<<<<<<< HEAD
=======
      "cell_type": "code",
      "metadata": {
        "id": "vP1TVQc5h9oR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
      "cell_type": "markdown",
      "metadata": {
        "id": "7R_Io_SR9yjD"
      },
      "source": [
        "# Main transformers classes\n",
        "* A **model class** to load/store a particular pre-train model.\n",
        "* A **tokenizer class** to pre-process the data and make it compatible with a particular model.\n",
        "* A **configuration class** to load/store the configuration of a particular model.\n",
        "\n",
        "Pre-trained model name can be found here: https://huggingface.co/transformers/pretrained_models.html#pretrained-models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IosPm09PBT53"
      },
      "source": [
        "from transformers import PreTrainedModel, PreTrainedTokenizer, PretrainedConfig\n",
        "from transformers import BertForSequenceClassification, BertTokenizer, BertConfig\n",
        "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig\n",
        "from transformers import XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig\n",
        "from transformers import XLMForSequenceClassification, XLMTokenizer, XLMConfig\n",
        "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig"
      ],
<<<<<<< HEAD
      "execution_count": 69,
=======
      "execution_count": 6,
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5gG7whd94Ez"
      },
      "source": [
        "MODEL_CLASSES = {\n",
        "    'bert': (BertForSequenceClassification, BertTokenizer, BertConfig),\n",
        "    'xlnet': (XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig),\n",
        "    'xlm': (XLMForSequenceClassification, XLMTokenizer, XLMConfig),\n",
        "    'roberta': (RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig),\n",
        "    'distilbert': (DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig)\n",
        "}"
      ],
<<<<<<< HEAD
      "execution_count": 70,
=======
      "execution_count": 7,
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CebDd2j7-xLR"
      },
      "source": [
        "seed = 42\n",
        "use_fp16 = False\n",
        "bs = 16\n",
        "\n",
<<<<<<< HEAD
        "# model_type = 'roberta'\n",
        "# pretrained_model_name = 'roberta-base'\n",
        "\n",
        "model_type = 'bert'\n",
        "pretrained_model_name='bert-base-uncased'\n",
=======
        "model_type = 'roberta'\n",
        "pretrained_model_name = 'roberta-base'\n",
        "\n",
        "# model_type = 'bert'\n",
        "# pretrained_model_name='bert-base-uncased'\n",
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
        "\n",
        "# model_type = 'distilbert'\n",
        "# pretrained_model_name = 'distilbert-base-uncased'\n",
        "\n",
        "#model_type = 'xlm'\n",
        "#pretrained_model_name = 'xlm-clm-enfr-1024'\n",
        "\n",
        "# model_type = 'xlnet'\n",
        "# pretrained_model_name = 'xlnet-base-cased'"
      ],
<<<<<<< HEAD
      "execution_count": 71,
=======
      "execution_count": 8,
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a3TKgiIAIEx"
      },
      "source": [
        "model_class, tokenizer_class, config_class = MODEL_CLASSES[model_type]"
      ],
<<<<<<< HEAD
      "execution_count": 72,
=======
      "execution_count": 9,
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7EoC-U5BjEA"
      },
      "source": [
        "# Function to set the seed for generating random numbers\n",
        "def seed_all(seed_value):\n",
        "    random.seed(seed_value) # Python\n",
        "    np.random.seed(seed_value) # cpu vars\n",
        "    torch.manual_seed(seed_value) # cpu  vars\n",
        "    \n",
        "    if torch.cuda.is_available(): \n",
        "        torch.cuda.manual_seed(seed_value)\n",
        "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
        "        torch.backends.cudnn.deterministic = True  #needed\n",
        "        torch.backends.cudnn.benchmark = False"
      ],
<<<<<<< HEAD
      "execution_count": 73,
=======
      "execution_count": 10,
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HA0nSgbXBzdT"
      },
      "source": [
        "seed_all(seed)"
      ],
<<<<<<< HEAD
      "execution_count": 74,
=======
      "execution_count": 11,
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liNQGmNbCg22"
      },
      "source": [
        "# Data Pre-processing\n",
        "\n",
        "### Custom Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DboUvy0hB2Fx"
      },
      "source": [
        "class TransformersBaseTokenizer(BaseTokenizer):\n",
        "    \"\"\"Wrapper around PreTrainedTokenizer to be compatible with fast.ai\"\"\"\n",
        "    def __init__(self, pretrained_tokenizer: PreTrainedTokenizer, model_type = 'bert', **kwargs):\n",
        "        self._pretrained_tokenizer = pretrained_tokenizer\n",
        "        self.max_seq_len = pretrained_tokenizer.max_len#.model_max_length\n",
        "        self.model_type = model_type\n",
        "\n",
        "    def __call__(self, *args, **kwargs): \n",
        "        return self\n",
        "\n",
        "    def tokenizer(self, t:str) -> List[str]:\n",
        "        \"\"\"Limits the maximum sequence length and add the spesial tokens\"\"\"\n",
        "        CLS = self._pretrained_tokenizer.cls_token\n",
        "        SEP = self._pretrained_tokenizer.sep_token\n",
        "        if self.model_type in ['roberta']:\n",
        "            tokens = self._pretrained_tokenizer.tokenize(t, add_prefix_space=True)[:self.max_seq_len - 2]\n",
        "            tokens = [CLS] + tokens + [SEP]\n",
        "        else:\n",
        "            tokens = self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2]\n",
        "            if self.model_type in ['xlnet']:\n",
        "                tokens = tokens + [SEP] +  [CLS]\n",
        "            else:\n",
        "                tokens = [CLS] + tokens + [SEP]\n",
        "        return tokens"
      ],
<<<<<<< HEAD
      "execution_count": 75,
=======
      "execution_count": 12,
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
<<<<<<< HEAD
        "id": "ort7lHvgFik4"
=======
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "c7ba7662891348378367ccf142cc1711",
            "1862ede431c94c85a47dd2f07f3eb46e",
            "71b8ec360ff042f3bbbb3b74557c38dc",
            "e295dd0d28c04d929792329d4c09d241",
            "b3060d5bb0cd430c97fd9825cbff8500",
            "d916225cc501423092777694788de930",
            "d7797a21c9ac45e2a82d87870e4027ef",
            "4836893364e34f24aa60374f1864db27",
            "0bea7a4366b84fbd94859ea9c916399b",
            "964cc5e00d41415f8f2e2d3e9172196d",
            "91b0f0e8ecd54bb6ae1ac9c35f8daa11",
            "19c6d0dfb73e4daf85159e232675195e",
            "2437178dd0594198a869afd6b1163e25",
            "f29699d4d46949dcadf7e741623fc3fc",
            "6fb79597483342ada61fbba8d76a0fdd",
            "33498899f1614f65ab37c0316f41eea6"
          ]
        },
        "id": "ort7lHvgFik4",
        "outputId": "25cbff9a-ccd6-4eea-ee0f-5544a27020fe"
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
      },
      "source": [
        "transformer_tokenizer = tokenizer_class.from_pretrained(pretrained_model_name)\n",
        "transformer_base_tokenizer = TransformersBaseTokenizer(pretrained_tokenizer = transformer_tokenizer, model_type = model_type)\n",
        "fastai_tokenizer = Tokenizer(tok_func = transformer_base_tokenizer, pre_rules=[], post_rules=[])"
      ],
<<<<<<< HEAD
      "execution_count": 76,
      "outputs": []
=======
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c7ba7662891348378367ccf142cc1711",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0bea7a4366b84fbd94859ea9c916399b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2Nxo5SCJgwb"
      },
      "source": [
        "In this implementation, be carefull about 3 things :\n",
        "\n",
        "1. As we are not using RNN, we have to limit the sequence length to the model input size.\n",
        "2. Most of the models require special tokens placed at the beginning and end of the sequences.\n",
        "3. Some models like RoBERTa require a space to start the input string. For those models, the encoding methods should be called with `add_prefix_space` set to `True`.\n",
        "\n",
        "Below, you can find the resume of each pre-process requirement for the 5 model types used in this tutorial. You can also find this information on the HuggingFace documentation in each model section.\n",
        "\n",
        "`bert:       [CLS] + tokens + [SEP] + padding`\n",
        "\n",
        "`roberta:    [CLS] + prefix_space + tokens + [SEP] + padding`\n",
        "\n",
        "`distilbert: [CLS] + tokens + [SEP] + padding`\n",
        "\n",
        "`xlm:        [CLS] + tokens + [SEP] + padding`\n",
        "\n",
        "`xlnet:      padding + tokens + [SEP] + [CLS]`\n",
        "\n",
        "### Custom Numericalizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eB7VJoNoJ7HF"
      },
      "source": [
        "class TransformersVocab(Vocab):\n",
        "    def __init__(self, tokenizer: PreTrainedTokenizer):\n",
        "        super(TransformersVocab, self).__init__(itos = [])\n",
        "        self.tokenizer = tokenizer\n",
        "    \n",
        "    def numericalize(self, t:Collection[str]) -> List[int]:\n",
        "        \"Convert a list of tokens `t` to their ids.\"\n",
        "        return self.tokenizer.convert_tokens_to_ids(t)\n",
        "        #return self.tokenizer.encode(t)\n",
        "\n",
        "    def textify(self, nums:Collection[int], sep=' ') -> List[str]:\n",
        "        \"Convert a list of `nums` to their tokens.\"\n",
        "        nums = np.array(nums).tolist()\n",
        "        return sep.join(self.tokenizer.convert_ids_to_tokens(nums)) if sep is not None else self.tokenizer.convert_ids_to_tokens(nums)\n",
        "    \n",
        "    def __getstate__(self):\n",
        "        return {'itos':self.itos, 'tokenizer':self.tokenizer}\n",
        "\n",
        "    def __setstate__(self, state:dict):\n",
        "        self.itos = state['itos']\n",
        "        self.tokenizer = state['tokenizer']\n",
        "        self.stoi = collections.defaultdict(int,{v:k for k,v in enumerate(self.itos)})"
      ],
<<<<<<< HEAD
      "execution_count": 77,
=======
      "execution_count": 14,
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D__1A1C7ksnM"
      },
      "source": [
        "### Custom processor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7zTXr5Jkuo9"
      },
      "source": [
        "transformer_vocab = TransformersVocab(tokenizer = transformer_tokenizer)\n",
        "numericalize_processor = NumericalizeProcessor(vocab = transformer_vocab)\n",
        "tokenize_processor = TokenizeProcessor(tokenizer=fastai_tokenizer, include_bos = False, include_eos = False)\n",
        "transformer_processor = [tokenize_processor, numericalize_processor]"
      ],
<<<<<<< HEAD
      "execution_count": 78,
=======
      "execution_count": 15,
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chjKAN1vl14k"
      },
      "source": [
        "## Setting up the Databunch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-jmHRp4l5Si"
      },
      "source": [
        "pad_first = bool(model_type in ['xlnet'])\n",
        "pad_idx = transformer_tokenizer.pad_token_id"
      ],
<<<<<<< HEAD
      "execution_count": 79,
=======
      "execution_count": 16,
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk54ORSPpgU0"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(basic_tweet, test_size=0.3, random_state=42)"
      ],
<<<<<<< HEAD
      "execution_count": 80,
=======
      "execution_count": 17,
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "S_leu-wSlzsu",
<<<<<<< HEAD
        "outputId": "fb25b1c2-0fac-46e6-9894-e4c8b2063ed0"
=======
        "outputId": "1126517d-4d9f-4a37-8d2d-c7876b441ef3"
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
      },
      "source": [
        "databunch = (TextList.from_df(train, cols='text', processor=transformer_processor)\n",
        "             .split_by_rand_pct(0.1,seed=seed)\n",
        "             .label_from_df(cols= 'sentiment')\n",
        "             .add_test(test)\n",
        "             .databunch(bs=bs, pad_first=pad_first, pad_idx=pad_idx))"
      ],
<<<<<<< HEAD
      "execution_count": 81,
=======
      "execution_count": 18,
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fastai/core.py:299: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return np.array(a, dtype=dtype, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNZhJ-jlqBRC"
      },
      "source": [
        "Check batch and tokenizer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
<<<<<<< HEAD
          "height": 343
        },
        "id": "AN9RZye6pzx6",
        "outputId": "e9c79a4f-6e5d-4d99-ddf8-423e891b6841"
=======
          "height": 326
        },
        "id": "AN9RZye6pzx6",
        "outputId": "f75afad7-2130-4ecf-bde8-efbe229cc464"
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
      },
      "source": [
        "print('[CLS] token :', transformer_tokenizer.cls_token)\n",
        "print('[SEP] token :', transformer_tokenizer.sep_token)\n",
        "print('[PAD] token :', transformer_tokenizer.pad_token)\n",
        "databunch.show_batch()"
      ],
<<<<<<< HEAD
      "execution_count": 82,
=======
      "execution_count": 19,
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
      "outputs": [
        {
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "[CLS] token : [CLS]\n",
            "[SEP] token : [SEP]\n",
            "[PAD] token : [PAD]\n"
=======
            "[CLS] token : <s>\n",
            "[SEP] token : </s>\n",
            "[PAD] token : <pad>\n"
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
<<<<<<< HEAD
              "      <td>[CLS] yes ##ss , flash is being shitty tonight ! it . . . . . . . . . takes . . . . . . . . . . . . . . . . . time . . . . . . . . . . . to . . . . . . . . . open . . . . . . . . .</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[CLS] hey ##y . th ##nx ##x . or . inviting . me . to . ur . party . rob . ill . be . down . there . on . june . 24th . ill . miss . u . when . u . go . to . italy . . . . &amp; lt ; 333 ##33 ##33 ##33 tx ##t . me . hon ! !</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[CLS] gr ##rr ##r ! ! ! it ' s back ! ! ! ! ! and what i mean is my headache but on the * * bright side . . . . it ' s only on one side ! ! ! ! / \\ / \\ / \\ / \\ / \\ [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[CLS] what ! ? ! ? ! i can ' t believe i had to find out this way . . . don ' t you pp ##l contact family first ? ? ! ! ? i ' m so sad ! who was it ? ! ? 1 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[CLS] &amp; quo ##t ; ic ##ant live , i can ##t live ! ! ! &amp; quo ##t ; l ##ma ##o . oh and bt ##w - o ##oo ##ow ##w ##wc ##h my foot hurry with that plaster , im going to bleed to death [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]</td>\n",
=======
              "      <td>&lt;s&gt; Ä yes Ä indeed Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä  Ä </td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>&lt;s&gt; Ä S is ... I Ä dont Ä think Ä I Ä will Ä be Ä up Ä 4 Ä 2 n ite Ä sadly Ä  Ä Im Ä in Ä alot Ä of Ä pain Ä 2 day Ä &amp; amp ; Ä had Ä bad Ä n ite ... can Ä we Ä go Ä out Ä an oth a Ä week Ä soon ? xx &lt;/s&gt;</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>&lt;s&gt; Ä On Ä the Ä way Ä back Ä to Ä dub lin Ä O mg Ä didnt Ä hit Ä the Ä bed Ä until Ä 530 Ä  Ä so Ä i Ä am Ä so Ä sleepy Ä  Ä  Ä but Ä once Ä again Ä on Ä the Ä road Ä back Ä to Ä good Ä o le Ä  Ä dub lin Ä : - p Ä ... &lt;/s&gt;</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>&lt;s&gt; Ä just Ä saw Ä an Ä advert Ä for Ä ATT ICS Ä TO Ä ED EN Ä on Ä tv Ä  Ä out Ä today Ä and Ä only Ä 9 . 99 Ä from Ä HM V ... so Ä I 'm Ä not Ä sure Ä why Ä I Ä had Ä to Ä pay Ä 13 Ä at Ä HM V ... never Ä mind &lt;/s&gt;</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>&lt;s&gt; Ä O Ä dear . Ä so Ä you 're Ä going Ä to Ä be Ä fucking Ä that Ä k idd oe Ä and Ä I 'm Ä going Ä to Ä sit Ä there Ä doing .. Ä  Ä nothing ! Ä awesome Ä  Ä WH ER ES Ä THE Ä SH OP P ING ?! &amp; lt ; 3 &lt;/s&gt;</td>\n",
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYwqTrtAqDMJ"
      },
      "source": [
        "Check batch and numericalizer :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgJsyx-aqFC5",
<<<<<<< HEAD
        "outputId": "e0fb19d6-7628-44e9-8359-c36444e8a9ac"
=======
        "outputId": "0e798592-4b9f-49de-ede5-46badde897e6"
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
      },
      "source": [
        "print('[CLS] id :', transformer_tokenizer.cls_token_id)\n",
        "print('[SEP] id :', transformer_tokenizer.sep_token_id)\n",
        "print('[PAD] id :', pad_idx)\n",
        "test_one_batch = databunch.one_batch()[0]\n",
        "print('Batch shape : ',test_one_batch.shape)\n",
        "print(test_one_batch)"
      ],
<<<<<<< HEAD
      "execution_count": 83,
=======
      "execution_count": 20,
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
      "outputs": [
        {
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "[CLS] id : 101\n",
            "[SEP] id : 102\n",
            "[PAD] id : 0\n",
            "Batch shape :  torch.Size([16, 92])\n",
            "tensor([[ 101, 2748, 4757,  ..., 1012, 1012,  102],\n",
            "        [ 101, 4931, 8183,  ...,    0,    0,    0],\n",
            "        [ 101, 2651, 1010,  ...,    0,    0,    0],\n",
            "        ...,\n",
            "        [ 101, 2031, 2000,  ...,    0,    0,    0],\n",
            "        [ 101, 2288, 2026,  ...,    0,    0,    0],\n",
            "        [ 101, 1045, 2089,  ...,    0,    0,    0]])\n"
=======
            "[CLS] id : 0\n",
            "[SEP] id : 2\n",
            "[PAD] id : 1\n",
            "Batch shape :  torch.Size([16, 102])\n",
            "tensor([[    0,  4420,  5329,  ...,   524,   456,     2],\n",
            "        [    0, 27557,  6015,  ...,     1,     1,     1],\n",
            "        [    0,   313,   939,  ...,     1,     1,     1],\n",
            "        ...,\n",
            "        [    0,   939,   348,  ...,     1,     1,     1],\n",
            "        [    0,  1381,  5963,  ...,     1,     1,     1],\n",
            "        [    0,    38,   784,  ...,     1,     1,     1]])\n"
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfvFEx98qHmi"
      },
      "source": [
        "### Custom model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqjm9zsNqQHG"
      },
      "source": [
        "# defining our model architecture \n",
        "class CustomTransformerModel(nn.Module):\n",
        "    def __init__(self, transformer_model: PreTrainedModel):\n",
        "        super(CustomTransformerModel,self).__init__()\n",
        "        self.transformer = transformer_model\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        \n",
        "        # attention_mask\n",
        "        # Mask to avoid performing attention on padding token indices.\n",
        "        # Mask values selected in ``[0, 1]``:\n",
        "        # ``1`` for tokens that are NOT MASKED, ``0`` for MASKED tokens.\n",
        "        attention_mask = (input_ids!=pad_idx).type(input_ids.type()) \n",
        "        \n",
        "        logits = self.transformer(input_ids,\n",
        "                                  attention_mask = attention_mask)[0]   \n",
        "        return logits"
      ],
<<<<<<< HEAD
      "execution_count": 84,
=======
      "execution_count": 21,
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
<<<<<<< HEAD
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BrsXeRyrfEb",
        "outputId": "9f68479f-0633-4e15-9379-45b5e2962c9f"
=======
          "base_uri": "https://localhost:8080/",
          "height": 899,
          "referenced_widgets": [
            "d825bba4a3724c80afd25f3a2d140c7a",
            "4426d80d3c964d5c9e0613c0f12a6135",
            "1873f6b1aa544e13b2bca4a256fbb425",
            "c3185dca06f8474abca1115d7b261c76",
            "26945c064dc34ed99893fa3404dc3af5",
            "59ab3115bb354caf892497a73c4d37fc",
            "4afa9fe458d74aa0a51e2a8d6e0ae5ec",
            "41ac469186d0440baf517a6bf4a58a7a"
          ]
        },
        "id": "7BrsXeRyrfEb",
        "outputId": "5c1958d4-66c4-4cb0-84e6-1b2930b11676"
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
      },
      "source": [
        "config = config_class.from_pretrained(pretrained_model_name)\n",
        "config.num_labels = len(basic_tweet.sentiment.unique())\n",
        "config.use_bfloat16 = use_fp16\n",
        "print(config)"
      ],
<<<<<<< HEAD
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": null,\n",
            "  \"do_sample\": false,\n",
=======
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d825bba4a3724c80afd25f3a2d140c7a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"do_sample\": false,\n",
            "  \"eos_token_id\": 2,\n",
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
            "  \"eos_token_ids\": null,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
<<<<<<< HEAD
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
=======
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 3,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
<<<<<<< HEAD
            "  \"pad_token_id\": 0,\n",
=======
            "  \"pad_token_id\": 1,\n",
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
<<<<<<< HEAD
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
=======
            "  \"type_vocab_size\": 1,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 50265\n",
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
            "}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
<<<<<<< HEAD
        "id": "fJ4CJs9trpFm"
=======
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "cce0a1ae13a94c6f8a0dedb636a30d23",
            "3876d4b1586f434e96b4dfc46e56edfa",
            "b8a66352e78847aa999dff6e804ca933",
            "42c6d4e981624d9787d46983dee3aa1a",
            "1a7db21b58ef45e0a8efa0d6396ff5da",
            "2c4186c995d64a70900ae1d5dfd236ac",
            "f0b6447c14c747fcb13ff96f9a69b10c",
            "ed23ad8506bc4f36861928859ba8df7f"
          ]
        },
        "id": "fJ4CJs9trpFm",
        "outputId": "58c82172-0a6b-4eef-abda-2bf22ca86516"
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
      },
      "source": [
        "transformer_model = model_class.from_pretrained(pretrained_model_name, config = config)\n",
        "custom_transformer_model = CustomTransformerModel(transformer_model = transformer_model)"
      ],
<<<<<<< HEAD
      "execution_count": 86,
      "outputs": []
=======
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cce0a1ae13a94c6f8a0dedb636a30d23",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=501200538.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27A9Qcb7sEAE"
      },
      "source": [
        "## Learner : Custom Optimizer / Custom Metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
<<<<<<< HEAD
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "De-IaWC5sFIC",
        "outputId": "46bbb7c7-a600-4ddb-cd12-4a05c7de0e2b"
=======
        "id": "De-IaWC5sFIC"
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
      },
      "source": [
        "from transformers import AdamW\n",
        "from functools import partial\n",
        "\n",
        "CustomAdamW = partial(AdamW, correct_bias=False)\n",
        "\n",
        "learner = Learner(databunch, \n",
        "                  custom_transformer_model, \n",
        "                  opt_func = CustomAdamW, \n",
        "                  metrics=[accuracy, error_rate])#.to_fp16()\n",
        "\n",
        "# Show graph of learner stats and metrics after each epoch.\n",
        "learner.callbacks.append(ShowGraph(learner))\n",
        "\n",
        "if use_fp16: learner = learner.to_fp16()"
      ],
<<<<<<< HEAD
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-c9bbb6568605>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                   \u001b[0mcustom_transformer_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                   \u001b[0mopt_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomAdamW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                   metrics=[accuracy, error_rate])#.to_fp16()\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Show graph of learner stats and metrics after each epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, model, opt_func, loss_func, metrics, true_wd, bn_wd, wd, train_bn, path, model_dir, callback_fns, callbacks, layer_groups, add_time, silent)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36m__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;34m\"Setup path,metrics, callbacks and ensure model directory exists.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mifnone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     def register_backward_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    669\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    670\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 671\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 90.00 MiB (GPU 0; 11.17 GiB total capacity; 10.68 GiB already allocated; 12.81 MiB free; 10.73 GiB reserved in total by PyTorch)"
          ]
        }
      ]
=======
      "execution_count": 24,
      "outputs": []
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgLjlP-3t6ct",
<<<<<<< HEAD
        "outputId": "38d27116-ba27-42a9-c563-0f36bb8c2a0e"
=======
        "outputId": "20d4ea28-276f-4215-b2f1-8367c8632940"
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
      },
      "source": [
        "print(learner.model)"
      ],
<<<<<<< HEAD
      "execution_count": 23,
=======
      "execution_count": 24,
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CustomTransformerModel(\n",
<<<<<<< HEAD
            "  (transformer): BertForSequenceClassification(\n",
            "    (bert): BertModel(\n",
            "      (embeddings): BertEmbeddings(\n",
            "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "        (position_embeddings): Embedding(512, 768)\n",
            "        (token_type_embeddings): Embedding(2, 768)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
=======
            "  (transformer): RobertaForSequenceClassification(\n",
            "    (roberta): RobertaModel(\n",
            "      (embeddings): RobertaEmbeddings(\n",
            "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
            "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
            "        (token_type_embeddings): Embedding(1, 768)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (encoder): BertEncoder(\n",
            "        (layer): ModuleList(\n",
            "          (0): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
<<<<<<< HEAD
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
=======
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
<<<<<<< HEAD
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
=======
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
<<<<<<< HEAD
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
=======
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
<<<<<<< HEAD
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
=======
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
<<<<<<< HEAD
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
=======
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
<<<<<<< HEAD
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
=======
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
<<<<<<< HEAD
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
=======
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
<<<<<<< HEAD
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
=======
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
<<<<<<< HEAD
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
=======
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
<<<<<<< HEAD
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
=======
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
<<<<<<< HEAD
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
=======
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
<<<<<<< HEAD
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
=======
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (6): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
<<<<<<< HEAD
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
=======
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
<<<<<<< HEAD
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
=======
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (7): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
<<<<<<< HEAD
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
=======
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
<<<<<<< HEAD
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
=======
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (8): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
<<<<<<< HEAD
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
=======
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
<<<<<<< HEAD
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
=======
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (9): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
<<<<<<< HEAD
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
=======
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
<<<<<<< HEAD
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
=======
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (10): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
<<<<<<< HEAD
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
=======
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
<<<<<<< HEAD
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
=======
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (11): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
<<<<<<< HEAD
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
=======
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
<<<<<<< HEAD
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
=======
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): BertPooler(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
<<<<<<< HEAD
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
=======
            "    (classifier): RobertaClassificationHead(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
            "    )\n",
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
<<<<<<< HEAD
        "id": "sDGaKcUtsiAU"
      },
      "source": [
        "# list_layers = [learner.model.transformer.roberta.embeddings,\n",
        "#               learner.model.transformer.roberta.encoder.layer[0],\n",
        "#               learner.model.transformer.roberta.encoder.layer[1],\n",
        "#               learner.model.transformer.roberta.encoder.layer[2],\n",
        "#               learner.model.transformer.roberta.encoder.layer[3],\n",
        "#               learner.model.transformer.roberta.encoder.layer[4],\n",
        "#               learner.model.transformer.roberta.encoder.layer[5],\n",
        "#               learner.model.transformer.roberta.encoder.layer[6],\n",
        "#               learner.model.transformer.roberta.encoder.layer[7],\n",
        "#               learner.model.transformer.roberta.encoder.layer[8],\n",
        "#               learner.model.transformer.roberta.encoder.layer[9],\n",
        "#               learner.model.transformer.roberta.encoder.layer[10],\n",
        "#               learner.model.transformer.roberta.encoder.layer[11],\n",
        "#               learner.model.transformer.roberta.pooler]\n",
        "# learner.split(list_layers)\n",
        "learner.freeze_to(-1)\n",
        "# learner.summary()"
      ],
      "execution_count": 24,
      "outputs": []
=======
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sDGaKcUtsiAU",
        "outputId": "98b1d728-8be2-46a5-d9a9-251283d8b4b1"
      },
      "source": [
        "learner.freeze_to(-1)\n",
        "learner.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "CustomTransformerModel\n",
              "======================================================================\n",
              "Layer (type)         Output Shape         Param #    Trainable \n",
              "======================================================================\n",
              "Embedding            [102, 768]           38,603,520 True      \n",
              "______________________________________________________________________\n",
              "Embedding            [102, 768]           394,752    True      \n",
              "______________________________________________________________________\n",
              "Embedding            [102, 768]           768        True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [102, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [102, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 102, 102]       0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [102, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [102, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [102, 3072]          2,362,368  True      \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           2,360,064  True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [102, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [102, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 102, 102]       0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [102, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [102, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [102, 3072]          2,362,368  True      \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           2,360,064  True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [102, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [102, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 102, 102]       0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [102, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [102, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [102, 3072]          2,362,368  True      \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           2,360,064  True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [102, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [102, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 102, 102]       0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [102, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [102, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [102, 3072]          2,362,368  True      \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           2,360,064  True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [102, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [102, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 102, 102]       0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [102, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [102, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [102, 3072]          2,362,368  True      \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           2,360,064  True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [102, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [102, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 102, 102]       0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [102, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [102, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [102, 3072]          2,362,368  True      \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           2,360,064  True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [102, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [102, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 102, 102]       0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [102, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [102, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [102, 3072]          2,362,368  True      \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           2,360,064  True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [102, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [102, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 102, 102]       0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [102, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [102, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [102, 3072]          2,362,368  True      \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           2,360,064  True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [102, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [102, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 102, 102]       0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [102, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [102, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [102, 3072]          2,362,368  True      \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           2,360,064  True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [102, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [102, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 102, 102]       0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [102, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [102, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [102, 3072]          2,362,368  True      \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           2,360,064  True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [102, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [102, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 102, 102]       0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [102, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [102, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [102, 3072]          2,362,368  True      \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           2,360,064  True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [102, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [102, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "Dropout              [12, 102, 102]       0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           590,592    True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [102, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [102, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [102, 3072]          2,362,368  True      \n",
              "______________________________________________________________________\n",
              "Linear               [102, 768]           2,360,064  True      \n",
              "______________________________________________________________________\n",
              "LayerNorm            [102, 768]           1,536      True      \n",
              "______________________________________________________________________\n",
              "Dropout              [102, 768]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [768]                590,592    True      \n",
              "______________________________________________________________________\n",
              "Tanh                 [768]                0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [768]                590,592    True      \n",
              "______________________________________________________________________\n",
              "Dropout              [768]                0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [3]                  2,307      True      \n",
              "______________________________________________________________________\n",
              "\n",
              "Total params: 125,238,531\n",
              "Total trainable params: 125,238,531\n",
              "Total non-trainable params: 0\n",
              "Optimized with 'transformers.optimization.AdamW', correct_bias=False\n",
              "Using true weight decay as discussed in https://www.fast.ai/2018/07/02/adam-weight-decay/ \n",
              "Loss function : FlattenedLoss\n",
              "======================================================================\n",
              "Callbacks functions applied \n",
              "    ShowGraph"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
<<<<<<< HEAD
          "height": 490
        },
        "id": "rHjymr62xMX9",
        "outputId": "93e99d6b-ee58-4cfc-db44-13c4028027eb"
=======
          "height": 479
        },
        "id": "rHjymr62xMX9",
        "outputId": "79f69750-6452-42b8-ccc6-077735a28091"
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
      },
      "source": [
        "learner.lr_find()\n",
        "learner.recorder.plot(skip_end=10,suggestion=True)"
      ],
<<<<<<< HEAD
      "execution_count": 25,
=======
      "execution_count": 27,
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
<<<<<<< HEAD
              "      <progress value='0' class='' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/2 00:00<00:00]\n",
=======
              "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/1 00:00<00:00]\n",
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
<<<<<<< HEAD
              "      <progress value='0' class='' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/59 00:00<00:00]\n",
=======
              "      <progress value='73' class='' max='1207' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      6.05% [73/1207 00:09<02:24 3.8924]\n",
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
=======
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n",
            "Min numerical gradient: 6.31E-07\n",
            "Min loss divided by 10: 2.51E-06\n"
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
          ],
          "name": "stdout"
        },
        {
<<<<<<< HEAD
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-73c1c08a70e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskip_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msuggestion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/train.py\u001b[0m in \u001b[0;36mlr_find\u001b[0;34m(learn, start_lr, end_lr, num_it, stop_div, wd)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLRFinder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_it\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m def to_fp16(learn:Learner, loss_scale:float=None, max_noskip:int=1000, dynamic:bool=True, clip:float=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_loss_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-3e632fdbef91>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         logits = self.transformer(input_ids,\n\u001b[0;32m---> 16\u001b[0;31m                                   attention_mask = attention_mask)[0]   \n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels)\u001b[0m\n\u001b[1;32m   1174\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m         )\n\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_extended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m         )\n\u001b[1;32m    792\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             layer_outputs = layer_module(\n\u001b[0;32m--> 407\u001b[0;31m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m             )\n\u001b[1;32m    409\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     ):\n\u001b[0;32m--> 368\u001b[0;31m         \u001b[0mself_attention_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add self attentions if we output attention weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    312\u001b[0m     ):\n\u001b[1;32m    313\u001b[0m         self_outputs = self.self(\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m         )\n\u001b[1;32m    316\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;31m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_head_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
=======
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
<<<<<<< HEAD
          "height": 166
        },
        "id": "hneR7OxyvkF4",
        "outputId": "d9d08948-c64a-4fe1-905b-4887e442bb20"
      },
      "source": [
        "# learner.unfreeze()\n",
        "learner.fit_one_cycle(1,max_lr=1e-04)"
      ],
      "execution_count": null,
=======
          "height": 645
        },
        "id": "hneR7OxyvkF4",
        "outputId": "e52095d5-3372-40b7-d154-8977b862e010"
      },
      "source": [
        "learner.unfreeze()\n",
        "learner.fit_one_cycle(4,max_lr=2e-04,moms=(0.8,0.7))"
      ],
      "execution_count": 28,
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
<<<<<<< HEAD
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/1 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
=======
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
<<<<<<< HEAD
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/59 00:00<00:00]\n",
              "    </div>\n",
              "    "
=======
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.114545</td>\n",
              "      <td>1.090370</td>\n",
              "      <td>0.330228</td>\n",
              "      <td>0.669772</td>\n",
              "      <td>02:17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.114235</td>\n",
              "      <td>1.088283</td>\n",
              "      <td>0.402422</td>\n",
              "      <td>0.597578</td>\n",
              "      <td>02:16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.104049</td>\n",
              "      <td>1.087056</td>\n",
              "      <td>0.402422</td>\n",
              "      <td>0.597578</td>\n",
              "      <td>02:25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.099210</td>\n",
              "      <td>1.086139</td>\n",
              "      <td>0.402422</td>\n",
              "      <td>0.597578</td>\n",
              "      <td>02:27</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
<<<<<<< HEAD
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4IYA8neuOCY"
      },
      "source": [
        "learner.predict('I am so scared')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caabPLglulcf"
      },
      "source": [
        "learner.export(file = 'transformer.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1RME5b1vZl7"
      },
      "source": [
        "def get_preds_as_nparray(ds_type) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    the get_preds method does not yield the elements in order by default\n",
        "    we borrow the code from the RNNLearner to resort the elements into their correct order\n",
        "    \"\"\"\n",
        "    preds = learner.get_preds(ds_type)[0].detach().cpu().numpy()\n",
        "    sampler = [i for i in databunch.dl(ds_type).sampler]\n",
        "    reverse_sampler = np.argsort(sampler)\n",
        "    return preds[reverse_sampler, :]\n",
        "\n",
        "test_preds = get_preds_as_nparray(DatasetType.Test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acj-mVI2v0wy"
      },
      "source": [
        "test_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHSo49vDv7Kq"
      },
      "source": [
        "test['prediction'] = np.argmax(test_preds,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqARHfvkv38S"
      },
      "source": [
        "test.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BVaABHoxNZg"
      },
      "source": [
        "np.argmax(test_preds,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
=======
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
>>>>>>> 7cb0694dd605626a970d6e43153e8f08afce378f
    }
  ]
}