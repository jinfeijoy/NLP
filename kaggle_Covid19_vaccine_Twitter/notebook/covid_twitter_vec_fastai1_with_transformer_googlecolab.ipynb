{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "covid_twitter_vec_fastai1_with_transformer_googlecolab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6ab810352d4d4ba6a81ff7619551a45d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fcfde2db12a647c78a3650f4ab535998",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_62d74e5b9b8146b3a75988a8870f5214",
              "IPY_MODEL_08b911150c24466b98b507c9200b3488"
            ]
          }
        },
        "fcfde2db12a647c78a3650f4ab535998": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "62d74e5b9b8146b3a75988a8870f5214": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2840f2b815904daca2d56abf1399b9aa",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 267967963,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 267967963,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eb721d98fcd74cec8f33845aca2478c9"
          }
        },
        "08b911150c24466b98b507c9200b3488": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fbe4cdba0da44a2ab032f9fddf2c1083",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 268M/268M [00:29&lt;00:00, 9.23MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_67efff9a7fa74cfc9d007e2dbe8b4cc5"
          }
        },
        "2840f2b815904daca2d56abf1399b9aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eb721d98fcd74cec8f33845aca2478c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fbe4cdba0da44a2ab032f9fddf2c1083": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "67efff9a7fa74cfc9d007e2dbe8b4cc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jinfeijoy/NLP/blob/main/kaggle_IMDB_Review/notebook/IMDB_fastai1_with_transformer_googlecolab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Zm4Mzx2heBJ",
        "outputId": "37386c66-09ad-477d-b36b-94e45011c821"
      },
      "source": [
        "#Please select GPU first (from Edit->NotebookSetting)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "import os\n",
        "import re\n",
        "from google.colab import drive\n",
        "!pip install fastai==1.0.58\n",
        "# !pip install urllib3==1.25.4\n",
        "!pip install transformers==2.5.1\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "import transformers\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import random \n",
        "from fastai import *\n",
        "from fastai.text import *\n",
        "from fastai.callbacks import *"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fastai==1.0.58\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/88/386289f6926a59cbd2765b033f5fe8414d6ff89ab27044dffe740cc1a5f3/fastai-1.0.58-py3-none-any.whl (236kB)\n",
            "\r\u001b[K     |█▍                              | 10kB 20.3MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 19.0MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30kB 15.5MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40kB 14.2MB/s eta 0:00:01\r\u001b[K     |███████                         | 51kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 61kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 71kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 92kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 102kB 7.3MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 112kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 122kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 133kB 7.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 143kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 153kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 163kB 7.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 174kB 7.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 184kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 194kB 7.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 204kB 7.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 215kB 7.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 225kB 7.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 235kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 7.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (2.7.3)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (1.8.1+cu101)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (3.13)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (3.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (1.4.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (4.6.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (7.1.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (1.1.5)\n",
            "Requirement already satisfied: fastprogress>=0.1.19 in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (1.0.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (0.9.1+cu101)\n",
            "Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (7.352.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (1.19.5)\n",
            "Requirement already satisfied: spacy>=2.0.18 in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (2.2.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (20.9)\n",
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (1.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.58) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->fastai==1.0.58) (3.7.4.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai==1.0.58) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai==1.0.58) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai==1.0.58) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai==1.0.58) (0.10.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai==1.0.58) (2018.9)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (3.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (0.8.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (2.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (1.1.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (4.41.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.58) (57.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==1.0.58) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==1.0.58) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==1.0.58) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==1.0.58) (2.10)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->fastai==1.0.58) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.0.18->fastai==1.0.58) (4.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.0.18->fastai==1.0.58) (3.4.1)\n",
            "Installing collected packages: fastai\n",
            "  Found existing installation: fastai 1.0.61\n",
            "    Uninstalling fastai-1.0.61:\n",
            "      Successfully uninstalled fastai-1.0.61\n",
            "Successfully installed fastai-1.0.58\n",
            "Collecting transformers==2.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/33/ffb67897a6985a7b7d8e5e7878c3628678f553634bd3836404fef06ef19b/transformers-2.5.1-py3-none-any.whl (499kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 7.4MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/e3/5e49e9a83fb605aaa34a1c1173e607302fecae529428c28696fb18f1c2c9/tokenizers-0.5.2-cp37-cp37m-manylinux1_x86_64.whl (5.6MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6MB 29.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (1.19.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 47.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (3.0.12)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 45.1MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/77/cc19511d0fe4672890209ebcbfb9b3f4746572f5a48f7ed2654e7f8c2f29/boto3-1.17.89-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 56.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.1) (2020.12.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.5.1) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.5.1) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.5.1) (7.1.2)\n",
            "Collecting botocore<1.21.0,>=1.20.89\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/20/e6e16f588036b387d4f4f8e2e780a520e2b3925ba1529fdfc97ad909fb6c/botocore-1.20.89-py2.py3-none-any.whl (7.6MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6MB 36.7MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting s3transfer<0.5.0,>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/d0/693477c688348654ddc21dcdce0817653a294aa43f41771084c25e7ff9c7/s3transfer-0.4.2-py2.py3-none-any.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 12.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.89->boto3->transformers==2.5.1) (2.8.1)\n",
            "\u001b[31mERROR: botocore 1.20.89 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, jmespath, botocore, s3transfer, boto3, transformers\n",
            "Successfully installed boto3-1.17.89 botocore-1.20.89 jmespath-0.10.0 s3transfer-0.4.2 sacremoses-0.0.45 sentencepiece-0.1.95 tokenizers-0.5.2 transformers-2.5.1\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnpFT7WmFswE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "000Lxer88C6x"
      },
      "source": [
        "# Load Data\n",
        "Reference: https://www.kaggle.com/maroberti/fastai-with-transformers-bert-roberta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AB5kSJ-qh9JV"
      },
      "source": [
        "path = '/content/drive/MyDrive/colab_data'\n",
        "def de_emojify(inputString):\n",
        "    return inputString.encode('ascii', 'ignore').decode('ascii')\n",
        "def tweet_proc(df, text_col='text'):\n",
        "    df['orig_text'] = df[text_col]\n",
        "    # Remove twitter handles\n",
        "    df[text_col] = df[text_col].apply(lambda x:re.sub('@[^\\s]+','',x))\n",
        "    # Remove URLs\n",
        "    df[text_col] = df[text_col].apply(lambda x:re.sub(r\"http\\S+\", \"\", x))\n",
        "    # Remove emojis\n",
        "    df[text_col] = df[text_col].apply(de_emojify)\n",
        "    # Remove hashtags\n",
        "    df[text_col] = df[text_col].apply(lambda x:re.sub(r'\\B#\\S+','',x))\n",
        "    return df[df[text_col]!='']\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioXaMandf4G2",
        "outputId": "cfc0cd28-fe17-4bb4-8517-2225b1ed8832"
      },
      "source": [
        "basic_tweet.new_sentiment.value_counts()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "neutral     12251\n",
              "positive     9804\n",
              "negative     8628\n",
              "Name: new_sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "Eif24MQRQANx",
        "outputId": "890562da-9289-47ec-da35-e1307b995861"
      },
      "source": [
        "basic_tweet = pd.read_csv(os.path.join(path, \"tweet_dataset.csv\"))\n",
        "basic_tweet = covid_tweet[(covid_tweet.text.isnull()==False) & (covid_tweet.sentiment != 'empty')].drop_duplicates().reset_index(drop=True)\n",
        "basic_tweet = tweet_proc(covid_tweet,'text').dropna(subset=['new_sentiment']).dropna(subset=['sentiment']).dropna(subset=['text'])\n",
        "basic_tweet['label'] = np.where(basic_tweet.new_sentiment=='negative',-1,(np.where(basic_tweet.new_sentiment=='positive',1,0)))\n",
        "print(len(basic_tweet))\n",
        "basic_tweet.head(3)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30683\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>author</th>\n",
              "      <th>text</th>\n",
              "      <th>old_text</th>\n",
              "      <th>aux_id</th>\n",
              "      <th>new_sentiment</th>\n",
              "      <th>selected_text</th>\n",
              "      <th>orig_text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1956967666</td>\n",
              "      <td>sadness</td>\n",
              "      <td>wannamama</td>\n",
              "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
              "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
              "      <td>c811396dc2</td>\n",
              "      <td>negative</td>\n",
              "      <td>headache</td>\n",
              "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1956967696</td>\n",
              "      <td>sadness</td>\n",
              "      <td>coolfunky</td>\n",
              "      <td>Funeral ceremony...gloomy friday...</td>\n",
              "      <td>Funeral ceremony...gloomy friday...</td>\n",
              "      <td>9063631ab1</td>\n",
              "      <td>negative</td>\n",
              "      <td>gloomy</td>\n",
              "      <td>Funeral ceremony...gloomy friday...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1956967789</td>\n",
              "      <td>enthusiasm</td>\n",
              "      <td>czareaquino</td>\n",
              "      <td>wants to hang out with friends SOON!</td>\n",
              "      <td>wants to hang out with friends SOON!</td>\n",
              "      <td>2a815f151d</td>\n",
              "      <td>positive</td>\n",
              "      <td>wants to hang out with friends SOON!</td>\n",
              "      <td>wants to hang out with friends SOON!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       textID  ... label\n",
              "0  1956967666  ...    -1\n",
              "1  1956967696  ...    -1\n",
              "2  1956967789  ...     1\n",
              "\n",
              "[3 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7R_Io_SR9yjD"
      },
      "source": [
        "# Main transformers classes\n",
        "* A **model class** to load/store a particular pre-train model.\n",
        "* A **tokenizer class** to pre-process the data and make it compatible with a particular model.\n",
        "* A **configuration class** to load/store the configuration of a particular model.\n",
        "\n",
        "Pre-trained model name can be found here: https://huggingface.co/transformers/pretrained_models.html#pretrained-models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IosPm09PBT53"
      },
      "source": [
        "from transformers import PreTrainedModel, PreTrainedTokenizer, PretrainedConfig\n",
        "from transformers import BertForSequenceClassification, BertTokenizer, BertConfig\n",
        "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig\n",
        "from transformers import XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig\n",
        "from transformers import XLMForSequenceClassification, XLMTokenizer, XLMConfig\n",
        "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5gG7whd94Ez"
      },
      "source": [
        "MODEL_CLASSES = {\n",
        "    'bert': (BertForSequenceClassification, BertTokenizer, BertConfig),\n",
        "    'xlnet': (XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig),\n",
        "    'xlm': (XLMForSequenceClassification, XLMTokenizer, XLMConfig),\n",
        "    'roberta': (RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig),\n",
        "    'distilbert': (DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig)\n",
        "}"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CebDd2j7-xLR"
      },
      "source": [
        "seed = 42\n",
        "use_fp16 = False\n",
        "bs = 16\n",
        "\n",
        "# model_type = 'roberta'\n",
        "# pretrained_model_name = 'roberta-base'\n",
        "\n",
        "# model_type = 'bert'\n",
        "# pretrained_model_name='bert-base-uncased'\n",
        "\n",
        "model_type = 'distilbert'\n",
        "pretrained_model_name = 'distilbert-base-uncased'\n",
        "\n",
        "#model_type = 'xlm'\n",
        "#pretrained_model_name = 'xlm-clm-enfr-1024'\n",
        "\n",
        "# model_type = 'xlnet'\n",
        "# pretrained_model_name = 'xlnet-base-cased'"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a3TKgiIAIEx"
      },
      "source": [
        "model_class, tokenizer_class, config_class = MODEL_CLASSES[model_type]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7EoC-U5BjEA"
      },
      "source": [
        "# Function to set the seed for generating random numbers\n",
        "def seed_all(seed_value):\n",
        "    random.seed(seed_value) # Python\n",
        "    np.random.seed(seed_value) # cpu vars\n",
        "    torch.manual_seed(seed_value) # cpu  vars\n",
        "    \n",
        "    if torch.cuda.is_available(): \n",
        "        torch.cuda.manual_seed(seed_value)\n",
        "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
        "        torch.backends.cudnn.deterministic = True  #needed\n",
        "        torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HA0nSgbXBzdT"
      },
      "source": [
        "seed_all(seed)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liNQGmNbCg22"
      },
      "source": [
        "# Data Pre-processing\n",
        "\n",
        "### Custom Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DboUvy0hB2Fx"
      },
      "source": [
        "class TransformersBaseTokenizer(BaseTokenizer):\n",
        "    \"\"\"Wrapper around PreTrainedTokenizer to be compatible with fast.ai\"\"\"\n",
        "    def __init__(self, pretrained_tokenizer: PreTrainedTokenizer, model_type = 'bert', **kwargs):\n",
        "        self._pretrained_tokenizer = pretrained_tokenizer\n",
        "        # self.max_seq_len = int(np.percentile(pretrained_tokenizer.max_len, 95))\n",
        "        self.max_seq_len = pretrained_tokenizer.max_len\n",
        "        self.model_type = model_type\n",
        "\n",
        "    def __call__(self, *args, **kwargs): \n",
        "        return self\n",
        "\n",
        "    def tokenizer(self, t:str) -> List[str]:\n",
        "        \"\"\"Limits the maximum sequence length and add the spesial tokens\"\"\"\n",
        "        CLS = self._pretrained_tokenizer.cls_token\n",
        "        SEP = self._pretrained_tokenizer.sep_token\n",
        "        if self.model_type in ['roberta']:\n",
        "            tokens = self._pretrained_tokenizer.tokenize(t, add_prefix_space=True)[:self.max_seq_len - 2]\n",
        "            tokens = [CLS] + tokens + [SEP]\n",
        "        else:\n",
        "            tokens = self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2]\n",
        "            if self.model_type in ['xlnet']:\n",
        "                tokens = tokens + [SEP] +  [CLS]\n",
        "            else:\n",
        "                tokens = [CLS] + tokens + [SEP]\n",
        "        return tokens"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ort7lHvgFik4"
      },
      "source": [
        "transformer_tokenizer = tokenizer_class.from_pretrained(pretrained_model_name)\n",
        "transformer_base_tokenizer = TransformersBaseTokenizer(pretrained_tokenizer = transformer_tokenizer, model_type = model_type)\n",
        "fastai_tokenizer = Tokenizer(tok_func = transformer_base_tokenizer, pre_rules=[], post_rules=[])"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2Nxo5SCJgwb"
      },
      "source": [
        "In this implementation, be carefull about 3 things :\n",
        "\n",
        "1. As we are not using RNN, we have to limit the sequence length to the model input size.\n",
        "2. Most of the models require special tokens placed at the beginning and end of the sequences.\n",
        "3. Some models like RoBERTa require a space to start the input string. For those models, the encoding methods should be called with `add_prefix_space` set to `True`.\n",
        "\n",
        "Below, you can find the resume of each pre-process requirement for the 5 model types used in this tutorial. You can also find this information on the HuggingFace documentation in each model section.\n",
        "\n",
        "`bert:       [CLS] + tokens + [SEP] + padding`\n",
        "\n",
        "`roberta:    [CLS] + prefix_space + tokens + [SEP] + padding`\n",
        "\n",
        "`distilbert: [CLS] + tokens + [SEP] + padding`\n",
        "\n",
        "`xlm:        [CLS] + tokens + [SEP] + padding`\n",
        "\n",
        "`xlnet:      padding + tokens + [SEP] + [CLS]`\n",
        "\n",
        "### Custom Numericalizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eB7VJoNoJ7HF"
      },
      "source": [
        "class TransformersVocab(Vocab):\n",
        "    def __init__(self, tokenizer: PreTrainedTokenizer):\n",
        "        super(TransformersVocab, self).__init__(itos = [])\n",
        "        self.tokenizer = tokenizer\n",
        "    \n",
        "    def numericalize(self, t:Collection[str]) -> List[int]:\n",
        "        \"Convert a list of tokens `t` to their ids.\"\n",
        "        return self.tokenizer.convert_tokens_to_ids(t)\n",
        "        #return self.tokenizer.encode(t)\n",
        "\n",
        "    def textify(self, nums:Collection[int], sep=' ') -> List[str]:\n",
        "        \"Convert a list of `nums` to their tokens.\"\n",
        "        nums = np.array(nums).tolist()\n",
        "        return sep.join(self.tokenizer.convert_ids_to_tokens(nums)) if sep is not None else self.tokenizer.convert_ids_to_tokens(nums)\n",
        "    \n",
        "    def __getstate__(self):\n",
        "        return {'itos':self.itos, 'tokenizer':self.tokenizer}\n",
        "\n",
        "    def __setstate__(self, state:dict):\n",
        "        self.itos = state['itos']\n",
        "        self.tokenizer = state['tokenizer']\n",
        "        self.stoi = collections.defaultdict(int,{v:k for k,v in enumerate(self.itos)})"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D__1A1C7ksnM"
      },
      "source": [
        "### Custom processor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7zTXr5Jkuo9"
      },
      "source": [
        "transformer_vocab = TransformersVocab(tokenizer = transformer_tokenizer)\n",
        "numericalize_processor = NumericalizeProcessor(vocab = transformer_vocab)\n",
        "tokenize_processor = TokenizeProcessor(tokenizer=fastai_tokenizer, include_bos = False, include_eos = False)\n",
        "transformer_processor = [tokenize_processor, numericalize_processor]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chjKAN1vl14k"
      },
      "source": [
        "## Setting up the Databunch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-jmHRp4l5Si"
      },
      "source": [
        "pad_first = bool(model_type in ['xlnet'])\n",
        "pad_idx = transformer_tokenizer.pad_token_id"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk54ORSPpgU0"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(basic_tweet, test_size=0.3, random_state=42)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "S_leu-wSlzsu",
        "outputId": "52b39bfd-c2b9-4ade-f638-b3be5e327c8b"
      },
      "source": [
        "databunch = (TextList.from_df(train, cols='text', processor=transformer_processor)\n",
        "             .split_by_rand_pct(0.1,seed=seed)\n",
        "             .label_from_df(cols= 'label')\n",
        "             .add_test(test)\n",
        "             .databunch(bs=bs, pad_first=pad_first, pad_idx=pad_idx))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fastai/core.py:299: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return np.array(a, dtype=dtype, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNZhJ-jlqBRC"
      },
      "source": [
        "Check batch and tokenizer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "AN9RZye6pzx6",
        "outputId": "09a9c507-b129-4b5c-957a-34462d415adc"
      },
      "source": [
        "print('[CLS] token :', transformer_tokenizer.cls_token)\n",
        "print('[SEP] token :', transformer_tokenizer.sep_token)\n",
        "print('[PAD] token :', transformer_tokenizer.pad_token)\n",
        "databunch.show_batch()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] token : [CLS]\n",
            "[SEP] token : [SEP]\n",
            "[PAD] token : [PAD]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>[CLS] within the realm of science fiction , two particular themes consistently eli ##cit interest , were initially explored in the literature of a pre - cinematic era , and have since been periodically revisited by filmmakers and writers alike , with varying degrees of success . the first theme , that of time travel , has held an un ##wave ##ring fascination for fans of film , as well</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[CLS] despite its many faults , hallmark ' s 1995 version of gu ##lli ##ver ' s travels is still the finest adaptation of jonathan swift ' s satirical classic - largely because it not only includes all of gu ##lli ##ver ' s many travels but also includes the satire that ' s often overlooked . unfortunately the twin problems of the book ' s highly ep ##iso ##dic</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[CLS] i first saw this film by chance when i was visiting my uncle in arizona about 3 and 1 / 2 years ago . the vhs print was a little faded looking , but i was very haunted by what i had watched . did it all make sense ? well , honestly , no it didn ' t . however , this is a film that requires more</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[CLS] as a big fan of brian yu ##z ##na and the majority of the movies he ' s been involved in , i guessed i ' d enjoy pro ##geny . i didn ' t , although in ways it has it ' s moments . however , if you ' re expecting something of the cal ##ib ##re of society or beyond re ##ani ##mat ##or , you</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[CLS] this movie was awful , especially considering the work that must have gone into its production . though it ' s not as bad as ax ' em , it is quite awful . take into account the obvious rip - offs from glad ##ia ##tor and raiders of the lost ark , and what do you get ? this sm ##org ##as ##bor ##d of awful make -</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYwqTrtAqDMJ"
      },
      "source": [
        "Check batch and numericalizer :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgJsyx-aqFC5",
        "outputId": "8640f908-881f-4e47-80c7-82bd88a1d6e6"
      },
      "source": [
        "print('[CLS] id :', transformer_tokenizer.cls_token_id)\n",
        "print('[SEP] id :', transformer_tokenizer.sep_token_id)\n",
        "print('[PAD] id :', pad_idx)\n",
        "test_one_batch = databunch.one_batch()[0]\n",
        "print('Batch shape : ',test_one_batch.shape)\n",
        "print(test_one_batch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] id : 101\n",
            "[SEP] id : 102\n",
            "[PAD] id : 0\n",
            "Batch shape :  torch.Size([16, 512])\n",
            "tensor([[  101,  2123,  1005,  ...,  1012,  1999,   102],\n",
            "        [  101,  1996, 10576,  ...,  1996,  3239,   102],\n",
            "        [  101,  2045,  2031,  ..., 12436, 28168,   102],\n",
            "        ...,\n",
            "        [  101,  1008,  1008,  ...,  1997,  2014,   102],\n",
            "        [  101,  1045,  2031,  ...,  1997,  2204,   102],\n",
            "        [  101,  2048, 28466,  ..., 25764, 13954,   102]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfvFEx98qHmi"
      },
      "source": [
        "### Custom model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqjm9zsNqQHG"
      },
      "source": [
        "# defining our model architecture \n",
        "class CustomTransformerModel(nn.Module):\n",
        "    def __init__(self, transformer_model: PreTrainedModel):\n",
        "        super(CustomTransformerModel,self).__init__()\n",
        "        self.transformer = transformer_model\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        \n",
        "        # attention_mask\n",
        "        # Mask to avoid performing attention on padding token indices.\n",
        "        # Mask values selected in ``[0, 1]``:\n",
        "        # ``1`` for tokens that are NOT MASKED, ``0`` for MASKED tokens.\n",
        "        attention_mask = (input_ids!=pad_idx).type(input_ids.type()) \n",
        "        \n",
        "        logits = self.transformer(input_ids,\n",
        "                                  attention_mask = attention_mask)[0]   \n",
        "        return logits"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BrsXeRyrfEb",
        "outputId": "f7ebeef0-f9d9-4cd8-cbf6-2e9d2b26d2b3"
      },
      "source": [
        "config = config_class.from_pretrained(pretrained_model_name)\n",
        "config.num_labels = len(basic_tweet.label.unique())\n",
        "print(len(basic_tweet.label.unique()))\n",
        "config.use_bfloat16 = use_fp16\n",
        "print(config)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "DistilBertConfig {\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"bos_token_id\": null,\n",
            "  \"dim\": 768,\n",
            "  \"do_sample\": false,\n",
            "  \"dropout\": 0.1,\n",
            "  \"eos_token_ids\": null,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_labels\": 3,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"temperature\": 1.0,\n",
            "  \"tie_weights_\": true,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ4CJs9trpFm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "6ab810352d4d4ba6a81ff7619551a45d",
            "fcfde2db12a647c78a3650f4ab535998",
            "62d74e5b9b8146b3a75988a8870f5214",
            "08b911150c24466b98b507c9200b3488",
            "2840f2b815904daca2d56abf1399b9aa",
            "eb721d98fcd74cec8f33845aca2478c9",
            "fbe4cdba0da44a2ab032f9fddf2c1083",
            "67efff9a7fa74cfc9d007e2dbe8b4cc5"
          ]
        },
        "outputId": "192162df-eada-47c0-e526-bd59b4e5abda"
      },
      "source": [
        "transformer_model = model_class.from_pretrained(pretrained_model_name, config = config)\n",
        "custom_transformer_model = CustomTransformerModel(transformer_model = transformer_model)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6ab810352d4d4ba6a81ff7619551a45d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=267967963.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27A9Qcb7sEAE"
      },
      "source": [
        "## Learner : Custom Optimizer / Custom Metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "De-IaWC5sFIC"
      },
      "source": [
        "from transformers import AdamW\n",
        "from functools import partial\n",
        "\n",
        "CustomAdamW = partial(AdamW, correct_bias=False)\n",
        "\n",
        "learner = Learner(databunch, \n",
        "                  custom_transformer_model, \n",
        "                  opt_func = CustomAdamW, \n",
        "                  metrics=[accuracy, error_rate])#.to_fp16()\n",
        "\n",
        "# Show graph of learner stats and metrics after each epoch.\n",
        "learner.callbacks.append(ShowGraph(learner))\n",
        "\n",
        "if use_fp16: learner = learner.to_fp16()"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgLjlP-3t6ct",
        "outputId": "38d27116-ba27-42a9-c563-0f36bb8c2a0e"
      },
      "source": [
        "print(learner.model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CustomTransformerModel(\n",
            "  (transformer): BertForSequenceClassification(\n",
            "    (bert): BertModel(\n",
            "      (embeddings): BertEmbeddings(\n",
            "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "        (position_embeddings): Embedding(512, 768)\n",
            "        (token_type_embeddings): Embedding(2, 768)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (encoder): BertEncoder(\n",
            "        (layer): ModuleList(\n",
            "          (0): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (6): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (7): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (8): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (9): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (10): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (11): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): BertPooler(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDGaKcUtsiAU"
      },
      "source": [
        "# list_layers = [learner.model.transformer.roberta.embeddings,\n",
        "#               learner.model.transformer.roberta.encoder.layer[0],\n",
        "#               learner.model.transformer.roberta.encoder.layer[1],\n",
        "#               learner.model.transformer.roberta.encoder.layer[2],\n",
        "#               learner.model.transformer.roberta.encoder.layer[3],\n",
        "#               learner.model.transformer.roberta.encoder.layer[4],\n",
        "#               learner.model.transformer.roberta.encoder.layer[5],\n",
        "#               learner.model.transformer.roberta.encoder.layer[6],\n",
        "#               learner.model.transformer.roberta.encoder.layer[7],\n",
        "#               learner.model.transformer.roberta.encoder.layer[8],\n",
        "#               learner.model.transformer.roberta.encoder.layer[9],\n",
        "#               learner.model.transformer.roberta.encoder.layer[10],\n",
        "#               learner.model.transformer.roberta.encoder.layer[11],\n",
        "#               learner.model.transformer.roberta.pooler]\n",
        "# learner.split(list_layers)\n",
        "learner.freeze_to(-1)\n",
        "# learner.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "rHjymr62xMX9",
        "outputId": "4862083a-c9fb-46d5-b12d-7a6f03461ebd"
      },
      "source": [
        "learner.unfreeze()\n",
        "learner.lr_find()\n",
        "learner.recorder.plot(skip_end=10,suggestion=True)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/1 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='62' class='' max='1208' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      5.13% [62/1208 00:04<01:30 1.6364]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n",
            "Min numerical gradient: 6.92E-06\n",
            "Min loss divided by 10: 1.45E-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "id": "hneR7OxyvkF4",
        "outputId": "d3316ab5-e87b-45e8-b6b3-d87d3919e810"
      },
      "source": [
        "learner.unfreeze()\n",
        "# learner.freeze_to(-2)\n",
        "learner.fit_one_cycle(3,max_lr=1e-05)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.091724</td>\n",
              "      <td>1.092582</td>\n",
              "      <td>0.381928</td>\n",
              "      <td>0.618072</td>\n",
              "      <td>01:15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.088575</td>\n",
              "      <td>1.092346</td>\n",
              "      <td>0.381928</td>\n",
              "      <td>0.618072</td>\n",
              "      <td>01:18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.091031</td>\n",
              "      <td>1.092327</td>\n",
              "      <td>0.381928</td>\n",
              "      <td>0.618072</td>\n",
              "      <td>01:16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4IYA8neuOCY",
        "outputId": "9368285b-23c7-4534-8edc-efaabba80cd2"
      },
      "source": [
        "learner.predict('I am so sad today')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Category neutral,\n",
              " tensor(1),\n",
              " tensor([2.7656e-01, 4.1231e-01, 3.1112e-01, 2.7256e-07, 2.7866e-07, 2.1317e-07,\n",
              "         2.5102e-07, 2.9112e-07, 1.8234e-07, 1.7835e-07, 3.4957e-07, 3.0324e-07]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caabPLglulcf"
      },
      "source": [
        "learner.export(file = os.path.join(path, 'transformer.pkl'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "J1RME5b1vZl7",
        "outputId": "3ba41d7a-e2a3-4a35-deb2-c790ff7abb85"
      },
      "source": [
        "def get_preds_as_nparray(ds_type) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    the get_preds method does not yield the elements in order by default\n",
        "    we borrow the code from the RNNLearner to resort the elements into their correct order\n",
        "    \"\"\"\n",
        "    preds = learner.get_preds(ds_type)[0].detach().cpu().numpy()\n",
        "    sampler = [i for i in databunch.dl(ds_type).sampler]\n",
        "    reverse_sampler = np.argsort(sampler)\n",
        "    return preds[reverse_sampler, :]\n",
        "\n",
        "test_preds = get_preds_as_nparray(DatasetType.Test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acj-mVI2v0wy",
        "outputId": "f122df8e-6ed4-4939-ef77-f732b49e6981"
      },
      "source": [
        "test_preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.50234 , 0.497659],\n",
              "       [0.50234 , 0.497659],\n",
              "       [0.50234 , 0.497659],\n",
              "       [0.50234 , 0.497659],\n",
              "       ...,\n",
              "       [0.50234 , 0.497659],\n",
              "       [0.50234 , 0.497659],\n",
              "       [0.50234 , 0.497659],\n",
              "       [0.50234 , 0.497659]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHSo49vDv7Kq"
      },
      "source": [
        "test['prediction'] = np.argmax(test_preds,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqARHfvkv38S"
      },
      "source": [
        "test.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BVaABHoxNZg"
      },
      "source": [
        "np.argmax(test_preds,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}