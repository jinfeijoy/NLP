{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0db02ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('C:\\\\Users\\\\luoyan011\\\\Desktop\\\\PersonalLearning\\\\GitHub\\\\python_functions\\\\jl_nlp_pkg')\n",
    "sys.path.append('C:\\\\Users\\\\luoyan011\\\\Desktop\\\\PersonalLearning\\\\GitHub\\\\python_functions\\\\jl_model_explain_pkg')\n",
    "import nlpbasic.textClean as textClean\n",
    "import nlpbasic.docVectors as DocVector\n",
    "import nlpbasic.dataExploration as DataExploration\n",
    "import nlpbasic.lda as lda\n",
    "import nlpbasic.tfidf as tfidf\n",
    "\n",
    "import model_explain.plot as meplot\n",
    "# import model_explain.shap as meshap\n",
    "import tensorflow as tf\n",
    "from numpy import array,asarray,zeros\n",
    "from scipy.spatial import distance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten,Embedding\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import numpy as np\n",
    "import re\n",
    "root_path = 'C:\\\\Users\\\\luoyan011\\\\Desktop\\\\PersonalLearning\\\\GitHub\\\\NLP_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "802de1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def de_emojify(inputString):\n",
    "    return inputString.encode('ascii', 'ignore').decode('ascii')\n",
    "def tweet_proc(df, text_col='text'):\n",
    "    df['orig_text'] = df[text_col]\n",
    "    # Remove twitter handles\n",
    "    df[text_col] = df[text_col].apply(lambda x:re.sub('@[^\\s]+','',x))\n",
    "    # Remove URLs\n",
    "    df[text_col] = df[text_col].apply(lambda x:re.sub(r\"http\\S+\", \"\", x))\n",
    "    # Remove emojis\n",
    "    df[text_col] = df[text_col].apply(de_emojify)\n",
    "    # Remove hashtags\n",
    "    df[text_col] = df[text_col].apply(lambda x:re.sub(r'\\B#\\S+','',x))\n",
    "    return df[df[text_col]!='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1e54efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.300000e+18</td>\n",
       "      <td>RT  91-year-old Ex-Vice President Moody Awori ...</td>\n",
       "      <td>neu</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.300000e+18</td>\n",
       "      <td>RT  BREAKING: The Department of Health reports...</td>\n",
       "      <td>neu</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.300000e+18</td>\n",
       "      <td>RT   Helps Out Fan Who Requested Him To Help A...</td>\n",
       "      <td>pos</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text sentiment  \\\n",
       "0  1.300000e+18  RT  91-year-old Ex-Vice President Moody Awori ...       neu   \n",
       "1  1.300000e+18  RT  BREAKING: The Department of Health reports...       neu   \n",
       "2  1.300000e+18  RT   Helps Out Fan Who Requested Him To Help A...       pos   \n",
       "\n",
       "   label  \n",
       "0    NaN  \n",
       "1    NaN  \n",
       "2    NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_tweet = pd.read_csv(os.path.join(root_path, \"Covid-19 Twitter Dataset (Aug-Sep 2020).csv\"))\n",
    "covid_tweet = covid_tweet[covid_tweet.original_text.isnull()==False].drop_duplicates().reset_index(drop=True)\n",
    "covid_tweet = tweet_proc(covid_tweet,'original_text')\n",
    "covid_tweet['label'] = np.nan\n",
    "covid_tweet = covid_tweet[covid_tweet.lang=='en']\n",
    "covid_tweet = covid_tweet[['id', 'original_text', 'sentiment', 'label']].rename(columns={'original_text':'text'})\n",
    "covid_tweet.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b8e4b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1467810369</td>\n",
       "      <td>- Awww, that's a bummer.  You shoulda got Da...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1467810672</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1467810917</td>\n",
       "      <td>I dived many times for the ball. Managed to s...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text sentiment  \\\n",
       "0  1467810369    - Awww, that's a bummer.  You shoulda got Da...       neg   \n",
       "1  1467810672  is upset that he can't update his Facebook by ...       neg   \n",
       "2  1467810917   I dived many times for the ball. Managed to s...       neg   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_tweet = pd.read_csv(os.path.join(root_path, \"sentiment140_twitter.csv\"), names=['target', 'id', 'date', 'flag', 'user', 'text'], header=None)\n",
    "basic_tweet = basic_tweet[basic_tweet.text.isnull()==False].drop_duplicates().reset_index(drop=True)\n",
    "basic_tweet = tweet_proc(basic_tweet,'text')\n",
    "basic_tweet['label'] = np.where(basic_tweet['target']==0, 0, 1)\n",
    "basic_tweet['sentiment'] = np.where(basic_tweet['target']==0, 'neg', 'pos')\n",
    "basic_tweet = basic_tweet[['id', 'text', 'sentiment', 'label']]\n",
    "basic_tweet.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ee311e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1842736 1600000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_lm = basic_tweet.append(covid_tweet)\n",
    "df_clas = df_lm.dropna(subset=['label'])\n",
    "print(len(df_lm), len(df_clas))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2474ce",
   "metadata": {},
   "source": [
    "## DL & Transfer Learning with fastai\n",
    "some reference:\n",
    "\n",
    "https://www.kaggle.com/maroberti/fastai-with-transformers-bert-roberta\n",
    "\n",
    "https://www.kaggle.com/twhelan/covid-19-vaccine-sentiment-analysis-with-fastai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217529cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
