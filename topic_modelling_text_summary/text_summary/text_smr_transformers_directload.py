# -*- coding: utf-8 -*-
"""text_smr_transformers_directload.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FTQXysRFpRQ87H8B1dIL6Pok2Xf7Bpr0
"""

import pandas as pd
import numpy as np
import io
import os
import re
from google.colab import drive
drive.mount('/content/drive')
datapath = '/content/drive/MyDrive/colab_data'

txt = pd.read_csv(os.path.join(datapath,'smr_data.csv'))

!pip install transformers
from transformers import pipeline
summarizer = pipeline("summarization")

txt.head(3)

print(summarizer(txt.text[0], max_length=130, min_length=30, do_sample=False))

from transformers import AutoModelForSeq2SeqLM, AutoTokenizer
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")
tokenizer = AutoTokenizer.from_pretrained("t5-base")
# T5 uses a max_length of 512 so we cut the article to 512 tokens.
inputs = tokenizer.encode("summarize: " + txt.text[0], return_tensors="pt", max_length=512, truncation=True)
outputs = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)

print(tokenizer.decode(outputs[0]))