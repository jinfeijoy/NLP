{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stock_news_sentiment_transformers.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1a0c4324cf3f4e179d3ecbb9eb51d45b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_12cc5ff48b634cf6b7f9b80f544c3238",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d03985e204f04b118ab177448328d550",
              "IPY_MODEL_8dfe10689f33486dae4a983d80f05ac7"
            ]
          }
        },
        "12cc5ff48b634cf6b7f9b80f544c3238": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d03985e204f04b118ab177448328d550": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_97ea28da952d42c89300ea9a71dbb41a",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6f15345c61f742d095d078bd34d5459b"
          }
        },
        "8dfe10689f33486dae4a983d80f05ac7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_99ad424205c546e5bef44cbc8156e663",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4/4 [08:45&lt;00:00, 131.40s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e38a1ddb402e456bb61710ed2830b63a"
          }
        },
        "97ea28da952d42c89300ea9a71dbb41a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6f15345c61f742d095d078bd34d5459b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "99ad424205c546e5bef44cbc8156e663": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e38a1ddb402e456bb61710ed2830b63a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZQRGgjLoBrI",
        "outputId": "eb2896a5-1c0d-4a73-b865-ec38696c19d7"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "import os\n",
        "import re\n",
        "from google.colab import drive\n",
        "!pip install transformers\n",
        "!pip install SentencePiece\n",
        "import torch\n",
        "import transformers\n",
        "from transformers import XLNetTokenizer, XLNetModel, AdamW, get_linear_schedule_with_warmup\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "from collections import defaultdict\n",
        "from textwrap import wrap\n",
        "from pylab import rcParams\n",
        "\n",
        "from torch import nn, optim\n",
        "from tqdm.notebook import tqdm\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.utils.data import TensorDataset,RandomSampler,SequentialSampler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from transformers import (AutoConfig, \n",
        "                          AutoModelForSequenceClassification, \n",
        "                          AutoTokenizer, AdamW, \n",
        "                          get_linear_schedule_with_warmup,\n",
        "                          set_seed,\n",
        "                          )\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.7.0)\n",
            "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: SentencePiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BV99Tnv4oowI"
      },
      "source": [
        "set_seed(123)\n",
        "epochs = 4\n",
        "batches = 10\n",
        "max_len = 50\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model_name = 'bert-base-cased'\n",
        "# model_name = 'xlnet-base-cased'\n",
        "# model_name = 'xlm-roberta-large'\n",
        "n_labels = 3\n",
        "class_names = ['negative', 'positive','neutral']\n",
        "output_model = 'stocknews.bin'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJeeI2uAovd8"
      },
      "source": [
        "path = '/content/drive/MyDrive/colab_data'\n",
        "def de_emojify(inputString):\n",
        "    return inputString.encode('ascii', 'ignore').decode('ascii')\n",
        "def clean_text(text):\n",
        "    text = re.sub(r\"@[A-Za-z0-9]+\", ' ', text)\n",
        "    text = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', text)\n",
        "    text = re.sub(r\"[^a-zA-z.!?'0-9]\", ' ', text)\n",
        "    text = re.sub('\\t', ' ',  text)\n",
        "    text = re.sub(r\" +\", ' ', text)\n",
        "    return text\n",
        "def text_proc(df, text_col='text'):\n",
        "    df['orig_text'] = df[text_col]\n",
        "    # Remove twitter handles\n",
        "    df[text_col] = df[text_col].apply(lambda x: clean_text(x))\n",
        "    # Remove URLs\n",
        "    df[text_col] = df[text_col].apply(lambda x:x.replace('<br />', ' '))\n",
        "    return df[df[text_col]!='']"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "XoX3vXWwoxHE",
        "outputId": "ae1c8279-df7f-4186-9dee-c9e846b6a841"
      },
      "source": [
        "data = pd.read_csv(os.path.join(path, \"nasdaq.csv\"))\n",
        "data = text_proc(data,'Headline').dropna(subset=['Label'])#.sample(2000, random_state = 10).reset_index(drop=True)\n",
        "data['len'] = data.Headline.apply(lambda x: len(x.split(' ')))\n",
        "print(len(data))\n",
        "print(data['len'].quantile(0.99))\n",
        "data.head(3)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13181\n",
            "52.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Ticker</th>\n",
              "      <th>Headline</th>\n",
              "      <th>orig_text</th>\n",
              "      <th>len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "      <td>Airline shares tumble as New York imposes qua...</td>\n",
              "      <td>@TotesTravel : Airline shares tumble as New Yo...</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>American United call off Hong Kong flights af...</td>\n",
              "      <td>@TotesTravel : American United call off Hong K...</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "      <td>U.S. airline stocks hit highest prices since ...</td>\n",
              "      <td>@TotesTravel : U.S. airline stocks hit highest...</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Label Ticker  ...                                          orig_text len\n",
              "0      0      A  ...  @TotesTravel : Airline shares tumble as New Yo...  35\n",
              "1      1      A  ...  @TotesTravel : American United call off Hong K...  35\n",
              "2      0      A  ...  @TotesTravel : U.S. airline stocks hit highest...  37\n",
              "\n",
              "[3 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdOE5wjdwFQh"
      },
      "source": [
        "df_train, df_val = train_test_split(data, test_size=0.33, random_state=42)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tS9d2KuVwHnP",
        "outputId": "a5227ddd-121f-41ac-d976-4afa9303ef0b"
      },
      "source": [
        "class Transformer_Dataset(Dataset):\n",
        "\n",
        "    def __init__(self, text, target, tokenizer, max_len):\n",
        "        self.text = text\n",
        "        self.target = target\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "    \n",
        "    def __getitem__(self, item):\n",
        "        text = str(self.text[item])\n",
        "        target = self.target[item]\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "        text,\n",
        "        add_special_tokens=True,\n",
        "        max_length=self.max_len,\n",
        "        return_token_type_ids=False,\n",
        "        pad_to_max_length=False,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt',\n",
        "        truncation=True\n",
        "        )\n",
        "\n",
        "        input_ids = pad_sequences(encoding['input_ids'], maxlen=max_len, dtype=torch.Tensor ,truncating=\"post\",padding=\"post\")\n",
        "        input_ids = input_ids.astype(dtype = 'int64')\n",
        "        input_ids = torch.tensor(input_ids) \n",
        "\n",
        "        attention_mask = pad_sequences(encoding['attention_mask'], maxlen=max_len, dtype=torch.Tensor ,truncating=\"post\",padding=\"post\")\n",
        "        attention_mask = attention_mask.astype(dtype = 'int64')\n",
        "        attention_mask = torch.tensor(attention_mask)       \n",
        "\n",
        "        return {\n",
        "        'text': text,\n",
        "        'input_ids': input_ids,\n",
        "        'attention_mask': attention_mask.flatten(),\n",
        "        'target': torch.tensor(target, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "def create_data_loader(df, text, target, tokenizer, max_len, batch_size):\n",
        "  ds = Transformer_Dataset(\n",
        "    text=df[text].to_numpy(),\n",
        "    target=df[target].to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=2,\n",
        "    drop_last = True\n",
        "  )\n",
        "\n",
        "# Get model configuration.\n",
        "print('Loading configuraiton...')\n",
        "model_config = AutoConfig.from_pretrained(pretrained_model_name_or_path=model_name, \n",
        "                                          num_labels=n_labels)\n",
        "\n",
        "# Get model's tokenizer.\n",
        "print('Loading tokenizer...')\n",
        "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_name)\n",
        "\n",
        "# Get the actual model.\n",
        "print('Loading model...')\n",
        "model = AutoModelForSequenceClassification.from_pretrained(pretrained_model_name_or_path=model_name, \n",
        "                                                           config=model_config)\n",
        "\n",
        "# Load model to defined device.\n",
        "model.to(device)\n",
        "print('Model loaded to `%s`'%device)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading configuraiton...\n",
            "Loading tokenizer...\n",
            "Loading model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model loaded to `cuda`\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og19bvnmwQzz"
      },
      "source": [
        "train_data_loader = create_data_loader(df_train,'Headline', 'Label', tokenizer, max_len, batches)\n",
        "val_data_loader = create_data_loader(df_val, 'Headline', 'Label', tokenizer, max_len, batches)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJKknXXexmKJ"
      },
      "source": [
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "                                {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "                                {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay':0.0}\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=3e-5)\n",
        "\n",
        "total_steps = len(train_data_loader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msAxbz1Rwbxr"
      },
      "source": [
        "from sklearn import metrics\n",
        "def train_epoch(model, data_loader, optimizer, device, scheduler, n_examples, batch_size, maxlen):\n",
        "    model = model.train()\n",
        "    losses = []\n",
        "    acc = 0\n",
        "    counter = 0\n",
        "  \n",
        "    for d in data_loader:\n",
        "        input_ids = d[\"input_ids\"].reshape(batch_size,maxlen).to(device)\n",
        "        attention_mask = d[\"attention_mask\"].to(device)\n",
        "        target = d['target'].to(device)\n",
        "        \n",
        "        outputs = model(input_ids=input_ids, token_type_ids=None, attention_mask=attention_mask, labels = target)\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "\n",
        "        # preds = preds.cpu().detach().numpy()\n",
        "        _, prediction = torch.max(outputs[1], dim=1)\n",
        "        target = target.cpu().detach().numpy()\n",
        "        prediction = prediction.cpu().detach().numpy()\n",
        "        accuracy = metrics.accuracy_score(target, prediction)\n",
        "\n",
        "        acc += accuracy\n",
        "        losses.append(loss.item())\n",
        "        \n",
        "        loss.backward()\n",
        "\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        counter = counter + 1\n",
        "\n",
        "    return acc / counter, np.mean(losses)\n",
        "\n",
        "def eval_model(model, data_loader, device, n_examples,batch_size,maxlen):\n",
        "    model = model.eval()\n",
        "    losses = []\n",
        "    acc = 0\n",
        "    counter = 0\n",
        "  \n",
        "    with torch.no_grad():\n",
        "        for d in data_loader:\n",
        "            input_ids = d[\"input_ids\"].reshape(batch_size,maxlen).to(device)\n",
        "            attention_mask = d[\"attention_mask\"].to(device)\n",
        "            target = d['target'].to(device)\n",
        "            \n",
        "            outputs = model(input_ids=input_ids, token_type_ids=None, attention_mask=attention_mask, labels = target)\n",
        "            loss = outputs[0]\n",
        "            logits = outputs[1]\n",
        "\n",
        "            _, prediction = torch.max(outputs[1], dim=1)\n",
        "            target = target.cpu().detach().numpy()\n",
        "            prediction = prediction.cpu().detach().numpy()\n",
        "            accuracy = metrics.accuracy_score(target, prediction)\n",
        "\n",
        "            acc += accuracy\n",
        "            losses.append(loss.item())\n",
        "            counter += 1\n",
        "\n",
        "    return acc / counter, np.mean(losses)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440,
          "referenced_widgets": [
            "1a0c4324cf3f4e179d3ecbb9eb51d45b",
            "12cc5ff48b634cf6b7f9b80f544c3238",
            "d03985e204f04b118ab177448328d550",
            "8dfe10689f33486dae4a983d80f05ac7",
            "97ea28da952d42c89300ea9a71dbb41a",
            "6f15345c61f742d095d078bd34d5459b",
            "99ad424205c546e5bef44cbc8156e663",
            "e38a1ddb402e456bb61710ed2830b63a"
          ]
        },
        "id": "u_NOeT9VyF7r",
        "outputId": "6dbceb5c-e62d-46a2-83c0-98cef4e7893f"
      },
      "source": [
        "%%time\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    print(f'Epoch {epoch + 1}/{epochs}')\n",
        "    print('-' * 10)\n",
        "\n",
        "    train_acc, train_loss = train_epoch(\n",
        "        model,\n",
        "        train_data_loader,     \n",
        "        optimizer, \n",
        "        device, \n",
        "        scheduler, \n",
        "        len(df_train),\n",
        "        batches,\n",
        "        max_len\n",
        "    )\n",
        "\n",
        "    print(f'Train loss {train_loss} Train accuracy {train_acc}')\n",
        "\n",
        "    val_acc, val_loss = eval_model(\n",
        "        model,\n",
        "        val_data_loader, \n",
        "        device, \n",
        "        len(df_val),\n",
        "        batches,\n",
        "        max_len\n",
        "    )\n",
        "\n",
        "    print(f'Val loss {val_loss} Val accuracy {val_acc}')\n",
        "    print()\n",
        "\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['val_acc'].append(val_acc)\n",
        "    history['val_loss'].append(val_loss)\n",
        "\n",
        "    if val_acc > best_accuracy:\n",
        "        torch.save(model.state_dict(), os.path.join(path, output_model))\n",
        "        best_accuracy = val_acc"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a0c4324cf3f4e179d3ecbb9eb51d45b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "----------\n",
            "Train loss 0.743994872574088 Train accuracy 0.6449603624009066\n",
            "Val loss 0.7336052577385958 Val accuracy 0.6452873563218381\n",
            "\n",
            "Epoch 2/4\n",
            "----------\n",
            "Train loss 0.6431200127639425 Train accuracy 0.695583238958097\n",
            "Val loss 0.7198057700847758 Val accuracy 0.6779310344827582\n",
            "\n",
            "Epoch 3/4\n",
            "----------\n",
            "Train loss 0.4273636349996853 Train accuracy 0.8319365798414443\n",
            "Val loss 0.8817875334072387 Val accuracy 0.6889655172413786\n",
            "\n",
            "Epoch 4/4\n",
            "----------\n",
            "Train loss 0.3061764814700016 Train accuracy 0.8958097395243428\n",
            "Val loss 1.1951032187661221 Val accuracy 0.6836781609195401\n",
            "\n",
            "\n",
            "CPU times: user 7min 44s, sys: 51.9 s, total: 8min 36s\n",
            "Wall time: 8min 45s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzmXzRt48MYF"
      },
      "source": [
        "Tried ```bert-base-cased```, val accuracy convert after epoch 1, accuracy in validation dataset is 0.6889655172413786.\n",
        "\n",
        "Tried ```xlnet-base-cased```, val accuracy convert after epoch 1, accuracy in validation dataset is 0.6452873563218381"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGsn2S0oyGDs"
      },
      "source": [
        "def predict_sentiment(text):\n",
        "    text = text\n",
        "\n",
        "    encoded_review = tokenizer.encode_plus(\n",
        "    text,\n",
        "    add_special_tokens=True,\n",
        "    max_length=max_len,\n",
        "    return_token_type_ids=False,\n",
        "    pad_to_max_length=False,\n",
        "    return_attention_mask=True,\n",
        "    return_tensors='pt',\n",
        "    truncation=True\n",
        "    )\n",
        "\n",
        "    input_ids = pad_sequences(encoded_review['input_ids'], maxlen=max_len, dtype=torch.Tensor ,truncating=\"post\",padding=\"post\")\n",
        "    input_ids = input_ids.astype(dtype = 'int64')\n",
        "    input_ids = torch.tensor(input_ids) \n",
        "\n",
        "    attention_mask = pad_sequences(encoded_review['attention_mask'], maxlen=max_len, dtype=torch.Tensor ,truncating=\"post\",padding=\"post\")\n",
        "    attention_mask = attention_mask.astype(dtype = 'int64')\n",
        "    attention_mask = torch.tensor(attention_mask) \n",
        "\n",
        "    input_ids = input_ids.reshape(1,max_len).to(device)\n",
        "    attention_mask = attention_mask.to(device)\n",
        "\n",
        "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    outputs = outputs[0][0].cpu().detach()\n",
        "\n",
        "    probs = F.softmax(outputs, dim=-1).cpu().detach().numpy().tolist()\n",
        "    _, prediction = torch.max(outputs, dim =-1)\n",
        "    # return class_names[prediction]\n",
        "    return prediction\n",
        "    # print(\"Positive score:\", probs[1])\n",
        "    # print(\"Negative score:\", probs[0])\n",
        "    # print(\"Neutral score\", probs[2])\n",
        "    # print(f'text: {text}')\n",
        "    # print(f'target  : {class_names[prediction]}')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "Zz_XED7w5RY1",
        "outputId": "a4c5278a-affb-4ef4-9a29-cccdad388384"
      },
      "source": [
        "df_val.head(3)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Ticker</th>\n",
              "      <th>Headline</th>\n",
              "      <th>orig_text</th>\n",
              "      <th>len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10734</th>\n",
              "      <td>0</td>\n",
              "      <td>AAN</td>\n",
              "      <td>S Africa 49 starving monkeys rescued from cage...</td>\n",
              "      <td>S Africa: 49 starving monkeys rescued from cag...</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6086</th>\n",
              "      <td>0</td>\n",
              "      <td>ASET</td>\n",
              "      <td>China Russia flex muscles in increasing number...</td>\n",
              "      <td>China Russia flex muscles in increasing number...</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7600</th>\n",
              "      <td>0</td>\n",
              "      <td>HWKN</td>\n",
              "      <td>Stephen Hawkins talks about his biggest myster...</td>\n",
              "      <td>Stephen Hawkins talks about his biggest myster...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Label Ticker  ...                                          orig_text len\n",
              "10734      0    AAN  ...  S Africa: 49 starving monkeys rescued from cag...  41\n",
              "6086       0   ASET  ...  China Russia flex muscles in increasing number...  13\n",
              "7600       0   HWKN  ...  Stephen Hawkins talks about his biggest myster...   8\n",
              "\n",
              "[3 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIvkepVSAcMX",
        "outputId": "bc531cb6-d78e-42ed-f68b-58dfaa83b150"
      },
      "source": [
        "df_val.Label.value_counts()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2807\n",
              "1    1438\n",
              "2     105\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUk1DmT65SiT"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HU6hUeaP5s4i",
        "outputId": "91354e06-e160-42ef-8e12-71f703483af5"
      },
      "source": [
        "predict_sentiment(df_val.Headline[10734])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive score: 0.04378170892596245\n",
            "Negative score: 0.9514105916023254\n",
            "Neutral score 0.004807799123227596\n",
            "text: S Africa 49 starving monkeys rescued from cages Starving dehydrated monkeys were rescued from garden nursery near Johannesburg Saturday kept for the entertainment of those buying plants. Some heads were disproportionally large for their bodies amp bones protruded. Many had rickets.\n",
            "target  : negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XIlKh7r5WA7",
        "outputId": "b9b51e1d-ca4e-4af3-9b73-4846f16b536b"
      },
      "source": [
        "df_val['pred']=df_val.Headline.apply(lambda x: int(predict_sentiment(x)))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "8ph_9UkM6qQ7",
        "outputId": "8a6f9579-5ef3-4ed3-821b-5f8aa12221e2"
      },
      "source": [
        "df_val.head(3)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Ticker</th>\n",
              "      <th>Headline</th>\n",
              "      <th>orig_text</th>\n",
              "      <th>len</th>\n",
              "      <th>pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10734</th>\n",
              "      <td>0</td>\n",
              "      <td>AAN</td>\n",
              "      <td>S Africa 49 starving monkeys rescued from cage...</td>\n",
              "      <td>S Africa: 49 starving monkeys rescued from cag...</td>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6086</th>\n",
              "      <td>0</td>\n",
              "      <td>ASET</td>\n",
              "      <td>China Russia flex muscles in increasing number...</td>\n",
              "      <td>China Russia flex muscles in increasing number...</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7600</th>\n",
              "      <td>0</td>\n",
              "      <td>HWKN</td>\n",
              "      <td>Stephen Hawkins talks about his biggest myster...</td>\n",
              "      <td>Stephen Hawkins talks about his biggest myster...</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Label Ticker  ... len pred\n",
              "10734      0    AAN  ...  41    0\n",
              "6086       0   ASET  ...  13    0\n",
              "7600       0   HWKN  ...   8    0\n",
              "\n",
              "[3 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jv7GjHiJ7nxz",
        "outputId": "45d297bf-b1ad-4d1b-d2fc-e83cc764ecef"
      },
      "source": [
        "confusion_matrix(df_val.Label, df_val.pred)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2217,  566,   24],\n",
              "       [ 697,  732,    9],\n",
              "       [  46,   34,   25]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guGnhha_7wGI",
        "outputId": "8c320398-0d93-4d4e-a215-6865043a9bbb"
      },
      "source": [
        "print(classification_report(df_val.Label, df_val.pred))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.79      0.77      2807\n",
            "           1       0.55      0.51      0.53      1438\n",
            "           2       0.43      0.24      0.31       105\n",
            "\n",
            "    accuracy                           0.68      4350\n",
            "   macro avg       0.58      0.51      0.53      4350\n",
            "weighted avg       0.68      0.68      0.68      4350\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}